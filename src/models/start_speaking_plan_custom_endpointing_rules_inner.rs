/*
 * Vapi API
 *
 * Voice AI for developers.
 *
 * The version of the OpenAPI document: 1.0
 * 
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

#[derive(Clone, Debug, PartialEq, Serialize, Deserialize)]
#[serde(untagged)]
pub enum StartSpeakingPlanCustomEndpointingRulesInner {
    AssistantCustomEndpointingRule(models::AssistantCustomEndpointingRule),
    CustomerCustomEndpointingRule(models::CustomerCustomEndpointingRule),
    BothCustomEndpointingRule(models::BothCustomEndpointingRule),
}

impl Default for StartSpeakingPlanCustomEndpointingRulesInner {
    fn default() -> Self {
        Self::AssistantCustomEndpointingRule(Default::default())
    }
}
/// This endpointing rule is based on the last assistant message before customer started speaking.  Flow: - Assistant speaks - Customer starts speaking - Customer transcription comes in - This rule is evaluated on the last assistant message - If a match is found based on `regex`, the endpointing timeout is set to `timeoutSeconds`  Usage: - If you have yes/no questions in your use case like \"are you interested in a loan?\", you can set a shorter timeout. - If you have questions where the customer may pause to look up information like \"what's my account number?\", you can set a longer timeout.
#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd, Hash, Serialize, Deserialize)]
pub enum TypeTrue {
    #[serde(rename = "assistant")]
    Assistant,
    #[serde(rename = "customer")]
    Customer,
    #[serde(rename = "both")]
    Both,
}

impl Default for TypeTrue {
    fn default() -> TypeTrue {
        Self::Assistant
    }
}

