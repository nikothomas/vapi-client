/*
 * Vapi API
 *
 * Voice AI for developers.
 *
 * The version of the OpenAPI document: 1.0
 *
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize)]
pub struct UpdateWorkflowDto {
    #[serde(rename = "nodes", skip_serializing_if = "Option::is_none")]
    pub nodes: Option<Vec<models::WorkflowUserEditableNodesInner>>,
    #[serde(rename = "transcriber", skip_serializing_if = "Option::is_none")]
    pub transcriber: Option<models::WorkflowUserEditableTranscriber>,
    #[serde(rename = "voice", skip_serializing_if = "Option::is_none")]
    pub voice: Option<models::WorkflowUserEditableVoice>,
    /// This is the plan for observability of workflow's calls.  Currently, only Langfuse is supported.
    #[serde(rename = "observabilityPlan", skip_serializing_if = "Option::is_none")]
    pub observability_plan: Option<models::LangfuseObservabilityPlan>,
    /// These are dynamic credentials that will be used for the workflow calls. By default, all the credentials are available for use in the call but you can supplement an additional credentials using this. Dynamic credentials override existing credentials.
    #[serde(rename = "credentials", skip_serializing_if = "Option::is_none")]
    pub credentials: Option<Vec<models::WorkflowUserEditableCredentialsInner>>,
    #[serde(rename = "name", skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    #[serde(rename = "edges", skip_serializing_if = "Option::is_none")]
    pub edges: Option<Vec<models::Edge>>,
    #[serde(rename = "globalPrompt", skip_serializing_if = "Option::is_none")]
    pub global_prompt: Option<String>,
    /// This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.  The order of precedence is:  1. tool.server 2. workflow.server / assistant.server 3. phoneNumber.server 4. org.server
    #[serde(rename = "server", skip_serializing_if = "Option::is_none")]
    pub server: Option<models::Server>,
    /// This is the compliance plan for the workflow. It allows you to configure HIPAA and other compliance settings.
    #[serde(rename = "compliancePlan", skip_serializing_if = "Option::is_none")]
    pub compliance_plan: Option<models::CompliancePlan>,
    /// This is the plan for analysis of workflow's calls. Stored in `call.analysis`.
    #[serde(rename = "analysisPlan", skip_serializing_if = "Option::is_none")]
    pub analysis_plan: Option<models::AnalysisPlan>,
    /// This is the plan for artifacts generated during workflow's calls. Stored in `call.artifact`.
    #[serde(rename = "artifactPlan", skip_serializing_if = "Option::is_none")]
    pub artifact_plan: Option<models::ArtifactPlan>,
    /// This is the plan for when the workflow nodes should start talking.  You should configure this if you're running into these issues: - The assistant is too slow to start talking after the customer is done speaking. - The assistant is too fast to start talking after the customer is done speaking. - The assistant is so fast that it's actually interrupting the customer.
    #[serde(rename = "startSpeakingPlan", skip_serializing_if = "Option::is_none")]
    pub start_speaking_plan: Option<models::StartSpeakingPlan>,
    /// This is the plan for when workflow nodes should stop talking on customer interruption.  You should configure this if you're running into these issues: - The assistant is too slow to recognize customer's interruption. - The assistant is too fast to recognize customer's interruption. - The assistant is getting interrupted by phrases that are just acknowledgments. - The assistant is getting interrupted by background noises. - The assistant is not properly stopping -- it starts talking right after getting interrupted.
    #[serde(rename = "stopSpeakingPlan", skip_serializing_if = "Option::is_none")]
    pub stop_speaking_plan: Option<models::StopSpeakingPlan>,
    /// This is the plan for real-time monitoring of the workflow's calls.  Usage: - To enable live listening of the workflow's calls, set `monitorPlan.listenEnabled` to `true`. - To enable live control of the workflow's calls, set `monitorPlan.controlEnabled` to `true`.
    #[serde(rename = "monitorPlan", skip_serializing_if = "Option::is_none")]
    pub monitor_plan: Option<models::MonitorPlan>,
    /// This enables filtering of noise and background speech while the user is talking.  Features: - Smart denoising using Krisp - Fourier denoising  Both can be used together. Order of precedence: - Smart denoising - Fourier denoising
    #[serde(
        rename = "backgroundSpeechDenoisingPlan",
        skip_serializing_if = "Option::is_none"
    )]
    pub background_speech_denoising_plan: Option<models::BackgroundSpeechDenoisingPlan>,
    /// These are the credentials that will be used for the workflow calls. By default, all the credentials are available for use in the call but you can provide a subset using this.
    #[serde(rename = "credentialIds", skip_serializing_if = "Option::is_none")]
    pub credential_ids: Option<Vec<String>>,
}

impl UpdateWorkflowDto {
    pub fn new() -> UpdateWorkflowDto {
        UpdateWorkflowDto {
            nodes: None,
            transcriber: None,
            voice: None,
            observability_plan: None,
            credentials: None,
            name: None,
            edges: None,
            global_prompt: None,
            server: None,
            compliance_plan: None,
            analysis_plan: None,
            artifact_plan: None,
            start_speaking_plan: None,
            stop_speaking_plan: None,
            monitor_plan: None,
            background_speech_denoising_plan: None,
            credential_ids: None,
        }
    }
}
