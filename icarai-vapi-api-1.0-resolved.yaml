openapi: 3.0.0
info:
  title: Vapi API
  description: Voice AI for developers.
  contact: {}
  version: "1.0"
servers:
- url: https://api.vapi.ai
paths:
  /call:
    get:
      tags:
      - Calls
      summary: List Calls
      operationId: CallController_findAll
      parameters:
      - name: id
        in: query
        description: This is the unique identifier for the call.
        required: false
        schema:
          type: string
      - name: assistantId
        in: query
        description: This will return calls with the specified assistantId.
        required: false
        schema:
          type: string
      - name: phoneNumberId
        in: query
        description: |-
          This is the phone number that will be used for the call. To use a transient number, use `phoneNumber` instead.

          Only relevant for `outboundPhoneCall` and `inboundPhoneCall` type.
        required: false
        schema:
          type: string
      - name: limit
        in: query
        description: This is the maximum number of items to return. Defaults to 100.
        required: false
        schema:
          maximum: 1000
          minimum: 0
          type: number
      - name: createdAtGt
        in: query
        description: This will return items where the createdAt is greater than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtLt
        in: query
        description: This will return items where the createdAt is less than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtGe
        in: query
        description: This will return items where the createdAt is greater than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtLe
        in: query
        description: This will return items where the createdAt is less than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtGt
        in: query
        description: This will return items where the updatedAt is greater than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtLt
        in: query
        description: This will return items where the updatedAt is less than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtGe
        in: query
        description: This will return items where the updatedAt is greater than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtLe
        in: query
        description: This will return items where the updatedAt is less than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/Call'
      security:
      - bearer: []
    post:
      tags:
      - Calls
      summary: Create Call
      operationId: CallController_create
      parameters: []
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateCallDTO'
        required: true
      responses:
        "201":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/inline_response_201'
      security:
      - bearer: []
  /call/{id}:
    get:
      tags:
      - Calls
      summary: Get Call
      operationId: CallController_findOne
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Call'
      security:
      - bearer: []
    delete:
      tags:
      - Calls
      summary: Delete Call Data
      operationId: CallController_deleteCallData
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Call'
      security:
      - bearer: []
    patch:
      tags:
      - Calls
      summary: Update Call
      operationId: CallController_update
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UpdateCallDTO'
        required: true
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Call'
      security:
      - bearer: []
  /assistant:
    get:
      tags:
      - Assistants
      summary: List Assistants
      operationId: AssistantController_findAll
      parameters:
      - name: limit
        in: query
        description: This is the maximum number of items to return. Defaults to 100.
        required: false
        schema:
          maximum: 1000
          minimum: 0
          type: number
      - name: createdAtGt
        in: query
        description: This will return items where the createdAt is greater than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtLt
        in: query
        description: This will return items where the createdAt is less than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtGe
        in: query
        description: This will return items where the createdAt is greater than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtLe
        in: query
        description: This will return items where the createdAt is less than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtGt
        in: query
        description: This will return items where the updatedAt is greater than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtLt
        in: query
        description: This will return items where the updatedAt is less than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtGe
        in: query
        description: This will return items where the updatedAt is greater than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtLe
        in: query
        description: This will return items where the updatedAt is less than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/Assistant'
      security:
      - bearer: []
    post:
      tags:
      - Assistants
      summary: Create Assistant
      operationId: AssistantController_create
      parameters: []
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateAssistantDTO'
        required: true
      responses:
        "201":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Assistant'
      security:
      - bearer: []
  /assistant/{id}:
    get:
      tags:
      - Assistants
      summary: Get Assistant
      operationId: AssistantController_findOne
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Assistant'
      security:
      - bearer: []
    delete:
      tags:
      - Assistants
      summary: Delete Assistant
      operationId: AssistantController_remove
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Assistant'
      security:
      - bearer: []
    patch:
      tags:
      - Assistants
      summary: Update Assistant
      operationId: AssistantController_update
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UpdateAssistantDTO'
        required: true
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Assistant'
      security:
      - bearer: []
  /phone-number:
    get:
      tags:
      - Phone Numbers
      summary: List Phone Numbers
      operationId: PhoneNumberController_findAll
      parameters:
      - name: limit
        in: query
        description: This is the maximum number of items to return. Defaults to 100.
        required: false
        schema:
          maximum: 1000
          minimum: 0
          type: number
      - name: createdAtGt
        in: query
        description: This will return items where the createdAt is greater than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtLt
        in: query
        description: This will return items where the createdAt is less than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtGe
        in: query
        description: This will return items where the createdAt is greater than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtLe
        in: query
        description: This will return items where the createdAt is less than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtGt
        in: query
        description: This will return items where the updatedAt is greater than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtLt
        in: query
        description: This will return items where the updatedAt is less than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtGe
        in: query
        description: This will return items where the updatedAt is greater than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtLe
        in: query
        description: This will return items where the updatedAt is less than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                type: array
                items:
                  title: PhoneNumber
                  discriminator:
                    propertyName: provider
                    mapping:
                      byo-phone-number: '#/components/schemas/ByoPhoneNumber'
                      twilio: '#/components/schemas/TwilioPhoneNumber'
                      vonage: '#/components/schemas/VonagePhoneNumber'
                      vapi: '#/components/schemas/VapiPhoneNumber'
                      telnyx: '#/components/schemas/TelnyxPhoneNumber'
                  oneOf:
                  - $ref: '#/components/schemas/ByoPhoneNumber'
                  - $ref: '#/components/schemas/TwilioPhoneNumber'
                  - $ref: '#/components/schemas/VonagePhoneNumber'
                  - $ref: '#/components/schemas/VapiPhoneNumber'
                  - $ref: '#/components/schemas/TelnyxPhoneNumber'
      security:
      - bearer: []
    post:
      tags:
      - Phone Numbers
      summary: Create Phone Number
      operationId: PhoneNumberController_create
      parameters: []
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/phonenumber_body'
        required: true
      responses:
        "201":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/PhoneNumber'
      security:
      - bearer: []
  /phone-number/{id}:
    get:
      tags:
      - Phone Numbers
      summary: Get Phone Number
      operationId: PhoneNumberController_findOne
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/PhoneNumber'
      security:
      - bearer: []
    delete:
      tags:
      - Phone Numbers
      summary: Delete Phone Number
      operationId: PhoneNumberController_remove
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/PhoneNumber'
      security:
      - bearer: []
    patch:
      tags:
      - Phone Numbers
      summary: Update Phone Number
      operationId: PhoneNumberController_update
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/phonenumber_id_body'
        required: true
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/PhoneNumber'
      security:
      - bearer: []
  /tool:
    get:
      tags:
      - Tools
      summary: List Tools
      operationId: ToolController_findAll
      parameters:
      - name: limit
        in: query
        description: This is the maximum number of items to return. Defaults to 100.
        required: false
        schema:
          maximum: 1000
          minimum: 0
          type: number
      - name: createdAtGt
        in: query
        description: This will return items where the createdAt is greater than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtLt
        in: query
        description: This will return items where the createdAt is less than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtGe
        in: query
        description: This will return items where the createdAt is greater than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtLe
        in: query
        description: This will return items where the createdAt is less than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtGt
        in: query
        description: This will return items where the updatedAt is greater than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtLt
        in: query
        description: This will return items where the updatedAt is less than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtGe
        in: query
        description: This will return items where the updatedAt is greater than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtLe
        in: query
        description: This will return items where the updatedAt is less than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                type: array
                items:
                  discriminator:
                    propertyName: type
                    mapping:
                      dtmf: '#/components/schemas/DtmfTool'
                      endCall: '#/components/schemas/EndCallTool'
                      function: '#/components/schemas/FunctionTool'
                      ghl: '#/components/schemas/GhlTool'
                      make: '#/components/schemas/MakeTool'
                      transferCall: '#/components/schemas/TransferCallTool'
                      output: '#/components/schemas/OutputTool'
                      bash: '#/components/schemas/BashTool'
                      computer: '#/components/schemas/ComputerTool'
                      textEditor: '#/components/schemas/TextEditorTool'
                      query: '#/components/schemas/QueryTool'
                      google.calendar.event.create: '#/components/schemas/GoogleCalendarCreateEventTool'
                      google.sheets.row.append: '#/components/schemas/GoogleSheetsRowAppendTool'
                      google.calendar.availability.check: '#/components/schemas/GoogleCalendarCheckAvailabilityTool'
                      slack.message.send: '#/components/schemas/SlackSendMessageTool'
                      sms: '#/components/schemas/SmsSendTool'
                      mcp: '#/components/schemas/McpTool'
                  oneOf:
                  - $ref: '#/components/schemas/DtmfTool'
                  - $ref: '#/components/schemas/EndCallTool'
                  - $ref: '#/components/schemas/FunctionTool'
                  - $ref: '#/components/schemas/GhlTool'
                  - $ref: '#/components/schemas/MakeTool'
                  - $ref: '#/components/schemas/TransferCallTool'
                  - $ref: '#/components/schemas/OutputTool'
                  - $ref: '#/components/schemas/BashTool'
                  - $ref: '#/components/schemas/ComputerTool'
                  - $ref: '#/components/schemas/TextEditorTool'
                  - $ref: '#/components/schemas/QueryTool'
                  - $ref: '#/components/schemas/GoogleCalendarCreateEventTool'
                  - $ref: '#/components/schemas/GoogleSheetsRowAppendTool'
                  - $ref: '#/components/schemas/GoogleCalendarCheckAvailabilityTool'
                  - $ref: '#/components/schemas/SlackSendMessageTool'
                  - $ref: '#/components/schemas/SmsSendTool'
                  - $ref: '#/components/schemas/McpTool'
      security:
      - bearer: []
    post:
      tags:
      - Tools
      summary: Create Tool
      operationId: ToolController_create
      parameters: []
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/tool_body'
        required: true
      responses:
        "201":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/inline_response_201_1'
      security:
      - bearer: []
  /tool/{id}:
    get:
      tags:
      - Tools
      summary: Get Tool
      operationId: ToolController_findOne
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/inline_response_201_1'
      security:
      - bearer: []
    delete:
      tags:
      - Tools
      summary: Delete Tool
      operationId: ToolController_remove
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/inline_response_201_1'
      security:
      - bearer: []
    patch:
      tags:
      - Tools
      summary: Update Tool
      operationId: ToolController_update
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/tool_id_body'
        required: true
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/inline_response_201_1'
      security:
      - bearer: []
  /file:
    get:
      tags:
      - Files
      summary: List Files
      operationId: FileController_findAll
      parameters: []
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/File'
      security:
      - bearer: []
    post:
      tags:
      - Files
      summary: Upload File
      operationId: FileController_create
      parameters: []
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateFileDTO'
        required: true
      responses:
        "201":
          description: File uploaded successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/File'
        "400":
          description: Invalid file
      security:
      - bearer: []
  /file/{id}:
    get:
      tags:
      - Files
      summary: Get File
      operationId: FileController_findOne
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/File'
      security:
      - bearer: []
    delete:
      tags:
      - Files
      summary: Delete File
      operationId: FileController_remove
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/File'
      security:
      - bearer: []
    patch:
      tags:
      - Files
      summary: Update File
      operationId: FileController_update
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UpdateFileDTO'
        required: true
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/File'
      security:
      - bearer: []
  /knowledge-base:
    get:
      tags:
      - Knowledge Base
      summary: List Knowledge Bases
      operationId: KnowledgeBaseController_findAll
      parameters:
      - name: limit
        in: query
        description: This is the maximum number of items to return. Defaults to 100.
        required: false
        schema:
          maximum: 1000
          minimum: 0
          type: number
      - name: createdAtGt
        in: query
        description: This will return items where the createdAt is greater than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtLt
        in: query
        description: This will return items where the createdAt is less than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtGe
        in: query
        description: This will return items where the createdAt is greater than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtLe
        in: query
        description: This will return items where the createdAt is less than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtGt
        in: query
        description: This will return items where the updatedAt is greater than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtLt
        in: query
        description: This will return items where the updatedAt is less than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtGe
        in: query
        description: This will return items where the updatedAt is greater than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtLe
        in: query
        description: This will return items where the updatedAt is less than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                type: array
                items:
                  discriminator:
                    propertyName: provider
                    mapping:
                      trieve: '#/components/schemas/TrieveKnowledgeBase'
                      custom-knowledge-base: '#/components/schemas/CustomKnowledgeBase'
                  oneOf:
                  - $ref: '#/components/schemas/TrieveKnowledgeBase'
                  - $ref: '#/components/schemas/CustomKnowledgeBase'
      security:
      - bearer: []
    post:
      tags:
      - Knowledge Base
      summary: Create Knowledge Base
      operationId: KnowledgeBaseController_create
      parameters: []
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/knowledgebase_body'
        required: true
      responses:
        "201":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/inline_response_201_2'
      security:
      - bearer: []
  /knowledge-base/{id}:
    get:
      tags:
      - Knowledge Base
      summary: Get Knowledge Base
      operationId: KnowledgeBaseController_findOne
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/inline_response_201_2'
      security:
      - bearer: []
    delete:
      tags:
      - Knowledge Base
      summary: Delete Knowledge Base
      operationId: KnowledgeBaseController_remove
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/inline_response_201_2'
      security:
      - bearer: []
    patch:
      tags:
      - Knowledge Base
      summary: Update Knowledge Base
      operationId: KnowledgeBaseController_update
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/knowledgebase_id_body'
        required: true
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/inline_response_201_2'
      security:
      - bearer: []
  /workflow:
    get:
      tags:
      - Workflow
      summary: Get Workflows
      operationId: WorkflowController_findAll
      parameters: []
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/Workflow'
      security:
      - bearer: []
    post:
      tags:
      - Workflow
      summary: Create Workflow
      operationId: WorkflowController_create
      parameters: []
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateWorkflowDTO'
        required: true
      responses:
        "201":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Workflow'
      security:
      - bearer: []
  /workflow/{id}:
    get:
      tags:
      - Workflow
      summary: Get Workflow
      operationId: WorkflowController_findOne
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Workflow'
      security:
      - bearer: []
    delete:
      tags:
      - Workflow
      summary: Delete Workflow
      operationId: WorkflowController_delete
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Workflow'
      security:
      - bearer: []
    patch:
      tags:
      - Workflow
      summary: Update Workflow
      operationId: WorkflowController_update
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UpdateWorkflowDTO'
        required: true
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Workflow'
      security:
      - bearer: []
  /squad:
    get:
      tags:
      - Squads
      summary: List Squads
      operationId: SquadController_findAll
      parameters:
      - name: limit
        in: query
        description: This is the maximum number of items to return. Defaults to 100.
        required: false
        schema:
          maximum: 1000
          minimum: 0
          type: number
      - name: createdAtGt
        in: query
        description: This will return items where the createdAt is greater than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtLt
        in: query
        description: This will return items where the createdAt is less than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtGe
        in: query
        description: This will return items where the createdAt is greater than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtLe
        in: query
        description: This will return items where the createdAt is less than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtGt
        in: query
        description: This will return items where the updatedAt is greater than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtLt
        in: query
        description: This will return items where the updatedAt is less than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtGe
        in: query
        description: This will return items where the updatedAt is greater than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtLe
        in: query
        description: This will return items where the updatedAt is less than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/Squad'
      security:
      - bearer: []
    post:
      tags:
      - Squads
      summary: Create Squad
      operationId: SquadController_create
      parameters: []
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateSquadDTO'
        required: true
      responses:
        "201":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Squad'
      security:
      - bearer: []
  /squad/{id}:
    get:
      tags:
      - Squads
      summary: Get Squad
      operationId: SquadController_findOne
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Squad'
      security:
      - bearer: []
    delete:
      tags:
      - Squads
      summary: Delete Squad
      operationId: SquadController_remove
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Squad'
      security:
      - bearer: []
    patch:
      tags:
      - Squads
      summary: Update Squad
      operationId: SquadController_update
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UpdateSquadDTO'
        required: true
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Squad'
      security:
      - bearer: []
  /test-suite:
    get:
      tags:
      - Test Suites
      summary: List Test Suites
      operationId: TestSuiteController_findAllPaginated
      parameters:
      - name: page
        in: query
        description: This is the page number to return. Defaults to 1.
        required: false
        schema:
          minimum: 1
          type: number
      - name: sortOrder
        in: query
        description: This is the sort order for pagination. Defaults to 'DESC'.
        required: false
        schema:
          type: string
          enum:
          - ASC
          - DESC
      - name: limit
        in: query
        description: This is the maximum number of items to return. Defaults to 100.
        required: false
        schema:
          maximum: 1000
          minimum: 0
          type: number
      - name: createdAtGt
        in: query
        description: This will return items where the createdAt is greater than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtLt
        in: query
        description: This will return items where the createdAt is less than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtGe
        in: query
        description: This will return items where the createdAt is greater than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtLe
        in: query
        description: This will return items where the createdAt is less than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtGt
        in: query
        description: This will return items where the updatedAt is greater than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtLt
        in: query
        description: This will return items where the updatedAt is less than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtGe
        in: query
        description: This will return items where the updatedAt is greater than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtLe
        in: query
        description: This will return items where the updatedAt is less than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/TestSuitesPaginatedResponse'
      security:
      - bearer: []
    post:
      tags:
      - Test Suites
      summary: Create Test Suite
      operationId: TestSuiteController_create
      parameters: []
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateTestSuiteDto'
        required: true
      responses:
        "201":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/TestSuite'
      security:
      - bearer: []
  /test-suite/{id}:
    get:
      tags:
      - Test Suites
      summary: Get Test Suite
      operationId: TestSuiteController_findOne
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/TestSuite'
      security:
      - bearer: []
    delete:
      tags:
      - Test Suites
      summary: Delete Test Suite
      operationId: TestSuiteController_remove
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/TestSuite'
      security:
      - bearer: []
    patch:
      tags:
      - Test Suites
      summary: Update Test Suite
      operationId: TestSuiteController_update
      parameters:
      - name: id
        in: path
        required: true
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UpdateTestSuiteDto'
        required: true
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/TestSuite'
      security:
      - bearer: []
  /test-suite/{testSuiteId}/test:
    get:
      tags:
      - Test Suite Tests
      summary: List Tests
      operationId: TestSuiteTestController_findAllPaginated
      parameters:
      - name: testSuiteId
        in: path
        required: true
        schema:
          type: string
      - name: page
        in: query
        description: This is the page number to return. Defaults to 1.
        required: false
        schema:
          minimum: 1
          type: number
      - name: sortOrder
        in: query
        description: This is the sort order for pagination. Defaults to 'DESC'.
        required: false
        schema:
          type: string
          enum:
          - ASC
          - DESC
      - name: limit
        in: query
        description: This is the maximum number of items to return. Defaults to 100.
        required: false
        schema:
          maximum: 1000
          minimum: 0
          type: number
      - name: createdAtGt
        in: query
        description: This will return items where the createdAt is greater than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtLt
        in: query
        description: This will return items where the createdAt is less than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtGe
        in: query
        description: This will return items where the createdAt is greater than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtLe
        in: query
        description: This will return items where the createdAt is less than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtGt
        in: query
        description: This will return items where the updatedAt is greater than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtLt
        in: query
        description: This will return items where the updatedAt is less than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtGe
        in: query
        description: This will return items where the updatedAt is greater than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtLe
        in: query
        description: This will return items where the updatedAt is less than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/TestSuiteTestsPaginatedResponse'
      security:
      - bearer: []
    post:
      tags:
      - Test Suite Tests
      summary: Create Test
      operationId: TestSuiteTestController_create
      parameters:
      - name: testSuiteId
        in: path
        required: true
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/testSuiteId_test_body'
        required: true
      responses:
        "201":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/inline_response_201_3'
      security:
      - bearer: []
  /test-suite/{testSuiteId}/test/{id}:
    get:
      tags:
      - Test Suite Tests
      summary: Get Test
      operationId: TestSuiteTestController_findOne
      parameters:
      - name: testSuiteId
        in: path
        required: true
        schema:
          type: string
      - name: id
        in: path
        required: true
        schema:
          type: string
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/inline_response_201_3'
      security:
      - bearer: []
    delete:
      tags:
      - Test Suite Tests
      summary: Delete Test
      operationId: TestSuiteTestController_remove
      parameters:
      - name: testSuiteId
        in: path
        required: true
        schema:
          type: string
      - name: id
        in: path
        required: true
        schema:
          type: string
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/inline_response_201_3'
      security:
      - bearer: []
    patch:
      tags:
      - Test Suite Tests
      summary: Update Test
      operationId: TestSuiteTestController_update
      parameters:
      - name: testSuiteId
        in: path
        required: true
        schema:
          type: string
      - name: id
        in: path
        required: true
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/test_id_body'
        required: true
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/inline_response_201_3'
      security:
      - bearer: []
  /test-suite/{testSuiteId}/run:
    get:
      tags:
      - Test Suite Runs
      summary: List Test Suite Runs
      operationId: TestSuiteRunController_findAllPaginated
      parameters:
      - name: testSuiteId
        in: path
        required: true
        schema:
          type: string
      - name: page
        in: query
        description: This is the page number to return. Defaults to 1.
        required: false
        schema:
          minimum: 1
          type: number
      - name: sortOrder
        in: query
        description: This is the sort order for pagination. Defaults to 'DESC'.
        required: false
        schema:
          type: string
          enum:
          - ASC
          - DESC
      - name: limit
        in: query
        description: This is the maximum number of items to return. Defaults to 100.
        required: false
        schema:
          maximum: 1000
          minimum: 0
          type: number
      - name: createdAtGt
        in: query
        description: This will return items where the createdAt is greater than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtLt
        in: query
        description: This will return items where the createdAt is less than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtGe
        in: query
        description: This will return items where the createdAt is greater than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtLe
        in: query
        description: This will return items where the createdAt is less than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtGt
        in: query
        description: This will return items where the updatedAt is greater than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtLt
        in: query
        description: This will return items where the updatedAt is less than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtGe
        in: query
        description: This will return items where the updatedAt is greater than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtLe
        in: query
        description: This will return items where the updatedAt is less than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/TestSuiteRunsPaginatedResponse'
      security:
      - bearer: []
    post:
      tags:
      - Test Suite Runs
      summary: Create Test Suite Run
      operationId: TestSuiteRunController_create
      parameters:
      - name: testSuiteId
        in: path
        required: true
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateTestSuiteRunDto'
        required: true
      responses:
        "201":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/TestSuiteRun'
      security:
      - bearer: []
  /test-suite/{testSuiteId}/run/{id}:
    get:
      tags:
      - Test Suite Runs
      summary: Get Test Suite Run
      operationId: TestSuiteRunController_findOne
      parameters:
      - name: testSuiteId
        in: path
        required: true
        schema:
          type: string
      - name: id
        in: path
        required: true
        schema:
          type: string
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/TestSuiteRun'
      security:
      - bearer: []
    delete:
      tags:
      - Test Suite Runs
      summary: Delete Test Suite Run
      operationId: TestSuiteRunController_remove
      parameters:
      - name: testSuiteId
        in: path
        required: true
        schema:
          type: string
      - name: id
        in: path
        required: true
        schema:
          type: string
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/TestSuiteRun'
      security:
      - bearer: []
    patch:
      tags:
      - Test Suite Runs
      summary: Update Test Suite Run
      operationId: TestSuiteRunController_update
      parameters:
      - name: testSuiteId
        in: path
        required: true
        schema:
          type: string
      - name: id
        in: path
        required: true
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UpdateTestSuiteRunDto'
        required: true
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/TestSuiteRun'
      security:
      - bearer: []
  /analytics:
    post:
      tags:
      - Analytics
      summary: Create Analytics Queries
      operationId: AnalyticsController_query
      parameters: []
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/AnalyticsQueryDTO'
        required: true
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/AnalyticsQueryResult'
        "201":
          description: ""
      security:
      - bearer: []
  /logs:
    get:
      tags:
      - Logs
      summary: Get Logs
      operationId: LoggingController_logsQuery
      parameters:
      - name: type
        in: query
        description: This is the type of the log.
        required: false
        schema:
          type: string
          enum:
          - API
          - Webhook
          - Call
          - Provider
      - name: webhookType
        in: query
        description: "This is the type of the webhook, given the log is from a webhook."
        required: false
        schema:
          type: string
      - name: assistantId
        in: query
        description: This is the ID of the assistant.
        required: false
        schema:
          type: string
      - name: phoneNumberId
        in: query
        description: This is the ID of the phone number.
        required: false
        schema:
          type: string
      - name: customerId
        in: query
        description: This is the ID of the customer.
        required: false
        schema:
          type: string
      - name: squadId
        in: query
        description: This is the ID of the squad.
        required: false
        schema:
          type: string
      - name: callId
        in: query
        description: This is the ID of the call.
        required: false
        schema:
          type: string
      - name: page
        in: query
        description: This is the page number to return. Defaults to 1.
        required: false
        schema:
          minimum: 1
          type: number
      - name: sortOrder
        in: query
        description: This is the sort order for pagination. Defaults to 'DESC'.
        required: false
        schema:
          type: string
          enum:
          - ASC
          - DESC
      - name: limit
        in: query
        description: This is the maximum number of items to return. Defaults to 100.
        required: false
        schema:
          maximum: 1000
          minimum: 0
          type: number
      - name: createdAtGt
        in: query
        description: This will return items where the createdAt is greater than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtLt
        in: query
        description: This will return items where the createdAt is less than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtGe
        in: query
        description: This will return items where the createdAt is greater than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: createdAtLe
        in: query
        description: This will return items where the createdAt is less than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtGt
        in: query
        description: This will return items where the updatedAt is greater than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtLt
        in: query
        description: This will return items where the updatedAt is less than the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtGe
        in: query
        description: This will return items where the updatedAt is greater than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      - name: updatedAtLe
        in: query
        description: This will return items where the updatedAt is less than or equal to the specified value.
        required: false
        schema:
          type: string
          format: date-time
      responses:
        "200":
          description: ""
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/LogsPaginatedResponse'
      deprecated: true
      security:
      - bearer: []
    delete:
      tags:
      - Logs
      summary: Delete Logs
      operationId: LoggingController_logsDeleteQuery
      parameters:
      - name: type
        in: query
        description: This is the type of the log.
        required: false
        schema:
          type: string
          enum:
          - API
          - Webhook
          - Call
          - Provider
      - name: assistantId
        in: query
        required: false
        schema:
          type: string
      - name: phoneNumberId
        in: query
        description: This is the ID of the phone number.
        required: false
        schema:
          type: string
      - name: customerId
        in: query
        description: This is the ID of the customer.
        required: false
        schema:
          type: string
      - name: squadId
        in: query
        description: This is the ID of the squad.
        required: false
        schema:
          type: string
      - name: callId
        in: query
        description: This is the ID of the call.
        required: false
        schema:
          type: string
      responses:
        "200":
          description: ""
      deprecated: true
      security:
      - bearer: []
components:
  schemas:
    AnalysisCostBreakdown:
      type: object
      properties:
        summary:
          type: number
          description: This is the cost to summarize the call.
        summaryPromptTokens:
          type: number
          description: This is the number of prompt tokens used to summarize the call.
        summaryCompletionTokens:
          type: number
          description: This is the number of completion tokens used to summarize the call.
        structuredData:
          type: number
          description: This is the cost to extract structured data from the call.
        structuredDataPromptTokens:
          type: number
          description: This is the number of prompt tokens used to extract structured data from the call.
        structuredDataCompletionTokens:
          type: number
          description: This is the number of completion tokens used to extract structured data from the call.
        successEvaluation:
          type: number
          description: This is the cost to evaluate if the call was successful.
        successEvaluationPromptTokens:
          type: number
          description: This is the number of prompt tokens used to evaluate if the call was successful.
        successEvaluationCompletionTokens:
          type: number
          description: This is the number of completion tokens used to evaluate if the call was successful.
    CostBreakdown:
      type: object
      properties:
        transport:
          type: number
          description: "This is the cost of the transport provider, like Twilio or Vonage."
        stt:
          type: number
          description: This is the cost of the speech-to-text service.
        llm:
          type: number
          description: This is the cost of the language model.
        tts:
          type: number
          description: This is the cost of the text-to-speech service.
        vapi:
          type: number
          description: This is the cost of Vapi.
        total:
          type: number
          description: This is the total cost of the call.
        llmPromptTokens:
          type: number
          description: This is the LLM prompt tokens used for the call.
        llmCompletionTokens:
          type: number
          description: This is the LLM completion tokens used for the call.
        ttsCharacters:
          type: number
          description: This is the TTS characters used for the call.
        analysisCostBreakdown:
          description: This is the cost of the analysis.
          allOf:
          - $ref: '#/components/schemas/AnalysisCostBreakdown'
    TranscriptPlan:
      type: object
      properties:
        enabled:
          type: boolean
          description: |-
            This determines whether the transcript is stored in `call.artifact.transcript`. Defaults to true.

            @default true
          example: true
        assistantName:
          type: string
          description: |-
            This is the name of the assistant in the transcript. Defaults to 'AI'.

            Usage:
            - If you want to change the name of the assistant in the transcript, set this. Example, here is what the transcript would look like with `assistantName` set to 'Buyer':
            ```
            User: Hello, how are you?
            Buyer: I'm fine.
            User: Do you want to buy a car?
            Buyer: No.
            ```

            @default 'AI'
        userName:
          type: string
          description: |-
            This is the name of the user in the transcript. Defaults to 'User'.

            Usage:
            - If you want to change the name of the user in the transcript, set this. Example, here is what the transcript would look like with `userName` set to 'Seller':
            ```
            Seller: Hello, how are you?
            AI: I'm fine.
            Seller: Do you want to buy a car?
            AI: No.
            ```

            @default 'User'
    ArtifactPlan:
      type: object
      properties:
        recordingEnabled:
          type: boolean
          description: |-
            This determines whether assistant's calls are recorded. Defaults to true.

            Usage:
            - If you don't want to record the calls, set this to false.
            - If you want to record the calls when `assistant.hipaaEnabled` (deprecated) or `assistant.compliancePlan.hipaaEnabled` explicity set this to true and make sure to provide S3 or GCP credentials on the Provider Credentials page in the Dashboard.

            You can find the recording at `call.artifact.recordingUrl` and `call.artifact.stereoRecordingUrl` after the call is ended.

            @default true
          example: true
        recordingFormat:
          type: string
          description: |-
            This determines the format of the recording. Defaults to `wav;l16`.

            @default 'wav;l16'
          enum:
          - wav;l16
          - mp3
        videoRecordingEnabled:
          type: boolean
          description: |-
            This determines whether the video is recorded during the call. Defaults to false. Only relevant for `webCall` type.

            You can find the video recording at `call.artifact.videoRecordingUrl` after the call is ended.

            @default false
          example: false
        pcapEnabled:
          type: boolean
          description: |-
            This determines whether the SIP packet capture is enabled. Defaults to true. Only relevant for `phone` type calls where phone number's provider is `vapi` or `byo-phone-number`.

            You can find the packet capture at `call.artifact.pcapUrl` after the call is ended.

            @default true
          example: true
        pcapS3PathPrefix:
          type: string
          description: |-
            This is the path where the SIP packet capture will be uploaded. This is only used if you have provided S3 or GCP credentials on the Provider Credentials page in the Dashboard.

            If credential.s3PathPrefix or credential.bucketPlan.path is set, this will append to it.

            Usage:
            - If you want to upload the packet capture to a specific path, set this to the path. Example: `/my-assistant-captures`.
            - If you want to upload the packet capture to the root of the bucket, set this to `/`.

            @default '/'
          example: /pcaps
        transcriptPlan:
          description: "This is the plan for `call.artifact.transcript`. To disable, set `transcriptPlan.enabled` to false."
          allOf:
          - $ref: '#/components/schemas/TranscriptPlan'
        recordingPath:
          type: string
          description: |-
            This is the path where the recording will be uploaded. This is only used if you have provided S3 or GCP credentials on the Provider Credentials page in the Dashboard.

            If credential.s3PathPrefix or credential.bucketPlan.path is set, this will append to it.

            Usage:
            - If you want to upload the recording to a specific path, set this to the path. Example: `/my-assistant-recordings`.
            - If you want to upload the recording to the root of the bucket, set this to `/`.

            @default '/'
    Analysis:
      type: object
      properties:
        summary:
          type: string
          description: This is the summary of the call. Customize by setting `assistant.analysisPlan.summaryPrompt`.
        structuredData:
          type: object
          description: This is the structured data extracted from the call. Customize by setting `assistant.analysisPlan.structuredDataPrompt` and/or `assistant.analysisPlan.structuredDataSchema`.
        structuredDataMulti:
          type: array
          description: This is the structured data catalog of the call. Customize by setting `assistant.analysisPlan.structuredDataMultiPlan`.
          items:
            type: object
        successEvaluation:
          type: string
          description: This is the evaluation of the call. Customize by setting `assistant.analysisPlan.successEvaluationPrompt` and/or `assistant.analysisPlan.successEvaluationRubric`.
    Monitor:
      type: object
      properties:
        listenUrl:
          type: string
          description: "This is the URL where the assistant's calls can be listened to in real-time. To enable, set `assistant.monitorPlan.listenEnabled` to `true`."
        controlUrl:
          type: string
          description: "This is the URL where the assistant's calls can be controlled in real-time. To enable, set `assistant.monitorPlan.controlEnabled` to `true`."
    OpenAIMessage:
      required:
      - content
      - role
      type: object
      properties:
        content:
          maxLength: 100000000
          type: string
          nullable: true
        role:
          type: string
          enum:
          - assistant
          - function
          - user
          - system
          - tool
    Artifact:
      type: object
      properties:
        messages:
          type: array
          description: These are the messages that were spoken during the call.
          items:
            oneOf:
            - $ref: '#/components/schemas/UserMessage'
            - $ref: '#/components/schemas/SystemMessage'
            - $ref: '#/components/schemas/BotMessage'
            - $ref: '#/components/schemas/ToolCallMessage'
            - $ref: '#/components/schemas/ToolCallResultMessage'
        messagesOpenAIFormatted:
          type: array
          description: "These are the messages that were spoken during the call, formatted for OpenAI."
          items:
            $ref: '#/components/schemas/OpenAIMessage'
        recordingUrl:
          type: string
          description: "This is the recording url for the call. To enable, set `assistant.artifactPlan.recordingEnabled`."
        stereoRecordingUrl:
          type: string
          description: "This is the stereo recording url for the call. To enable, set `assistant.artifactPlan.recordingEnabled`."
        videoRecordingUrl:
          type: string
          description: "This is video recording url for the call. To enable, set `assistant.artifactPlan.videoRecordingEnabled`."
        videoRecordingStartDelaySeconds:
          type: number
          description: "This is video recording start delay in ms. To enable, set `assistant.artifactPlan.videoRecordingEnabled`. This can be used to align the playback of the recording with artifact.messages timestamps."
        transcript:
          type: string
          description: This is the transcript of the call. This is derived from `artifact.messages` but provided for convenience.
        pcapUrl:
          type: string
          description: This is the packet capture url for the call. This is only available for `phone` type calls where phone number's provider is `vapi` or `byo-phone-number`.
    FallbackTranscriberPlan:
      required:
      - transcribers
      type: object
      properties:
        transcribers:
          type: array
          items:
            oneOf:
            - $ref: '#/components/schemas/FallbackAssemblyAITranscriber'
            - $ref: '#/components/schemas/FallbackAzureSpeechTranscriber'
            - $ref: '#/components/schemas/FallbackCustomTranscriber'
            - $ref: '#/components/schemas/FallbackDeepgramTranscriber'
            - $ref: '#/components/schemas/FallbackElevenLabsTranscriber'
            - $ref: '#/components/schemas/FallbackGladiaTranscriber'
            - $ref: '#/components/schemas/FallbackGoogleTranscriber'
            - $ref: '#/components/schemas/FallbackTalkscriberTranscriber'
            - $ref: '#/components/schemas/FallbackSpeechmaticsTranscriber'
            - $ref: '#/components/schemas/FallbackOpenAITranscriber'
    AssemblyAITranscriber:
      required:
      - provider
      type: object
      properties:
        provider:
          type: string
          description: This is the transcription provider that will be used.
          enum:
          - assembly-ai
        language:
          type: string
          description: This is the language that will be set for the transcription.
          enum:
          - en
        confidenceThreshold:
          maximum: 1
          minimum: 0
          type: number
          description: |-
            Transcripts below this confidence threshold will be discarded.

            @default 0.4
          example: 0.4
        realtimeUrl:
          type: string
          description: The WebSocket URL that the transcriber connects to.
        wordBoost:
          type: array
          description: Add up to 2500 characters of custom vocabulary.
          items:
            maxLength: 2500
            type: string
        endUtteranceSilenceThreshold:
          type: number
          description: The duration of the end utterance silence threshold in milliseconds.
        disablePartialTranscripts:
          type: boolean
          description: |-
            Disable partial transcripts.
            Set to `true` to not receive partial transcripts. Defaults to `false`.
        fallbackPlan:
          description: This is the plan for voice provider fallbacks in the event that the primary voice provider fails.
          allOf:
          - $ref: '#/components/schemas/FallbackTranscriberPlan'
    AzureSpeechTranscriber:
      required:
      - provider
      type: object
      properties:
        provider:
          type: string
          description: This is the transcription provider that will be used.
          enum:
          - azure
        language:
          type: string
          description: "This is the language that will be set for the transcription. The list of languages Azure supports can be found here: https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=stt"
          enum:
          - af-ZA
          - am-ET
          - ar-AE
          - ar-BH
          - ar-DZ
          - ar-EG
          - ar-IL
          - ar-IQ
          - ar-JO
          - ar-KW
          - ar-LB
          - ar-LY
          - ar-MA
          - ar-OM
          - ar-PS
          - ar-QA
          - ar-SA
          - ar-SY
          - ar-TN
          - ar-YE
          - az-AZ
          - bg-BG
          - bn-IN
          - bs-BA
          - ca-ES
          - cs-CZ
          - cy-GB
          - da-DK
          - de-AT
          - de-CH
          - de-DE
          - el-GR
          - en-AU
          - en-CA
          - en-GB
          - en-GH
          - en-HK
          - en-IE
          - en-IN
          - en-KE
          - en-NG
          - en-NZ
          - en-PH
          - en-SG
          - en-TZ
          - en-US
          - en-ZA
          - es-AR
          - es-BO
          - es-CL
          - es-CO
          - es-CR
          - es-CU
          - es-DO
          - es-EC
          - es-ES
          - es-GQ
          - es-GT
          - es-HN
          - es-MX
          - es-NI
          - es-PA
          - es-PE
          - es-PR
          - es-PY
          - es-SV
          - es-US
          - es-UY
          - es-VE
          - et-EE
          - eu-ES
          - fa-IR
          - fi-FI
          - fil-PH
          - fr-BE
          - fr-CA
          - fr-CH
          - fr-FR
          - ga-IE
          - gl-ES
          - gu-IN
          - he-IL
          - hi-IN
          - hr-HR
          - hu-HU
          - hy-AM
          - id-ID
          - is-IS
          - it-CH
          - it-IT
          - ja-JP
          - jv-ID
          - ka-GE
          - kk-KZ
          - km-KH
          - kn-IN
          - ko-KR
          - lo-LA
          - lt-LT
          - lv-LV
          - mk-MK
          - ml-IN
          - mn-MN
          - mr-IN
          - ms-MY
          - mt-MT
          - my-MM
          - nb-NO
          - ne-NP
          - nl-BE
          - nl-NL
          - pa-IN
          - pl-PL
          - ps-AF
          - pt-BR
          - pt-PT
          - ro-RO
          - ru-RU
          - si-LK
          - sk-SK
          - sl-SI
          - so-SO
          - sq-AL
          - sr-RS
          - sv-SE
          - sw-KE
          - sw-TZ
          - ta-IN
          - te-IN
          - th-TH
          - tr-TR
          - uk-UA
          - ur-IN
          - uz-UZ
          - vi-VN
          - wuu-CN
          - yue-CN
          - zh-CN
          - zh-CN-shandong
          - zh-CN-sichuan
          - zh-HK
          - zh-TW
          - zu-ZA
        fallbackPlan:
          description: This is the plan for voice provider fallbacks in the event that the primary voice provider fails.
          allOf:
          - $ref: '#/components/schemas/FallbackTranscriberPlan'
    BackoffPlan:
      required:
      - baseDelaySeconds
      - maxRetries
      - type
      type: object
      properties:
        maxRetries:
          maximum: 10
          minimum: 0
          type: number
          description: |-
            This is the maximum number of retries to attempt if the request fails. Defaults to 0 (no retries).

            @default 0
          example: 0
        type:
          type: object
          description: |-
            This is the type of backoff plan to use. Defaults to fixed.

            @default fixed
          example: fixed
          enum:
          - fixed
          - exponential
        baseDelaySeconds:
          maximum: 10
          minimum: 0
          type: number
          description: "This is the base delay in seconds. For linear backoff, this is the delay between each retry. For exponential backoff, this is the initial delay."
          example: 1
    Server:
      required:
      - url
      type: object
      properties:
        timeoutSeconds:
          maximum: 120
          minimum: 1
          type: number
          description: |-
            This is the timeout in seconds for the request to your server. Defaults to 20 seconds.

            @default 20
          example: 20
        url:
          type: string
          description: API endpoint to send requests to.
        secret:
          type: string
          description: |-
            This is the secret you can set that Vapi will send with every request to your server. Will be sent as a header called x-vapi-secret.

            Same precedence logic as server.
        headers:
          type: object
          description: |-
            These are the custom headers to include in the request sent to your server.

            Each key-value pair represents a header name and its value.
        backoffPlan:
          description: This is the backoff plan to use if the request fails.
          allOf:
          - $ref: '#/components/schemas/BackoffPlan'
    CustomTranscriber:
      required:
      - provider
      - server
      type: object
      properties:
        provider:
          type: string
          description: This is the transcription provider that will be used. Use `custom-transcriber` for providers that are not natively supported.
          enum:
          - custom-transcriber
        server:
          description: |-
            This is where the transcription request will be sent.

            Usage:
            1. Vapi will initiate a websocket connection with `server.url`.

            2. Vapi will send an initial text frame with the sample rate. Format:
            ```
                {
                  "type": "start",
                  "encoding": "linear16", // 16-bit raw PCM format
                  "container": "raw",
                  "sampleRate": {{sampleRate}},
                  "channels": 2 // customer is channel 0, assistant is channel 1
                }
            ```

            3. Vapi will send the audio data in 16-bit raw PCM format as binary frames.

            4. You can read the messages something like this:
            ```
            ws.on('message', (data, isBinary) => {
              if (isBinary) {
                pcmBuffer = Buffer.concat([pcmBuffer, data]);
                console.log(`Received PCM data, buffer size: ${pcmBuffer.length}`);
              } else {
                console.log('Received message:', JSON.parse(data.toString()));
              }
            });
            ```

            5. You will respond with transcriptions as you have them. Format:
            ```
             {
                "type": "transcriber-response",
                "transcription": "Hello, world!",
                "channel": "customer" | "assistant"
             }
            ```
          allOf:
          - $ref: '#/components/schemas/Server'
        fallbackPlan:
          description: This is the plan for voice provider fallbacks in the event that the primary voice provider fails.
          allOf:
          - $ref: '#/components/schemas/FallbackTranscriberPlan'
    DeepgramTranscriber:
      required:
      - provider
      type: object
      properties:
        provider:
          type: string
          description: This is the transcription provider that will be used.
          enum:
          - deepgram
        model:
          description: "This is the Deepgram model that will be used. A list of models can be found here: https://developers.deepgram.com/docs/models-languages-overview"
          oneOf:
          - type: string
            enum:
            - nova-3
            - nova-3-general
            - nova-3-medical
            - nova-2
            - nova-2-general
            - nova-2-meeting
            - nova-2-phonecall
            - nova-2-finance
            - nova-2-conversationalai
            - nova-2-voicemail
            - nova-2-video
            - nova-2-medical
            - nova-2-drivethru
            - nova-2-automotive
            - nova
            - nova-general
            - nova-phonecall
            - nova-medical
            - enhanced
            - enhanced-general
            - enhanced-meeting
            - enhanced-phonecall
            - enhanced-finance
            - base
            - base-general
            - base-meeting
            - base-phonecall
            - base-finance
            - base-conversationalai
            - base-voicemail
            - base-video
          - type: string
        language:
          type: string
          description: "This is the language that will be set for the transcription. The list of languages Deepgram supports can be found here: https://developers.deepgram.com/docs/models-languages-overview"
          enum:
          - bg
          - ca
          - cs
          - da
          - da-DK
          - de
          - de-CH
          - el
          - en
          - en-AU
          - en-GB
          - en-IN
          - en-NZ
          - en-US
          - es
          - es-419
          - es-LATAM
          - et
          - fi
          - fr
          - fr-CA
          - hi
          - hi-Latn
          - hu
          - id
          - it
          - ja
          - ko
          - ko-KR
          - lt
          - lv
          - ms
          - multi
          - nl
          - nl-BE
          - "no"
          - pl
          - pt
          - pt-BR
          - ro
          - ru
          - sk
          - sv
          - sv-SE
          - ta
          - taq
          - th
          - th-TH
          - tr
          - uk
          - vi
          - zh
          - zh-CN
          - zh-HK
          - zh-Hans
          - zh-Hant
          - zh-TW
        smartFormat:
          type: boolean
          description: This will be use smart format option provided by Deepgram. It's default disabled because it can sometimes format numbers as times but it's getting better.
          example: false
        codeSwitchingEnabled:
          type: boolean
          description: |-
            This automatically switches the transcriber's language when the customer's language changes. Defaults to false.

            Usage:
            - If your customers switch languages mid-call, you can set this to true.

            Note:
            - To detect language changes, Vapi uses a custom trained model. Languages supported (X = limited support):
              1. Arabic
              2. Bengali
              3. Cantonese
              4. Chinese
              5. Chinese Simplified (X)
              6. Chinese Traditional (X)
              7. English
              8. Farsi (X)
              9. French
              10. German
              11. Haitian Creole (X)
              12. Hindi
              13. Italian
              14. Japanese
              15. Korean
              16. Portuguese
              17. Russian
              18. Spanish
              19. Thai
              20. Urdu
              21. Vietnamese
            - To receive `language-change-detected` webhook events, add it to `assistant.serverMessages`.

            @default false
          example: false
        mipOptOut:
          type: boolean
          description: |-
            If set to true, this will add mip_opt_out=true as a query parameter of all API requests. See https://developers.deepgram.com/docs/the-deepgram-model-improvement-partnership-program#want-to-opt-out

            This will only be used if you are using your own Deepgram API key.

            @default false
          example: false
          default: false
        numerals:
          type: boolean
          description: |-
            If set to true, this will cause deepgram to convert spoken numbers to literal numerals. For example, "my phone number is nine-seven-two..." would become "my phone number is 972..."

            @default false
          example: false
        confidenceThreshold:
          maximum: 1
          minimum: 0
          type: number
          description: |-
            Transcripts below this confidence threshold will be discarded.

            @default 0.4
          example: 0.4
        keywords:
          type: array
          description: "These keywords are passed to the transcription model to help it pick up use-case specific words. Anything that may not be a common word, like your company name, should be added here."
          items:
            pattern: "/^\\p{L}[\\p{L}\\d]*(?::[+-]?\\d+)?$/u"
            type: string
        keyterm:
          type: array
          description: Keyterm Prompting allows you improve Keyword Recall Rate (KRR) for important keyterms or phrases up to 90%.
          items:
            type: string
        endpointing:
          maximum: 500
          minimum: 10
          type: number
          description: |-
            This is the timeout after which Deepgram will send transcription on user silence. You can read in-depth documentation here: https://developers.deepgram.com/docs/endpointing.

            Here are the most important bits:
            - Defaults to 10. This is recommended for most use cases to optimize for latency.
            - 10 can cause some missing transcriptions since because of the shorter context. This mostly happens for one-word utterances. For those uses cases, it's recommended to try 300. It will add a bit of latency but the quality and reliability of the experience will be better.
            - If neither 10 nor 300 work, contact support@vapi.ai and we'll find another solution.

            @default 10
        fallbackPlan:
          description: This is the plan for voice provider fallbacks in the event that the primary voice provider fails.
          allOf:
          - $ref: '#/components/schemas/FallbackTranscriberPlan'
    ElevenLabsTranscriber:
      required:
      - provider
      type: object
      properties:
        provider:
          type: string
          description: This is the transcription provider that will be used.
          enum:
          - 11labs
        model:
          type: string
          description: This is the model that will be used for the transcription.
          enum:
          - scribe_v1
        language:
          type: string
          enum:
          - aa
          - ab
          - ae
          - af
          - ak
          - am
          - an
          - ar
          - as
          - av
          - ay
          - az
          - ba
          - be
          - bg
          - bh
          - bi
          - bm
          - bn
          - bo
          - br
          - bs
          - ca
          - ce
          - ch
          - co
          - cr
          - cs
          - cu
          - cv
          - cy
          - da
          - de
          - dv
          - dz
          - ee
          - el
          - en
          - eo
          - es
          - et
          - eu
          - fa
          - ff
          - fi
          - fj
          - fo
          - fr
          - fy
          - ga
          - gd
          - gl
          - gn
          - gu
          - gv
          - ha
          - he
          - hi
          - ho
          - hr
          - ht
          - hu
          - hy
          - hz
          - ia
          - id
          - ie
          - ig
          - ii
          - ik
          - io
          - is
          - it
          - iu
          - ja
          - jv
          - ka
          - kg
          - ki
          - kj
          - kk
          - kl
          - km
          - kn
          - ko
          - kr
          - ks
          - ku
          - kv
          - kw
          - ky
          - la
          - lb
          - lg
          - li
          - ln
          - lo
          - lt
          - lu
          - lv
          - mg
          - mh
          - mi
          - mk
          - ml
          - mn
          - mr
          - ms
          - mt
          - my
          - na
          - nb
          - nd
          - ne
          - ng
          - nl
          - nn
          - "no"
          - nr
          - nv
          - ny
          - oc
          - oj
          - om
          - or
          - os
          - pa
          - pi
          - pl
          - ps
          - pt
          - qu
          - rm
          - rn
          - ro
          - ru
          - rw
          - sa
          - sc
          - sd
          - se
          - sg
          - si
          - sk
          - sl
          - sm
          - sn
          - so
          - sq
          - sr
          - ss
          - st
          - su
          - sv
          - sw
          - ta
          - te
          - tg
          - th
          - ti
          - tk
          - tl
          - tn
          - to
          - tr
          - ts
          - tt
          - tw
          - ty
          - ug
          - uk
          - ur
          - uz
          - ve
          - vi
          - vo
          - wa
          - wo
          - xh
          - yi
          - yue
          - yo
          - za
          - zh
          - zu
        fallbackPlan:
          description: This is the plan for voice provider fallbacks in the event that the primary voice provider fails.
          allOf:
          - $ref: '#/components/schemas/FallbackTranscriberPlan'
    GladiaTranscriber:
      required:
      - provider
      type: object
      properties:
        provider:
          type: string
          description: This is the transcription provider that will be used.
          enum:
          - gladia
        model:
          description: This is the Gladia model that will be used. Default is 'fast'
          oneOf:
          - type: string
            enum:
            - fast
            - accurate
        languageBehaviour:
          description: Defines how the transcription model detects the audio language. Default value is 'automatic single language'.
          oneOf:
          - type: string
            enum:
            - manual
            - automatic single language
            - automatic multiple languages
        language:
          type: string
          description: Defines the language to use for the transcription. Required when languageBehaviour is 'manual'.
          enum:
          - af
          - sq
          - am
          - ar
          - hy
          - as
          - az
          - ba
          - eu
          - be
          - bn
          - bs
          - br
          - bg
          - ca
          - zh
          - hr
          - cs
          - da
          - nl
          - en
          - et
          - fo
          - fi
          - fr
          - gl
          - ka
          - de
          - el
          - gu
          - ht
          - ha
          - haw
          - he
          - hi
          - hu
          - is
          - id
          - it
          - ja
          - jv
          - kn
          - kk
          - km
          - ko
          - lo
          - la
          - lv
          - ln
          - lt
          - lb
          - mk
          - mg
          - ms
          - ml
          - mt
          - mi
          - mr
          - mn
          - my
          - ne
          - "no"
          - nn
          - oc
          - ps
          - fa
          - pl
          - pt
          - pa
          - ro
          - ru
          - sa
          - sr
          - sn
          - sd
          - si
          - sk
          - sl
          - so
          - es
          - su
          - sw
          - sv
          - tl
          - tg
          - ta
          - tt
          - te
          - th
          - bo
          - tr
          - tk
          - uk
          - ur
          - uz
          - vi
          - cy
          - yi
          - yo
        transcriptionHint:
          maxLength: 600
          type: string
          description: |-
            Provides a custom vocabulary to the model to improve accuracy of transcribing context specific words, technical terms, names, etc. If empty, this argument is ignored.
            ⚠️ Warning ⚠️: Please be aware that the transcription_hint field has a character limit of 600. If you provide a transcription_hint longer than 600 characters, it will be automatically truncated to meet this limit.
          example: custom vocabulary
        prosody:
          type: boolean
          description: "If prosody is true, you will get a transcription that can contain prosodies i.e. (laugh) (giggles) (malefic laugh) (toss) (music)… Default value is false."
          example: false
        audioEnhancer:
          type: boolean
          description: "If true, audio will be pre-processed to improve accuracy but latency will increase. Default value is false."
          example: false
        confidenceThreshold:
          maximum: 1
          minimum: 0
          type: number
          description: |-
            Transcripts below this confidence threshold will be discarded.

            @default 0.4
          example: 0.4
        fallbackPlan:
          description: This is the plan for voice provider fallbacks in the event that the primary voice provider fails.
          allOf:
          - $ref: '#/components/schemas/FallbackTranscriberPlan'
    SpeechmaticsTranscriber:
      required:
      - provider
      type: object
      properties:
        provider:
          type: string
          description: This is the transcription provider that will be used.
          enum:
          - speechmatics
        model:
          type: string
          description: This is the model that will be used for the transcription.
          enum:
          - default
        language:
          type: string
          enum:
          - auto
          - ar
          - ba
          - eu
          - be
          - bn
          - bg
          - yue
          - ca
          - hr
          - cs
          - da
          - nl
          - en
          - eo
          - et
          - fi
          - fr
          - gl
          - de
          - el
          - he
          - hi
          - hu
          - id
          - ia
          - ga
          - it
          - ja
          - ko
          - lv
          - lt
          - ms
          - mt
          - cmn
          - mr
          - mn
          - "no"
          - fa
          - pl
          - pt
          - ro
          - ru
          - sk
          - sl
          - es
          - sw
          - sv
          - ta
          - th
          - tr
          - uk
          - ur
          - ug
          - vi
          - cy
        fallbackPlan:
          description: This is the plan for voice provider fallbacks in the event that the primary voice provider fails.
          allOf:
          - $ref: '#/components/schemas/FallbackTranscriberPlan'
    TalkscriberTranscriber:
      required:
      - provider
      type: object
      properties:
        provider:
          type: string
          description: This is the transcription provider that will be used.
          enum:
          - talkscriber
        model:
          type: string
          description: This is the model that will be used for the transcription.
          enum:
          - whisper
        language:
          type: string
          description: "This is the language that will be set for the transcription. The list of languages Whisper supports can be found here: https://github.com/openai/whisper/blob/main/whisper/tokenizer.py"
          enum:
          - en
          - zh
          - de
          - es
          - ru
          - ko
          - fr
          - ja
          - pt
          - tr
          - pl
          - ca
          - nl
          - ar
          - sv
          - it
          - id
          - hi
          - fi
          - vi
          - he
          - uk
          - el
          - ms
          - cs
          - ro
          - da
          - hu
          - ta
          - "no"
          - th
          - ur
          - hr
          - bg
          - lt
          - la
          - mi
          - ml
          - cy
          - sk
          - te
          - fa
          - lv
          - bn
          - sr
          - az
          - sl
          - kn
          - et
          - mk
          - br
          - eu
          - is
          - hy
          - ne
          - mn
          - bs
          - kk
          - sq
          - sw
          - gl
          - mr
          - pa
          - si
          - km
          - sn
          - yo
          - so
          - af
          - oc
          - ka
          - be
          - tg
          - sd
          - gu
          - am
          - yi
          - lo
          - uz
          - fo
          - ht
          - ps
          - tk
          - nn
          - mt
          - sa
          - lb
          - my
          - bo
          - tl
          - mg
          - as
          - tt
          - haw
          - ln
          - ha
          - ba
          - jw
          - su
          - yue
        fallbackPlan:
          description: This is the plan for voice provider fallbacks in the event that the primary voice provider fails.
          allOf:
          - $ref: '#/components/schemas/FallbackTranscriberPlan'
    GoogleTranscriber:
      required:
      - provider
      type: object
      properties:
        provider:
          type: string
          description: This is the transcription provider that will be used.
          enum:
          - google
        model:
          type: string
          description: This is the model that will be used for the transcription.
          enum:
          - gemini-2.0-flash-thinking-exp
          - gemini-2.0-pro-exp-02-05
          - gemini-2.0-flash
          - gemini-2.0-flash-lite
          - gemini-2.0-flash-lite-preview-02-05
          - gemini-2.0-flash-exp
          - gemini-2.0-flash-realtime-exp
          - gemini-1.5-flash
          - gemini-1.5-flash-002
          - gemini-1.5-pro
          - gemini-1.5-pro-002
          - gemini-1.0-pro
        language:
          type: string
          description: This is the language that will be set for the transcription.
          enum:
          - Multilingual
          - Arabic
          - Bengali
          - Bulgarian
          - Chinese
          - Croatian
          - Czech
          - Danish
          - Dutch
          - English
          - Estonian
          - Finnish
          - French
          - German
          - Greek
          - Hebrew
          - Hindi
          - Hungarian
          - Indonesian
          - Italian
          - Japanese
          - Korean
          - Latvian
          - Lithuanian
          - Norwegian
          - Polish
          - Portuguese
          - Romanian
          - Russian
          - Serbian
          - Slovak
          - Slovenian
          - Spanish
          - Swahili
          - Swedish
          - Thai
          - Turkish
          - Ukrainian
          - Vietnamese
        fallbackPlan:
          description: This is the plan for voice provider fallbacks in the event that the primary voice provider fails.
          allOf:
          - $ref: '#/components/schemas/FallbackTranscriberPlan'
    OpenAITranscriber:
      required:
      - model
      - provider
      type: object
      properties:
        provider:
          type: string
          description: This is the transcription provider that will be used.
          enum:
          - openai
        model:
          type: string
          description: This is the model that will be used for the transcription.
          enum:
          - gpt-4o-transcribe
          - gpt-4o-mini-transcribe
        language:
          type: string
          description: This is the language that will be set for the transcription.
          enum:
          - af
          - ar
          - hy
          - az
          - be
          - bs
          - bg
          - ca
          - zh
          - hr
          - cs
          - da
          - nl
          - en
          - et
          - fi
          - fr
          - gl
          - de
          - el
          - he
          - hi
          - hu
          - is
          - id
          - it
          - ja
          - kn
          - kk
          - ko
          - lv
          - lt
          - mk
          - ms
          - mr
          - mi
          - ne
          - "no"
          - fa
          - pl
          - pt
          - ro
          - ru
          - sr
          - sk
          - sl
          - es
          - sw
          - sv
          - tl
          - ta
          - th
          - tr
          - uk
          - ur
          - vi
          - cy
        fallbackPlan:
          description: This is the plan for voice provider fallbacks in the event that the primary voice provider fails.
          allOf:
          - $ref: '#/components/schemas/FallbackTranscriberPlan'
    FallbackAssemblyAITranscriber:
      required:
      - provider
      type: object
      properties:
        provider:
          type: string
          description: This is the transcription provider that will be used.
          enum:
          - assembly-ai
        language:
          type: string
          description: This is the language that will be set for the transcription.
          enum:
          - en
        confidenceThreshold:
          maximum: 1
          minimum: 0
          type: number
          description: |-
            Transcripts below this confidence threshold will be discarded.

            @default 0.4
          example: 0.4
        realtimeUrl:
          type: string
          description: The WebSocket URL that the transcriber connects to.
        wordBoost:
          type: array
          description: Add up to 2500 characters of custom vocabulary.
          items:
            maxLength: 2500
            type: string
        endUtteranceSilenceThreshold:
          type: number
          description: The duration of the end utterance silence threshold in milliseconds.
        disablePartialTranscripts:
          type: boolean
          description: |-
            Disable partial transcripts.
            Set to `true` to not receive partial transcripts. Defaults to `false`.
    FallbackAzureSpeechTranscriber:
      required:
      - provider
      type: object
      properties:
        provider:
          type: string
          description: This is the transcription provider that will be used.
          enum:
          - azure
        language:
          type: string
          description: "This is the language that will be set for the transcription. The list of languages Azure supports can be found here: https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=stt"
          enum:
          - af-ZA
          - am-ET
          - ar-AE
          - ar-BH
          - ar-DZ
          - ar-EG
          - ar-IL
          - ar-IQ
          - ar-JO
          - ar-KW
          - ar-LB
          - ar-LY
          - ar-MA
          - ar-OM
          - ar-PS
          - ar-QA
          - ar-SA
          - ar-SY
          - ar-TN
          - ar-YE
          - az-AZ
          - bg-BG
          - bn-IN
          - bs-BA
          - ca-ES
          - cs-CZ
          - cy-GB
          - da-DK
          - de-AT
          - de-CH
          - de-DE
          - el-GR
          - en-AU
          - en-CA
          - en-GB
          - en-GH
          - en-HK
          - en-IE
          - en-IN
          - en-KE
          - en-NG
          - en-NZ
          - en-PH
          - en-SG
          - en-TZ
          - en-US
          - en-ZA
          - es-AR
          - es-BO
          - es-CL
          - es-CO
          - es-CR
          - es-CU
          - es-DO
          - es-EC
          - es-ES
          - es-GQ
          - es-GT
          - es-HN
          - es-MX
          - es-NI
          - es-PA
          - es-PE
          - es-PR
          - es-PY
          - es-SV
          - es-US
          - es-UY
          - es-VE
          - et-EE
          - eu-ES
          - fa-IR
          - fi-FI
          - fil-PH
          - fr-BE
          - fr-CA
          - fr-CH
          - fr-FR
          - ga-IE
          - gl-ES
          - gu-IN
          - he-IL
          - hi-IN
          - hr-HR
          - hu-HU
          - hy-AM
          - id-ID
          - is-IS
          - it-CH
          - it-IT
          - ja-JP
          - jv-ID
          - ka-GE
          - kk-KZ
          - km-KH
          - kn-IN
          - ko-KR
          - lo-LA
          - lt-LT
          - lv-LV
          - mk-MK
          - ml-IN
          - mn-MN
          - mr-IN
          - ms-MY
          - mt-MT
          - my-MM
          - nb-NO
          - ne-NP
          - nl-BE
          - nl-NL
          - pa-IN
          - pl-PL
          - ps-AF
          - pt-BR
          - pt-PT
          - ro-RO
          - ru-RU
          - si-LK
          - sk-SK
          - sl-SI
          - so-SO
          - sq-AL
          - sr-RS
          - sv-SE
          - sw-KE
          - sw-TZ
          - ta-IN
          - te-IN
          - th-TH
          - tr-TR
          - uk-UA
          - ur-IN
          - uz-UZ
          - vi-VN
          - wuu-CN
          - yue-CN
          - zh-CN
          - zh-CN-shandong
          - zh-CN-sichuan
          - zh-HK
          - zh-TW
          - zu-ZA
    FallbackCustomTranscriber:
      required:
      - provider
      - server
      type: object
      properties:
        provider:
          type: string
          description: This is the transcription provider that will be used. Use `custom-transcriber` for providers that are not natively supported.
          enum:
          - custom-transcriber
        server:
          description: |-
            This is where the transcription request will be sent.

            Usage:
            1. Vapi will initiate a websocket connection with `server.url`.

            2. Vapi will send an initial text frame with the sample rate. Format:
            ```
                {
                  "type": "start",
                  "encoding": "linear16", // 16-bit raw PCM format
                  "container": "raw",
                  "sampleRate": {{sampleRate}},
                  "channels": 2 // customer is channel 0, assistant is channel 1
                }
            ```

            3. Vapi will send the audio data in 16-bit raw PCM format as binary frames.

            4. You can read the messages something like this:
            ```
            ws.on('message', (data, isBinary) => {
              if (isBinary) {
                pcmBuffer = Buffer.concat([pcmBuffer, data]);
                console.log(`Received PCM data, buffer size: ${pcmBuffer.length}`);
              } else {
                console.log('Received message:', JSON.parse(data.toString()));
              }
            });
            ```

            5. You will respond with transcriptions as you have them. Format:
            ```
             {
                "type": "transcriber-response",
                "transcription": "Hello, world!",
                "channel": "customer" | "assistant"
             }
            ```
          allOf:
          - $ref: '#/components/schemas/Server'
    FallbackDeepgramTranscriber:
      required:
      - provider
      type: object
      properties:
        provider:
          type: string
          description: This is the transcription provider that will be used.
          enum:
          - deepgram
        model:
          description: "This is the Deepgram model that will be used. A list of models can be found here: https://developers.deepgram.com/docs/models-languages-overview"
          oneOf:
          - type: string
            enum:
            - nova-3
            - nova-3-general
            - nova-3-medical
            - nova-2
            - nova-2-general
            - nova-2-meeting
            - nova-2-phonecall
            - nova-2-finance
            - nova-2-conversationalai
            - nova-2-voicemail
            - nova-2-video
            - nova-2-medical
            - nova-2-drivethru
            - nova-2-automotive
            - nova
            - nova-general
            - nova-phonecall
            - nova-medical
            - enhanced
            - enhanced-general
            - enhanced-meeting
            - enhanced-phonecall
            - enhanced-finance
            - base
            - base-general
            - base-meeting
            - base-phonecall
            - base-finance
            - base-conversationalai
            - base-voicemail
            - base-video
          - type: string
        language:
          type: string
          description: "This is the language that will be set for the transcription. The list of languages Deepgram supports can be found here: https://developers.deepgram.com/docs/models-languages-overview"
          enum:
          - bg
          - ca
          - cs
          - da
          - da-DK
          - de
          - de-CH
          - el
          - en
          - en-AU
          - en-GB
          - en-IN
          - en-NZ
          - en-US
          - es
          - es-419
          - es-LATAM
          - et
          - fi
          - fr
          - fr-CA
          - hi
          - hi-Latn
          - hu
          - id
          - it
          - ja
          - ko
          - ko-KR
          - lt
          - lv
          - ms
          - multi
          - nl
          - nl-BE
          - "no"
          - pl
          - pt
          - pt-BR
          - ro
          - ru
          - sk
          - sv
          - sv-SE
          - ta
          - taq
          - th
          - th-TH
          - tr
          - uk
          - vi
          - zh
          - zh-CN
          - zh-HK
          - zh-Hans
          - zh-Hant
          - zh-TW
        smartFormat:
          type: boolean
          description: This will be use smart format option provided by Deepgram. It's default disabled because it can sometimes format numbers as times but it's getting better.
          example: false
        codeSwitchingEnabled:
          type: boolean
          description: |-
            This automatically switches the transcriber's language when the customer's language changes. Defaults to false.

            Usage:
            - If your customers switch languages mid-call, you can set this to true.

            Note:
            - To detect language changes, Vapi uses a custom trained model. Languages supported (X = limited support):
              1. Arabic
              2. Bengali
              3. Cantonese
              4. Chinese
              5. Chinese Simplified (X)
              6. Chinese Traditional (X)
              7. English
              8. Farsi (X)
              9. French
              10. German
              11. Haitian Creole (X)
              12. Hindi
              13. Italian
              14. Japanese
              15. Korean
              16. Portuguese
              17. Russian
              18. Spanish
              19. Thai
              20. Urdu
              21. Vietnamese
            - To receive `language-change-detected` webhook events, add it to `assistant.serverMessages`.

            @default false
          example: false
        mipOptOut:
          type: boolean
          description: |-
            If set to true, this will add mip_opt_out=true as a query parameter of all API requests. See https://developers.deepgram.com/docs/the-deepgram-model-improvement-partnership-program#want-to-opt-out

            This will only be used if you are using your own Deepgram API key.

            @default false
          example: false
          default: false
        numerals:
          type: boolean
          description: |-
            If set to true, this will cause deepgram to convert spoken numbers to literal numerals. For example, "my phone number is nine-seven-two..." would become "my phone number is 972..."

            @default false
          example: false
        confidenceThreshold:
          maximum: 1
          minimum: 0
          type: number
          description: |-
            Transcripts below this confidence threshold will be discarded.

            @default 0.4
          example: 0.4
        keywords:
          type: array
          description: "These keywords are passed to the transcription model to help it pick up use-case specific words. Anything that may not be a common word, like your company name, should be added here."
          items:
            pattern: "/^\\p{L}[\\p{L}\\d]*(?::[+-]?\\d+)?$/u"
            type: string
        keyterm:
          type: array
          description: Keyterm Prompting allows you improve Keyword Recall Rate (KRR) for important keyterms or phrases up to 90%.
          items:
            type: string
        endpointing:
          maximum: 500
          minimum: 10
          type: number
          description: |-
            This is the timeout after which Deepgram will send transcription on user silence. You can read in-depth documentation here: https://developers.deepgram.com/docs/endpointing.

            Here are the most important bits:
            - Defaults to 10. This is recommended for most use cases to optimize for latency.
            - 10 can cause some missing transcriptions since because of the shorter context. This mostly happens for one-word utterances. For those uses cases, it's recommended to try 300. It will add a bit of latency but the quality and reliability of the experience will be better.
            - If neither 10 nor 300 work, contact support@vapi.ai and we'll find another solution.

            @default 10
    FallbackElevenLabsTranscriber:
      required:
      - provider
      type: object
      properties:
        provider:
          type: string
          description: This is the transcription provider that will be used.
          enum:
          - 11labs
        model:
          type: string
          description: This is the model that will be used for the transcription.
          enum:
          - scribe_v1
        language:
          type: string
          enum:
          - aa
          - ab
          - ae
          - af
          - ak
          - am
          - an
          - ar
          - as
          - av
          - ay
          - az
          - ba
          - be
          - bg
          - bh
          - bi
          - bm
          - bn
          - bo
          - br
          - bs
          - ca
          - ce
          - ch
          - co
          - cr
          - cs
          - cu
          - cv
          - cy
          - da
          - de
          - dv
          - dz
          - ee
          - el
          - en
          - eo
          - es
          - et
          - eu
          - fa
          - ff
          - fi
          - fj
          - fo
          - fr
          - fy
          - ga
          - gd
          - gl
          - gn
          - gu
          - gv
          - ha
          - he
          - hi
          - ho
          - hr
          - ht
          - hu
          - hy
          - hz
          - ia
          - id
          - ie
          - ig
          - ii
          - ik
          - io
          - is
          - it
          - iu
          - ja
          - jv
          - ka
          - kg
          - ki
          - kj
          - kk
          - kl
          - km
          - kn
          - ko
          - kr
          - ks
          - ku
          - kv
          - kw
          - ky
          - la
          - lb
          - lg
          - li
          - ln
          - lo
          - lt
          - lu
          - lv
          - mg
          - mh
          - mi
          - mk
          - ml
          - mn
          - mr
          - ms
          - mt
          - my
          - na
          - nb
          - nd
          - ne
          - ng
          - nl
          - nn
          - "no"
          - nr
          - nv
          - ny
          - oc
          - oj
          - om
          - or
          - os
          - pa
          - pi
          - pl
          - ps
          - pt
          - qu
          - rm
          - rn
          - ro
          - ru
          - rw
          - sa
          - sc
          - sd
          - se
          - sg
          - si
          - sk
          - sl
          - sm
          - sn
          - so
          - sq
          - sr
          - ss
          - st
          - su
          - sv
          - sw
          - ta
          - te
          - tg
          - th
          - ti
          - tk
          - tl
          - tn
          - to
          - tr
          - ts
          - tt
          - tw
          - ty
          - ug
          - uk
          - ur
          - uz
          - ve
          - vi
          - vo
          - wa
          - wo
          - xh
          - yi
          - yue
          - yo
          - za
          - zh
          - zu
    FallbackGladiaTranscriber:
      required:
      - provider
      type: object
      properties:
        provider:
          type: string
          description: This is the transcription provider that will be used.
          enum:
          - gladia
        model:
          description: This is the Gladia model that will be used. Default is 'fast'
          oneOf:
          - type: string
            enum:
            - fast
            - accurate
        languageBehaviour:
          description: Defines how the transcription model detects the audio language. Default value is 'automatic single language'.
          oneOf:
          - type: string
            enum:
            - manual
            - automatic single language
            - automatic multiple languages
        language:
          type: string
          description: Defines the language to use for the transcription. Required when languageBehaviour is 'manual'.
          enum:
          - af
          - sq
          - am
          - ar
          - hy
          - as
          - az
          - ba
          - eu
          - be
          - bn
          - bs
          - br
          - bg
          - ca
          - zh
          - hr
          - cs
          - da
          - nl
          - en
          - et
          - fo
          - fi
          - fr
          - gl
          - ka
          - de
          - el
          - gu
          - ht
          - ha
          - haw
          - he
          - hi
          - hu
          - is
          - id
          - it
          - ja
          - jv
          - kn
          - kk
          - km
          - ko
          - lo
          - la
          - lv
          - ln
          - lt
          - lb
          - mk
          - mg
          - ms
          - ml
          - mt
          - mi
          - mr
          - mn
          - my
          - ne
          - "no"
          - nn
          - oc
          - ps
          - fa
          - pl
          - pt
          - pa
          - ro
          - ru
          - sa
          - sr
          - sn
          - sd
          - si
          - sk
          - sl
          - so
          - es
          - su
          - sw
          - sv
          - tl
          - tg
          - ta
          - tt
          - te
          - th
          - bo
          - tr
          - tk
          - uk
          - ur
          - uz
          - vi
          - cy
          - yi
          - yo
        transcriptionHint:
          maxLength: 600
          type: string
          description: |-
            Provides a custom vocabulary to the model to improve accuracy of transcribing context specific words, technical terms, names, etc. If empty, this argument is ignored.
            ⚠️ Warning ⚠️: Please be aware that the transcription_hint field has a character limit of 600. If you provide a transcription_hint longer than 600 characters, it will be automatically truncated to meet this limit.
          example: custom vocabulary
        prosody:
          type: boolean
          description: "If prosody is true, you will get a transcription that can contain prosodies i.e. (laugh) (giggles) (malefic laugh) (toss) (music)… Default value is false."
          example: false
        audioEnhancer:
          type: boolean
          description: "If true, audio will be pre-processed to improve accuracy but latency will increase. Default value is false."
          example: false
        confidenceThreshold:
          maximum: 1
          minimum: 0
          type: number
          description: |-
            Transcripts below this confidence threshold will be discarded.

            @default 0.4
          example: 0.4
    FallbackSpeechmaticsTranscriber:
      required:
      - provider
      type: object
      properties:
        provider:
          type: string
          description: This is the transcription provider that will be used.
          enum:
          - speechmatics
        model:
          type: string
          description: This is the model that will be used for the transcription.
          enum:
          - default
        language:
          type: string
          enum:
          - auto
          - ar
          - ba
          - eu
          - be
          - bn
          - bg
          - yue
          - ca
          - hr
          - cs
          - da
          - nl
          - en
          - eo
          - et
          - fi
          - fr
          - gl
          - de
          - el
          - he
          - hi
          - hu
          - id
          - ia
          - ga
          - it
          - ja
          - ko
          - lv
          - lt
          - ms
          - mt
          - cmn
          - mr
          - mn
          - "no"
          - fa
          - pl
          - pt
          - ro
          - ru
          - sk
          - sl
          - es
          - sw
          - sv
          - ta
          - th
          - tr
          - uk
          - ur
          - ug
          - vi
          - cy
    FallbackTalkscriberTranscriber:
      required:
      - provider
      type: object
      properties:
        provider:
          type: string
          description: This is the transcription provider that will be used.
          enum:
          - talkscriber
        model:
          type: string
          description: This is the model that will be used for the transcription.
          enum:
          - whisper
        language:
          type: string
          description: "This is the language that will be set for the transcription. The list of languages Whisper supports can be found here: https://github.com/openai/whisper/blob/main/whisper/tokenizer.py"
          enum:
          - en
          - zh
          - de
          - es
          - ru
          - ko
          - fr
          - ja
          - pt
          - tr
          - pl
          - ca
          - nl
          - ar
          - sv
          - it
          - id
          - hi
          - fi
          - vi
          - he
          - uk
          - el
          - ms
          - cs
          - ro
          - da
          - hu
          - ta
          - "no"
          - th
          - ur
          - hr
          - bg
          - lt
          - la
          - mi
          - ml
          - cy
          - sk
          - te
          - fa
          - lv
          - bn
          - sr
          - az
          - sl
          - kn
          - et
          - mk
          - br
          - eu
          - is
          - hy
          - ne
          - mn
          - bs
          - kk
          - sq
          - sw
          - gl
          - mr
          - pa
          - si
          - km
          - sn
          - yo
          - so
          - af
          - oc
          - ka
          - be
          - tg
          - sd
          - gu
          - am
          - yi
          - lo
          - uz
          - fo
          - ht
          - ps
          - tk
          - nn
          - mt
          - sa
          - lb
          - my
          - bo
          - tl
          - mg
          - as
          - tt
          - haw
          - ln
          - ha
          - ba
          - jw
          - su
          - yue
    FallbackGoogleTranscriber:
      required:
      - provider
      type: object
      properties:
        provider:
          type: string
          description: This is the transcription provider that will be used.
          enum:
          - google
        model:
          type: string
          description: This is the model that will be used for the transcription.
          enum:
          - gemini-2.0-flash-thinking-exp
          - gemini-2.0-pro-exp-02-05
          - gemini-2.0-flash
          - gemini-2.0-flash-lite
          - gemini-2.0-flash-lite-preview-02-05
          - gemini-2.0-flash-exp
          - gemini-2.0-flash-realtime-exp
          - gemini-1.5-flash
          - gemini-1.5-flash-002
          - gemini-1.5-pro
          - gemini-1.5-pro-002
          - gemini-1.0-pro
        language:
          type: string
          description: This is the language that will be set for the transcription.
          enum:
          - Multilingual
          - Arabic
          - Bengali
          - Bulgarian
          - Chinese
          - Croatian
          - Czech
          - Danish
          - Dutch
          - English
          - Estonian
          - Finnish
          - French
          - German
          - Greek
          - Hebrew
          - Hindi
          - Hungarian
          - Indonesian
          - Italian
          - Japanese
          - Korean
          - Latvian
          - Lithuanian
          - Norwegian
          - Polish
          - Portuguese
          - Romanian
          - Russian
          - Serbian
          - Slovak
          - Slovenian
          - Spanish
          - Swahili
          - Swedish
          - Thai
          - Turkish
          - Ukrainian
          - Vietnamese
    FallbackOpenAITranscriber:
      required:
      - model
      - provider
      type: object
      properties:
        provider:
          type: string
          description: This is the transcription provider that will be used.
          enum:
          - openai
        model:
          type: string
          description: This is the model that will be used for the transcription.
          enum:
          - gpt-4o-transcribe
          - gpt-4o-mini-transcribe
        language:
          type: string
          description: This is the language that will be set for the transcription.
          enum:
          - af
          - ar
          - hy
          - az
          - be
          - bs
          - bg
          - ca
          - zh
          - hr
          - cs
          - da
          - nl
          - en
          - et
          - fi
          - fr
          - gl
          - de
          - el
          - he
          - hi
          - hu
          - is
          - id
          - it
          - ja
          - kn
          - kk
          - ko
          - lv
          - lt
          - mk
          - ms
          - mr
          - mi
          - ne
          - "no"
          - fa
          - pl
          - pt
          - ro
          - ru
          - sr
          - sk
          - sl
          - es
          - sw
          - sv
          - tl
          - ta
          - th
          - tr
          - uk
          - ur
          - vi
          - cy
    LangfuseObservabilityPlan:
      required:
      - provider
      - tags
      type: object
      properties:
        provider:
          type: string
          enum:
          - langfuse
        tags:
          type: array
          description: This is an array of tags to be added to the Langfuse trace. Tags allow you to categorize and filter traces. https://langfuse.com/docs/tracing-features/tags
          items:
            type: string
        metadata:
          type: object
          description: |-
            This is a JSON object that will be added to the Langfuse trace. Traces can be enriched with metadata to better understand your users, application, and experiments. https://langfuse.com/docs/tracing-features/metadata
            By default it includes the call metadata, assistant metadata, and assistant overrides.
    TextContent:
      required:
      - language
      - text
      - type
      type: object
      properties:
        type:
          type: string
          enum:
          - text
        text:
          type: string
        language:
          type: string
          enum:
          - aa
          - ab
          - ae
          - af
          - ak
          - am
          - an
          - ar
          - as
          - av
          - ay
          - az
          - ba
          - be
          - bg
          - bh
          - bi
          - bm
          - bn
          - bo
          - br
          - bs
          - ca
          - ce
          - ch
          - co
          - cr
          - cs
          - cu
          - cv
          - cy
          - da
          - de
          - dv
          - dz
          - ee
          - el
          - en
          - eo
          - es
          - et
          - eu
          - fa
          - ff
          - fi
          - fj
          - fo
          - fr
          - fy
          - ga
          - gd
          - gl
          - gn
          - gu
          - gv
          - ha
          - he
          - hi
          - ho
          - hr
          - ht
          - hu
          - hy
          - hz
          - ia
          - id
          - ie
          - ig
          - ii
          - ik
          - io
          - is
          - it
          - iu
          - ja
          - jv
          - ka
          - kg
          - ki
          - kj
          - kk
          - kl
          - km
          - kn
          - ko
          - kr
          - ks
          - ku
          - kv
          - kw
          - ky
          - la
          - lb
          - lg
          - li
          - ln
          - lo
          - lt
          - lu
          - lv
          - mg
          - mh
          - mi
          - mk
          - ml
          - mn
          - mr
          - ms
          - mt
          - my
          - na
          - nb
          - nd
          - ne
          - ng
          - nl
          - nn
          - "no"
          - nr
          - nv
          - ny
          - oc
          - oj
          - om
          - or
          - os
          - pa
          - pi
          - pl
          - ps
          - pt
          - qu
          - rm
          - rn
          - ro
          - ru
          - rw
          - sa
          - sc
          - sd
          - se
          - sg
          - si
          - sk
          - sl
          - sm
          - sn
          - so
          - sq
          - sr
          - ss
          - st
          - su
          - sv
          - sw
          - ta
          - te
          - tg
          - th
          - ti
          - tk
          - tl
          - tn
          - to
          - tr
          - ts
          - tt
          - tw
          - ty
          - ug
          - uk
          - ur
          - uz
          - ve
          - vi
          - vo
          - wa
          - wo
          - xh
          - yi
          - yue
          - yo
          - za
          - zh
          - zu
    Condition:
      required:
      - operator
      - param
      - value
      type: object
      properties:
        operator:
          type: string
          description: This is the operator you want to use to compare the parameter and value.
          enum:
          - eq
          - neq
          - gt
          - gte
          - lt
          - lte
        param:
          maxLength: 1000
          type: string
          description: This is the name of the parameter that you want to check.
        value:
          maxLength: 1000
          type: object
          description: This is the value you want to compare against the parameter.
    ToolMessageStart:
      required:
      - type
      type: object
      properties:
        contents:
          type: array
          description: |-
            This is an alternative to the `content` property. It allows to specify variants of the same content, one per language.

            Usage:
            - If your assistants are multilingual, you can provide content for each language.
            - If you don't provide content for a language, the first item in the array will be automatically translated to the active language at that moment.

            This will override the `content` property.
          items:
            oneOf:
            - $ref: '#/components/schemas/TextContent'
        type:
          type: string
          description: |-
            This message is triggered when the tool call starts.

            This message is never triggered for async tools.

            If this message is not provided, one of the default filler messages "Hold on a sec", "One moment", "Just a sec", "Give me a moment" or "This'll just take a sec" will be used.
          enum:
          - request-start
        blocking:
          type: boolean
          description: |-
            This is an optional boolean that if true, the tool call will only trigger after the message is spoken. Default is false.

            @default false
          example: false
          default: false
        content:
          maxLength: 1000
          type: string
          description: This is the content that the assistant says when this message is triggered.
        conditions:
          type: array
          description: This is an optional array of conditions that the tool call arguments must meet in order for this message to be triggered.
          items:
            $ref: '#/components/schemas/Condition'
    ToolMessageComplete:
      required:
      - type
      type: object
      properties:
        contents:
          type: array
          description: |-
            This is an alternative to the `content` property. It allows to specify variants of the same content, one per language.

            Usage:
            - If your assistants are multilingual, you can provide content for each language.
            - If you don't provide content for a language, the first item in the array will be automatically translated to the active language at that moment.

            This will override the `content` property.
          items:
            oneOf:
            - $ref: '#/components/schemas/TextContent'
        type:
          type: string
          description: |-
            This message is triggered when the tool call is complete.

            This message is triggered immediately without waiting for your server to respond for async tool calls.

            If this message is not provided, the model will be requested to respond.

            If this message is provided, only this message will be spoken and the model will not be requested to come up with a response. It's an exclusive OR.
          enum:
          - request-complete
        role:
          type: string
          description: |-
            This is optional and defaults to "assistant".

            When role=assistant, `content` is said out loud.

            When role=system, `content` is passed to the model in a system message. Example:
                system: default one
                assistant:
                user:
                assistant:
                user:
                assistant:
                user:
                assistant: tool called
                tool: your server response
                <--- system prompt as hint
                ---> model generates response which is spoken
            This is useful when you want to provide a hint to the model about what to say next.
          enum:
          - assistant
          - system
        endCallAfterSpokenEnabled:
          type: boolean
          description: |-
            This is an optional boolean that if true, the call will end after the message is spoken. Default is false.

            This is ignored if `role` is set to `system`.

            @default false
          example: false
        content:
          maxLength: 1000
          type: string
          description: This is the content that the assistant says when this message is triggered.
        conditions:
          type: array
          description: This is an optional array of conditions that the tool call arguments must meet in order for this message to be triggered.
          items:
            $ref: '#/components/schemas/Condition'
    ToolMessageFailed:
      required:
      - type
      type: object
      properties:
        contents:
          type: array
          description: |-
            This is an alternative to the `content` property. It allows to specify variants of the same content, one per language.

            Usage:
            - If your assistants are multilingual, you can provide content for each language.
            - If you don't provide content for a language, the first item in the array will be automatically translated to the active language at that moment.

            This will override the `content` property.
          items:
            oneOf:
            - $ref: '#/components/schemas/TextContent'
        type:
          type: string
          description: |-
            This message is triggered when the tool call fails.

            This message is never triggered for async tool calls.

            If this message is not provided, the model will be requested to respond.

            If this message is provided, only this message will be spoken and the model will not be requested to come up with a response. It's an exclusive OR.
          enum:
          - request-failed
        endCallAfterSpokenEnabled:
          type: boolean
          description: |-
            This is an optional boolean that if true, the call will end after the message is spoken. Default is false.

            @default false
          example: false
        content:
          maxLength: 1000
          type: string
          description: This is the content that the assistant says when this message is triggered.
        conditions:
          type: array
          description: This is an optional array of conditions that the tool call arguments must meet in order for this message to be triggered.
          items:
            $ref: '#/components/schemas/Condition'
    ToolMessageDelayed:
      required:
      - type
      type: object
      properties:
        contents:
          type: array
          description: |-
            This is an alternative to the `content` property. It allows to specify variants of the same content, one per language.

            Usage:
            - If your assistants are multilingual, you can provide content for each language.
            - If you don't provide content for a language, the first item in the array will be automatically translated to the active language at that moment.

            This will override the `content` property.
          items:
            oneOf:
            - $ref: '#/components/schemas/TextContent'
        type:
          type: string
          description: |-
            This message is triggered when the tool call is delayed.

            There are the two things that can trigger this message:
            1. The user talks with the assistant while your server is processing the request. Default is "Sorry, a few more seconds."
            2. The server doesn't respond within `timingMilliseconds`.

            This message is never triggered for async tool calls.
          enum:
          - request-response-delayed
        timingMilliseconds:
          maximum: 120000
          minimum: 100
          type: number
          description: The number of milliseconds to wait for the server response before saying this message.
          example: 1000
        content:
          maxLength: 1000
          type: string
          description: This is the content that the assistant says when this message is triggered.
        conditions:
          type: array
          description: This is an optional array of conditions that the tool call arguments must meet in order for this message to be triggered.
          items:
            $ref: '#/components/schemas/Condition'
    JsonSchema:
      required:
      - type
      type: object
      properties:
        type:
          type: string
          description: |-
            This is the type of output you'd like.

            `string`, `number`, `integer`, `boolean` are the primitive types and should be obvious.

            `array` and `object` are more interesting and quite powerful. They allow you to define nested structures.

            For `array`, you can define the schema of the items in the array using the `items` property.

            For `object`, you can define the properties of the object using the `properties` property.
          enum:
          - string
          - number
          - integer
          - boolean
          - array
          - object
        items:
          type: object
          description: |-
            This is required if the type is "array". This is the schema of the items in the array.

            This is of type JsonSchema. However, Swagger doesn't support circular references.
        properties:
          type: object
          description: |-
            This is required if the type is "object". This specifies the properties of the object.

            This is a map of string to JsonSchema. However, Swagger doesn't support circular references.
        description:
          type: string
          description: This is the description to help the model understand what it needs to output.
        required:
          type: array
          description: |-
            This is a list of properties that are required.

            This only makes sense if the type is "object".
          items:
            type: string
        regex:
          type: string
          description: This is a regex that will be used to validate data in question.
        value:
          type: string
          description: This the value that will be used in filling the property.
        target:
          type: string
          description: This the target variable that will be filled with the value of this property.
        enum:
          type: array
          description: This array specifies the allowed values that can be used to restrict the output of the model.
          items:
            type: string
    OpenAIFunctionParameters:
      required:
      - properties
      - type
      type: object
      properties:
        type:
          type: string
          description: This must be set to 'object'. It instructs the model to return a JSON object containing the function call properties.
          enum:
          - object
        properties:
          type: object
          additionalProperties:
            $ref: '#/components/schemas/JsonSchema'
          description: |-
            This provides a description of the properties required by the function.
            JSON Schema can be used to specify expectations for each property.
            Refer to [this doc](https://ajv.js.org/json-schema.html#json-data-type) for a comprehensive guide on JSON Schema.
        required:
          type: array
          description: This specifies the properties that are required by the function.
          items:
            type: string
    OpenAIFunction:
      required:
      - name
      type: object
      properties:
        strict:
          type: boolean
          description: |-
            This is a boolean that controls whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true. Learn more about Structured Outputs in the [OpenAI guide](https://openai.com/index/introducing-structured-outputs-in-the-api/).

            @default false
          default: false
        name:
          maxLength: 64
          pattern: "/^[a-zA-Z0-9_-]{1,64}$/"
          type: string
          description: |-
            This is the the name of the function to be called.

            Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.
        description:
          maxLength: 1000
          type: string
          description: "This is the description of what the function does, used by the AI to choose when and how to call the function."
        parameters:
          description: |-
            These are the parameters the functions accepts, described as a JSON Schema object.

            See the [OpenAI guide](https://platform.openai.com/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema) for documentation about the format.

            Omitting parameters defines a function with an empty parameter list.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunctionParameters'
    CreateDtmfToolDTO:
      required:
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "dtmf" for DTMF tool.
          enum:
          - dtmf
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    CreateEndCallToolDTO:
      required:
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "endCall" for End Call tool.
          enum:
          - endCall
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    CreateVoicemailToolDTO:
      required:
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "voicemail". This uses the model itself to determine if a voicemil was reached. Can be used alternatively/alongside with TwilioVoicemailDetection
          enum:
          - voicemail
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    CreateFunctionToolDTO:
      required:
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "function" for Function tool.
          enum:
          - function
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    GhlToolMetadata:
      type: object
      properties:
        workflowId:
          type: string
        locationId:
          type: string
    CreateGhlToolDTO:
      required:
      - metadata
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "ghl" for GHL tool.
          enum:
          - ghl
        metadata:
          $ref: '#/components/schemas/GhlToolMetadata'
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    MakeToolMetadata:
      type: object
      properties:
        scenarioId:
          type: number
        triggerHookId:
          type: number
    CreateMakeToolDTO:
      required:
      - metadata
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "make" for Make tool.
          enum:
          - make
        metadata:
          $ref: '#/components/schemas/MakeToolMetadata'
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    CustomMessage:
      required:
      - type
      type: object
      properties:
        contents:
          type: array
          description: |-
            This is an alternative to the `content` property. It allows to specify variants of the same content, one per language.

            Usage:
            - If your assistants are multilingual, you can provide content for each language.
            - If you don't provide content for a language, the first item in the array will be automatically translated to the active language at that moment.

            This will override the `content` property.
          items:
            oneOf:
            - $ref: '#/components/schemas/TextContent'
        type:
          type: string
          description: This is a custom message.
          enum:
          - custom-message
        content:
          maxLength: 1000
          type: string
          description: This is the content that the assistant will say when this message is triggered.
    TransferDestinationAssistant:
      required:
      - assistantName
      - type
      type: object
      properties:
        message:
          description: |-
            This is spoken to the customer before connecting them to the destination.

            Usage:
            - If this is not provided and transfer tool messages is not provided, default is "Transferring the call now".
            - If set to "", nothing is spoken. This is useful when you want to silently transfer. This is especially useful when transferring between assistants in a squad. In this scenario, you likely also want to set `assistant.firstMessageMode=assistant-speaks-first-with-model-generated-message` for the destination assistant.

            This accepts a string or a ToolMessageStart class. Latter is useful if you want to specify multiple messages for different languages through the `contents` field.
          oneOf:
          - type: string
          - $ref: '#/components/schemas/CustomMessage'
        type:
          type: string
          enum:
          - assistant
        transferMode:
          type: string
          description: |-
            This is the mode to use for the transfer. Defaults to `rolling-history`.

            - `rolling-history`: This is the default mode. It keeps the entire conversation history and appends the new assistant's system message on transfer.

              Example:

              Pre-transfer:
                system: assistant1 system message
                assistant: assistant1 first message
                user: hey, good morning
                assistant: how can i help?
                user: i need help with my account
                assistant: (destination.message)

              Post-transfer:
                system: assistant1 system message
                assistant: assistant1 first message
                user: hey, good morning
                assistant: how can i help?
                user: i need help with my account
                assistant: (destination.message)
                system: assistant2 system message
                assistant: assistant2 first message (or model generated if firstMessageMode is set to `assistant-speaks-first-with-model-generated-message`)

            - `swap-system-message-in-history`: This replaces the original system message with the new assistant's system message on transfer.

              Example:

              Pre-transfer:
                system: assistant1 system message
                assistant: assistant1 first message
                user: hey, good morning
                assistant: how can i help?
                user: i need help with my account
                assistant: (destination.message)

              Post-transfer:
                system: assistant2 system message
                assistant: assistant1 first message
                user: hey, good morning
                assistant: how can i help?
                user: i need help with my account
                assistant: (destination.message)
                assistant: assistant2 first message (or model generated if firstMessageMode is set to `assistant-speaks-first-with-model-generated-message`)

            - `delete-history`: This deletes the entire conversation history on transfer.

              Example:

              Pre-transfer:
                system: assistant1 system message
                assistant: assistant1 first message
                user: hey, good morning
                assistant: how can i help?
                user: i need help with my account
                assistant: (destination.message)

              Post-transfer:
                system: assistant2 system message
                assistant: assistant2 first message
                user: Yes, please
                assistant: how can i help?
                user: i need help with my account

            - `swap-system-message-in-history-and-remove-transfer-tool-messages`: This replaces the original system message with the new assistant's system message on transfer and removes transfer tool messages from conversation history sent to the LLM.

              Example:

              Pre-transfer:
                system: assistant1 system message
                assistant: assistant1 first message
                user: hey, good morning
                assistant: how can i help?
                user: i need help with my account
                transfer-tool
                transfer-tool-result
                assistant: (destination.message)

              Post-transfer:
                system: assistant2 system message
                assistant: assistant1 first message
                user: hey, good morning
                assistant: how can i help?
                user: i need help with my account
                assistant: (destination.message)
                assistant: assistant2 first message (or model generated if firstMessageMode is set to `assistant-speaks-first-with-model-generated-message`)

            @default 'rolling-history'
          enum:
          - rolling-history
          - swap-system-message-in-history
          - swap-system-message-in-history-and-remove-transfer-tool-messages
          - delete-history
        assistantName:
          type: string
          description: This is the assistant to transfer the call to.
        description:
          type: string
          description: "This is the description of the destination, used by the AI to choose when and how to transfer the call."
    TransferDestinationStep:
      required:
      - stepName
      - type
      type: object
      properties:
        message:
          description: |-
            This is spoken to the customer before connecting them to the destination.

            Usage:
            - If this is not provided and transfer tool messages is not provided, default is "Transferring the call now".
            - If set to "", nothing is spoken. This is useful when you want to silently transfer. This is especially useful when transferring between assistants in a squad. In this scenario, you likely also want to set `assistant.firstMessageMode=assistant-speaks-first-with-model-generated-message` for the destination assistant.

            This accepts a string or a ToolMessageStart class. Latter is useful if you want to specify multiple messages for different languages through the `contents` field.
          oneOf:
          - type: string
          - $ref: '#/components/schemas/CustomMessage'
        type:
          type: string
          enum:
          - step
        stepName:
          type: string
          description: This is the step to transfer to.
        description:
          type: string
          description: "This is the description of the destination, used by the AI to choose when and how to transfer the call."
    SummaryPlan:
      type: object
      properties:
        messages:
          type: array
          description: |-
            These are the messages used to generate the summary.

            @default: ```
            [
              {
                "role": "system",
                "content": "You are an expert note-taker. You will be given a transcript of a call. Summarize the call in 2-3 sentences. DO NOT return anything except the summary."
              },
              {
                "role": "user",
                "content": "Here is the transcript:\n\n{{transcript}}\n\n"
              }
            ]```

            You can customize by providing any messages you want.

            Here are the template variables available:
            - {{transcript}}: The transcript of the call from `call.artifact.transcript`- {{systemPrompt}}: The system prompt of the call from `assistant.model.messages[type=system].content`
          items:
            type: object
        enabled:
          type: boolean
          description: |-
            This determines whether a summary is generated and stored in `call.analysis.summary`. Defaults to true.

            Usage:
            - If you want to disable the summary, set this to false.

            @default true
        timeoutSeconds:
          maximum: 60
          minimum: 1
          type: number
          description: |-
            This is how long the request is tried before giving up. When request times out, `call.analysis.summary` will be empty.

            Usage:
            - To guarantee the summary is generated, set this value high. Note, this will delay the end of call report in cases where model is slow to respond.

            @default 5 seconds
    TransferPlan:
      required:
      - mode
      type: object
      properties:
        mode:
          type: string
          description: |-
            This configures how transfer is executed and the experience of the destination party receiving the call.

            Usage:
            - `blind-transfer`: The assistant forwards the call to the destination without any message or summary.
            - `blind-transfer-add-summary-to-sip-header`: The assistant forwards the call to the destination and adds a SIP header X-Transfer-Summary to the call to include the summary.
            - `warm-transfer-say-message`: The assistant dials the destination, delivers the `message` to the destination party, connects the customer, and leaves the call.
            - `warm-transfer-say-summary`: The assistant dials the destination, provides a summary of the call to the destination party, connects the customer, and leaves the call.
            - `warm-transfer-wait-for-operator-to-speak-first-and-then-say-message`: The assistant dials the destination, waits for the operator to speak, delivers the `message` to the destination party, and then connects the customer.
            - `warm-transfer-wait-for-operator-to-speak-first-and-then-say-summary`: The assistant dials the destination, waits for the operator to speak, provides a summary of the call to the destination party, and then connects the customer.
            - `warm-transfer-twiml`: The assistant dials the destination, executes the twiml instructions on the destination call leg, connects the customer, and leaves the call.

            @default 'blind-transfer'
          enum:
          - blind-transfer
          - blind-transfer-add-summary-to-sip-header
          - warm-transfer-say-message
          - warm-transfer-say-summary
          - warm-transfer-twiml
          - warm-transfer-wait-for-operator-to-speak-first-and-then-say-message
          - warm-transfer-wait-for-operator-to-speak-first-and-then-say-summary
        message:
          description: |-
            This is the message the assistant will deliver to the destination party before connecting the customer.

            Usage:
            - Used only when `mode` is `blind-transfer-add-summary-to-sip-header`, `warm-transfer-say-message` or `warm-transfer-wait-for-operator-to-speak-first-and-then-say-message`.
          oneOf:
          - type: string
          - $ref: '#/components/schemas/CustomMessage'
        sipVerb:
          type: string
          description: |-
            This specifies the SIP verb to use while transferring the call.
            - 'refer': Uses SIP REFER to transfer the call (default)
            - 'bye': Ends current call with SIP BYE
            - 'dial': Uses SIP DIAL to transfer the call
          enum:
          - refer
          - bye
          - dial
        twiml:
          maxLength: 4096
          type: string
          description: |-
            This is the TwiML instructions to execute on the destination call leg before connecting the customer.

            Usage:
            - Used only when `mode` is `warm-transfer-twiml`.
            - Supports only `Play`, `Say`, `Gather`, `Hangup` and `Pause` verbs.
            - Maximum length is 4096 characters.

            Example:
            ```
            <Say voice="alice" language="en-US">Hello, transferring a customer to you.</Say>
            <Pause length="2"/>
            <Say>They called about billing questions.</Say>
            ```
        summaryPlan:
          description: |-
            This is the plan for generating a summary of the call to present to the destination party.

            Usage:
            - Used only when `mode` is `blind-transfer-add-summary-to-sip-header` or `warm-transfer-say-summary` or `warm-transfer-wait-for-operator-to-speak-first-and-then-say-summary`.
          allOf:
          - $ref: '#/components/schemas/SummaryPlan'
    TransferDestinationNumber:
      required:
      - number
      - type
      type: object
      properties:
        message:
          description: |-
            This is spoken to the customer before connecting them to the destination.

            Usage:
            - If this is not provided and transfer tool messages is not provided, default is "Transferring the call now".
            - If set to "", nothing is spoken. This is useful when you want to silently transfer. This is especially useful when transferring between assistants in a squad. In this scenario, you likely also want to set `assistant.firstMessageMode=assistant-speaks-first-with-model-generated-message` for the destination assistant.

            This accepts a string or a ToolMessageStart class. Latter is useful if you want to specify multiple messages for different languages through the `contents` field.
          oneOf:
          - type: string
          - $ref: '#/components/schemas/CustomMessage'
        type:
          type: string
          enum:
          - number
        numberE164CheckEnabled:
          type: boolean
          description: |-
            This is the flag to toggle the E164 check for the `number` field. This is an advanced property which should be used if you know your use case requires it.

            Use cases:
            - `false`: To allow non-E164 numbers like `+001234567890`, `1234`, or `abc`. This is useful for dialing out to non-E164 numbers on your SIP trunks.
            - `true` (default): To allow only E164 numbers like `+14155551234`. This is standard for PSTN calls.

            If `false`, the `number` is still required to only contain alphanumeric characters (regex: `/^\+?[a-zA-Z0-9]+$/`).

            @default true (E164 check is enabled)
          default: true
        number:
          maxLength: 40
          minLength: 3
          type: string
          description: This is the phone number to transfer the call to.
        extension:
          maxLength: 10
          minLength: 1
          type: string
          description: This is the extension to dial after transferring the call to the `number`.
        callerId:
          maxLength: 40
          type: string
          description: |-
            This is the caller ID to use when transferring the call to the `number`.

            Usage:
            - If not provided, the caller ID will be the number the call is coming from. Example, +14151111111 calls in to and the assistant transfers out to +16470000000. +16470000000 will see +14151111111 as the caller.
            - To change this behavior, provide a `callerId`.
            - Set to '{{customer.number}}' to always use the customer's number as the caller ID.
            - Set to '{{phoneNumber.number}}' to always use the phone number of the assistant as the caller ID.
            - Set to any E164 number to always use that number as the caller ID. This needs to be a number that is owned or verified by your Transport provider like Twilio.

            For Twilio, you can read up more here: https://www.twilio.com/docs/voice/twiml/dial#callerid
        transferPlan:
          description: |-
            This configures how transfer is executed and the experience of the destination party receiving the call. Defaults to `blind-transfer`.

            @default `transferPlan.mode='blind-transfer'`
          allOf:
          - $ref: '#/components/schemas/TransferPlan'
        description:
          type: string
          description: "This is the description of the destination, used by the AI to choose when and how to transfer the call."
    TransferDestinationSip:
      required:
      - sipUri
      - type
      type: object
      properties:
        message:
          description: |-
            This is spoken to the customer before connecting them to the destination.

            Usage:
            - If this is not provided and transfer tool messages is not provided, default is "Transferring the call now".
            - If set to "", nothing is spoken. This is useful when you want to silently transfer. This is especially useful when transferring between assistants in a squad. In this scenario, you likely also want to set `assistant.firstMessageMode=assistant-speaks-first-with-model-generated-message` for the destination assistant.

            This accepts a string or a ToolMessageStart class. Latter is useful if you want to specify multiple messages for different languages through the `contents` field.
          oneOf:
          - type: string
          - $ref: '#/components/schemas/CustomMessage'
        type:
          type: string
          enum:
          - sip
        sipUri:
          type: string
          description: This is the SIP URI to transfer the call to.
        transferPlan:
          description: |-
            This configures how transfer is executed and the experience of the destination party receiving the call. Defaults to `blind-transfer`.

            @default `transferPlan.mode='blind-transfer'`
          allOf:
          - $ref: '#/components/schemas/TransferPlan'
        sipHeaders:
          type: object
          description: These are custom headers to be added to SIP refer during transfer call.
        description:
          type: string
          description: "This is the description of the destination, used by the AI to choose when and how to transfer the call."
    CreateTransferCallToolDTO:
      required:
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          enum:
          - transferCall
        destinations:
          type: array
          description: "These are the destinations that the call can be transferred to. If no destinations are provided, server.url will be used to get the transfer destination once the tool is called."
          items:
            oneOf:
            - $ref: '#/components/schemas/TransferDestinationAssistant'
            - $ref: '#/components/schemas/TransferDestinationStep'
            - $ref: '#/components/schemas/TransferDestinationNumber'
            - $ref: '#/components/schemas/TransferDestinationSip'
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    CreateCustomKnowledgeBaseDTO:
      required:
      - provider
      - server
      type: object
      properties:
        provider:
          type: string
          description: This knowledge base is bring your own knowledge base implementation.
          enum:
          - custom-knowledge-base
        server:
          description: |-
            This is where the knowledge base request will be sent.

            Request Example:

            POST https://{server.url}
            Content-Type: application/json

            {
              "messsage": {
                "type": "knowledge-base-request",
                "messages": [
                  {
                    "role": "user",
                    "content": "Why is ocean blue?"
                  }
                ],
                ...other metadata about the call...
              }
            }

            Response Expected:
            ```
            {
              "message": {
                 "role": "assistant",
                 "content": "The ocean is blue because water absorbs everything but blue.",
              }, // YOU CAN RETURN THE EXACT RESPONSE TO SPEAK
              "documents": [
                {
                  "content": "The ocean is blue primarily because water absorbs colors in the red part of the light spectrum and scatters the blue light, making it more visible to our eyes.",
                  "similarity": 1
                },
                {
                  "content": "Blue light is scattered more by the water molecules than other colors, enhancing the blue appearance of the ocean.",
                  "similarity": .5
                }
              ] // OR, YOU CAN RETURN AN ARRAY OF DOCUMENTS THAT WILL BE SENT TO THE MODEL
            }
            ```
          allOf:
          - $ref: '#/components/schemas/Server'
    KnowledgeBase:
      required:
      - description
      - fileIds
      - name
      - provider
      type: object
      properties:
        name:
          type: string
          description: The name of the knowledge base
          example: My Knowledge Base
        provider:
          type: string
          description: The provider of the knowledge base
          example: google
          enum:
          - google
        model:
          type: string
          description: The model to use for the knowledge base
          enum:
          - gemini-2.0-flash-thinking-exp
          - gemini-2.0-pro-exp-02-05
          - gemini-2.0-flash
          - gemini-2.0-flash-lite
          - gemini-2.0-flash-lite-preview-02-05
          - gemini-2.0-flash-exp
          - gemini-2.0-flash-realtime-exp
          - gemini-1.5-flash
          - gemini-1.5-flash-002
          - gemini-1.5-pro
          - gemini-1.5-pro-002
          - gemini-1.0-pro
        description:
          type: string
          description: A description of the knowledge base
        fileIds:
          type: array
          description: The file IDs associated with this knowledge base
          items:
            type: string
    CreateQueryToolDTO:
      required:
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "query" for Query tool.
          enum:
          - query
        knowledgeBases:
          type: array
          description: The knowledge bases to query
          items:
            $ref: '#/components/schemas/KnowledgeBase'
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    CreateGoogleCalendarCreateEventToolDTO:
      required:
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "google.calendar.event.create" for Google Calendar tool.
          enum:
          - google.calendar.event.create
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    CreateGoogleSheetsRowAppendToolDTO:
      required:
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "google.sheets.row.append" for Google Sheets tool.
          enum:
          - google.sheets.row.append
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    CreateGoogleCalendarCheckAvailabilityToolDTO:
      required:
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "google.calendar.availability.check" for Google Calendar availability check tool.
          enum:
          - google.calendar.availability.check
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    CreateSlackSendMessageToolDTO:
      required:
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "slack.message.send" for Slack send message tool.
          enum:
          - slack.message.send
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    AnyscaleModel:
      required:
      - model
      - provider
      type: object
      properties:
        messages:
          type: array
          description: This is the starting state for the conversation.
          items:
            $ref: '#/components/schemas/OpenAIMessage'
        tools:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.

            Both `tools` and `toolIds` can be used together.
          items:
            oneOf:
            - $ref: '#/components/schemas/CreateDtmfToolDTO'
            - $ref: '#/components/schemas/CreateEndCallToolDTO'
            - $ref: '#/components/schemas/CreateVoicemailToolDTO'
            - $ref: '#/components/schemas/CreateFunctionToolDTO'
            - $ref: '#/components/schemas/CreateGhlToolDTO'
            - $ref: '#/components/schemas/CreateMakeToolDTO'
            - $ref: '#/components/schemas/CreateTransferCallToolDTO'
            - $ref: '#/components/schemas/CreateQueryToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCreateEventToolDTO'
            - $ref: '#/components/schemas/CreateGoogleSheetsRowAppendToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCheckAvailabilityToolDTO'
            - $ref: '#/components/schemas/CreateSlackSendMessageToolDTO'
        toolIds:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use transient tools, use `tools`.

            Both `tools` and `toolIds` can be used together.
          items:
            type: string
        knowledgeBase:
          description: These are the options for the knowledge base.
          oneOf:
          - $ref: '#/components/schemas/CreateCustomKnowledgeBaseDTO'
        knowledgeBaseId:
          type: string
          description: This is the ID of the knowledge base the model will use.
        provider:
          type: string
          enum:
          - anyscale
        model:
          type: string
          description: This is the name of the model. Ex. cognitivecomputations/dolphin-mixtral-8x7b
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency.
        maxTokens:
          maximum: 10000
          minimum: 50
          type: number
          description: This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250.
        emotionRecognitionEnabled:
          type: boolean
          description: |-
            This determines whether we detect user's emotion while they speak and send it as an additional info to model.

            Default `false` because the model is usually are good at understanding the user's emotion from text.

            @default false
        numFastTurns:
          minimum: 0
          type: number
          description: |-
            This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.

            Default is 0.

            @default 0
    AnthropicThinkingConfig:
      required:
      - budgetTokens
      - type
      type: object
      properties:
        type:
          type: string
          enum:
          - enabled
        budgetTokens:
          maximum: 100000
          minimum: 1024
          type: number
          description: |-
            The maximum number of tokens to allocate for thinking.
            Must be between 1024 and 100000 tokens.
    AnthropicModel:
      required:
      - model
      - provider
      type: object
      properties:
        messages:
          type: array
          description: This is the starting state for the conversation.
          items:
            $ref: '#/components/schemas/OpenAIMessage'
        tools:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.

            Both `tools` and `toolIds` can be used together.
          items:
            oneOf:
            - $ref: '#/components/schemas/CreateDtmfToolDTO'
            - $ref: '#/components/schemas/CreateEndCallToolDTO'
            - $ref: '#/components/schemas/CreateVoicemailToolDTO'
            - $ref: '#/components/schemas/CreateFunctionToolDTO'
            - $ref: '#/components/schemas/CreateGhlToolDTO'
            - $ref: '#/components/schemas/CreateMakeToolDTO'
            - $ref: '#/components/schemas/CreateTransferCallToolDTO'
            - $ref: '#/components/schemas/CreateQueryToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCreateEventToolDTO'
            - $ref: '#/components/schemas/CreateGoogleSheetsRowAppendToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCheckAvailabilityToolDTO'
            - $ref: '#/components/schemas/CreateSlackSendMessageToolDTO'
        toolIds:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use transient tools, use `tools`.

            Both `tools` and `toolIds` can be used together.
          items:
            type: string
        knowledgeBase:
          description: These are the options for the knowledge base.
          oneOf:
          - $ref: '#/components/schemas/CreateCustomKnowledgeBaseDTO'
        knowledgeBaseId:
          type: string
          description: This is the ID of the knowledge base the model will use.
        model:
          type: string
          description: The specific Anthropic/Claude model that will be used.
          enum:
          - claude-3-opus-20240229
          - claude-3-sonnet-20240229
          - claude-3-haiku-20240307
          - claude-3-5-sonnet-20240620
          - claude-3-5-sonnet-20241022
          - claude-3-5-haiku-20241022
          - claude-3-7-sonnet-20250219
        provider:
          type: string
          description: The provider identifier for Anthropic.
          enum:
          - anthropic
        thinking:
          description: |-
            Optional configuration for Anthropic's thinking feature.
            Only applicable for claude-3-7-sonnet-20250219 model.
            If provided, maxTokens must be greater than thinking.budgetTokens.
          allOf:
          - $ref: '#/components/schemas/AnthropicThinkingConfig'
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency.
        maxTokens:
          maximum: 10000
          minimum: 50
          type: number
          description: This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250.
        emotionRecognitionEnabled:
          type: boolean
          description: |-
            This determines whether we detect user's emotion while they speak and send it as an additional info to model.

            Default `false` because the model is usually are good at understanding the user's emotion from text.

            @default false
        numFastTurns:
          minimum: 0
          type: number
          description: |-
            This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.

            Default is 0.

            @default 0
    CerebrasModel:
      required:
      - model
      - provider
      type: object
      properties:
        messages:
          type: array
          description: This is the starting state for the conversation.
          items:
            $ref: '#/components/schemas/OpenAIMessage'
        tools:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.

            Both `tools` and `toolIds` can be used together.
          items:
            oneOf:
            - $ref: '#/components/schemas/CreateDtmfToolDTO'
            - $ref: '#/components/schemas/CreateEndCallToolDTO'
            - $ref: '#/components/schemas/CreateVoicemailToolDTO'
            - $ref: '#/components/schemas/CreateFunctionToolDTO'
            - $ref: '#/components/schemas/CreateGhlToolDTO'
            - $ref: '#/components/schemas/CreateMakeToolDTO'
            - $ref: '#/components/schemas/CreateTransferCallToolDTO'
            - $ref: '#/components/schemas/CreateQueryToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCreateEventToolDTO'
            - $ref: '#/components/schemas/CreateGoogleSheetsRowAppendToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCheckAvailabilityToolDTO'
            - $ref: '#/components/schemas/CreateSlackSendMessageToolDTO'
        toolIds:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use transient tools, use `tools`.

            Both `tools` and `toolIds` can be used together.
          items:
            type: string
        knowledgeBase:
          description: These are the options for the knowledge base.
          oneOf:
          - $ref: '#/components/schemas/CreateCustomKnowledgeBaseDTO'
        knowledgeBaseId:
          type: string
          description: This is the ID of the knowledge base the model will use.
        model:
          type: string
          description: This is the name of the model. Ex. cognitivecomputations/dolphin-mixtral-8x7b
          enum:
          - llama3.1-8b
          - llama-3.3-70b
        provider:
          type: string
          enum:
          - cerebras
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency.
        maxTokens:
          maximum: 10000
          minimum: 50
          type: number
          description: This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250.
        emotionRecognitionEnabled:
          type: boolean
          description: |-
            This determines whether we detect user's emotion while they speak and send it as an additional info to model.

            Default `false` because the model is usually are good at understanding the user's emotion from text.

            @default false
        numFastTurns:
          minimum: 0
          type: number
          description: |-
            This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.

            Default is 0.

            @default 0
    CustomLLMModel:
      required:
      - model
      - provider
      - url
      type: object
      properties:
        messages:
          type: array
          description: This is the starting state for the conversation.
          items:
            $ref: '#/components/schemas/OpenAIMessage'
        tools:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.

            Both `tools` and `toolIds` can be used together.
          items:
            oneOf:
            - $ref: '#/components/schemas/CreateDtmfToolDTO'
            - $ref: '#/components/schemas/CreateEndCallToolDTO'
            - $ref: '#/components/schemas/CreateVoicemailToolDTO'
            - $ref: '#/components/schemas/CreateFunctionToolDTO'
            - $ref: '#/components/schemas/CreateGhlToolDTO'
            - $ref: '#/components/schemas/CreateMakeToolDTO'
            - $ref: '#/components/schemas/CreateTransferCallToolDTO'
            - $ref: '#/components/schemas/CreateQueryToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCreateEventToolDTO'
            - $ref: '#/components/schemas/CreateGoogleSheetsRowAppendToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCheckAvailabilityToolDTO'
            - $ref: '#/components/schemas/CreateSlackSendMessageToolDTO'
        toolIds:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use transient tools, use `tools`.

            Both `tools` and `toolIds` can be used together.
          items:
            type: string
        knowledgeBase:
          description: These are the options for the knowledge base.
          oneOf:
          - $ref: '#/components/schemas/CreateCustomKnowledgeBaseDTO'
        knowledgeBaseId:
          type: string
          description: This is the ID of the knowledge base the model will use.
        provider:
          type: string
          description: "This is the provider that will be used for the model. Any service, including your own server, that is compatible with the OpenAI API can be used."
          enum:
          - custom-llm
        metadataSendMode:
          type: string
          description: |-
            This determines whether metadata is sent in requests to the custom provider.

            - `off` will not send any metadata. payload will look like `{ messages }`
            - `variable` will send `assistant.metadata` as a variable on the payload. payload will look like `{ messages, metadata }`
            - `destructured` will send `assistant.metadata` fields directly on the payload. payload will look like `{ messages, ...metadata }`

            Further, `variable` and `destructured` will send `call`, `phoneNumber`, and `customer` objects in the payload.

            Default is `variable`.
          enum:
          - "off"
          - variable
          - destructured
        url:
          type: string
          description: These is the URL we'll use for the OpenAI client's `baseURL`. Ex. https://openrouter.ai/api/v1
        timeoutSeconds:
          maximum: 600
          minimum: 20
          type: number
          description: This sets the timeout for the connection to the custom provider without needing to stream any tokens back. Default is 20 seconds.
        model:
          type: string
          description: This is the name of the model. Ex. cognitivecomputations/dolphin-mixtral-8x7b
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency.
        maxTokens:
          maximum: 10000
          minimum: 50
          type: number
          description: This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250.
        emotionRecognitionEnabled:
          type: boolean
          description: |-
            This determines whether we detect user's emotion while they speak and send it as an additional info to model.

            Default `false` because the model is usually are good at understanding the user's emotion from text.

            @default false
        numFastTurns:
          minimum: 0
          type: number
          description: |-
            This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.

            Default is 0.

            @default 0
    DeepInfraModel:
      required:
      - model
      - provider
      type: object
      properties:
        messages:
          type: array
          description: This is the starting state for the conversation.
          items:
            $ref: '#/components/schemas/OpenAIMessage'
        tools:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.

            Both `tools` and `toolIds` can be used together.
          items:
            oneOf:
            - $ref: '#/components/schemas/CreateDtmfToolDTO'
            - $ref: '#/components/schemas/CreateEndCallToolDTO'
            - $ref: '#/components/schemas/CreateVoicemailToolDTO'
            - $ref: '#/components/schemas/CreateFunctionToolDTO'
            - $ref: '#/components/schemas/CreateGhlToolDTO'
            - $ref: '#/components/schemas/CreateMakeToolDTO'
            - $ref: '#/components/schemas/CreateTransferCallToolDTO'
            - $ref: '#/components/schemas/CreateQueryToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCreateEventToolDTO'
            - $ref: '#/components/schemas/CreateGoogleSheetsRowAppendToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCheckAvailabilityToolDTO'
            - $ref: '#/components/schemas/CreateSlackSendMessageToolDTO'
        toolIds:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use transient tools, use `tools`.

            Both `tools` and `toolIds` can be used together.
          items:
            type: string
        knowledgeBase:
          description: These are the options for the knowledge base.
          oneOf:
          - $ref: '#/components/schemas/CreateCustomKnowledgeBaseDTO'
        knowledgeBaseId:
          type: string
          description: This is the ID of the knowledge base the model will use.
        provider:
          type: string
          enum:
          - deepinfra
        model:
          type: string
          description: This is the name of the model. Ex. cognitivecomputations/dolphin-mixtral-8x7b
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency.
        maxTokens:
          maximum: 10000
          minimum: 50
          type: number
          description: This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250.
        emotionRecognitionEnabled:
          type: boolean
          description: |-
            This determines whether we detect user's emotion while they speak and send it as an additional info to model.

            Default `false` because the model is usually are good at understanding the user's emotion from text.

            @default false
        numFastTurns:
          minimum: 0
          type: number
          description: |-
            This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.

            Default is 0.

            @default 0
    DeepSeekModel:
      required:
      - model
      - provider
      type: object
      properties:
        messages:
          type: array
          description: This is the starting state for the conversation.
          items:
            $ref: '#/components/schemas/OpenAIMessage'
        tools:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.

            Both `tools` and `toolIds` can be used together.
          items:
            oneOf:
            - $ref: '#/components/schemas/CreateDtmfToolDTO'
            - $ref: '#/components/schemas/CreateEndCallToolDTO'
            - $ref: '#/components/schemas/CreateVoicemailToolDTO'
            - $ref: '#/components/schemas/CreateFunctionToolDTO'
            - $ref: '#/components/schemas/CreateGhlToolDTO'
            - $ref: '#/components/schemas/CreateMakeToolDTO'
            - $ref: '#/components/schemas/CreateTransferCallToolDTO'
            - $ref: '#/components/schemas/CreateQueryToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCreateEventToolDTO'
            - $ref: '#/components/schemas/CreateGoogleSheetsRowAppendToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCheckAvailabilityToolDTO'
            - $ref: '#/components/schemas/CreateSlackSendMessageToolDTO'
        toolIds:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use transient tools, use `tools`.

            Both `tools` and `toolIds` can be used together.
          items:
            type: string
        knowledgeBase:
          description: These are the options for the knowledge base.
          oneOf:
          - $ref: '#/components/schemas/CreateCustomKnowledgeBaseDTO'
        knowledgeBaseId:
          type: string
          description: This is the ID of the knowledge base the model will use.
        model:
          type: string
          description: This is the name of the model. Ex. cognitivecomputations/dolphin-mixtral-8x7b
          enum:
          - deepseek-chat
          - deepseek-reasoner
        provider:
          type: string
          enum:
          - deep-seek
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency.
        maxTokens:
          maximum: 10000
          minimum: 50
          type: number
          description: This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250.
        emotionRecognitionEnabled:
          type: boolean
          description: |-
            This determines whether we detect user's emotion while they speak and send it as an additional info to model.

            Default `false` because the model is usually are good at understanding the user's emotion from text.

            @default false
        numFastTurns:
          minimum: 0
          type: number
          description: |-
            This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.

            Default is 0.

            @default 0
    GeminiMultimodalLivePrebuiltVoiceConfig:
      required:
      - voiceName
      type: object
      properties:
        voiceName:
          type: string
          enum:
          - Puck
          - Charon
          - Kore
          - Fenrir
          - Aoede
    GeminiMultimodalLiveVoiceConfig:
      required:
      - prebuiltVoiceConfig
      type: object
      properties:
        prebuiltVoiceConfig:
          $ref: '#/components/schemas/GeminiMultimodalLivePrebuiltVoiceConfig'
    GeminiMultimodalLiveSpeechConfig:
      required:
      - voiceConfig
      type: object
      properties:
        voiceConfig:
          $ref: '#/components/schemas/GeminiMultimodalLiveVoiceConfig'
    GoogleRealtimeConfig:
      type: object
      properties:
        topP:
          type: number
          description: |-
            This is the nucleus sampling parameter that controls the cumulative probability of tokens considered during text generation.
            Only applicable with the Gemini Flash 2.0 Multimodal Live API.
        topK:
          type: number
          description: |-
            This is the top-k sampling parameter that limits the number of highest probability tokens considered during text generation.
            Only applicable with the Gemini Flash 2.0 Multimodal Live API.
        presencePenalty:
          type: number
          description: |-
            This is the presence penalty parameter that influences the model's likelihood to repeat information by penalizing tokens based on their presence in the text.
            Only applicable with the Gemini Flash 2.0 Multimodal Live API.
        frequencyPenalty:
          type: number
          description: |-
            This is the frequency penalty parameter that influences the model's likelihood to repeat tokens by penalizing them based on their frequency in the text.
            Only applicable with the Gemini Flash 2.0 Multimodal Live API.
        speechConfig:
          description: |-
            This is the speech configuration object that defines the voice settings to be used for the model's speech output.
            Only applicable with the Gemini Flash 2.0 Multimodal Live API.
          allOf:
          - $ref: '#/components/schemas/GeminiMultimodalLiveSpeechConfig'
    GoogleModel:
      required:
      - model
      - provider
      type: object
      properties:
        messages:
          type: array
          description: This is the starting state for the conversation.
          items:
            $ref: '#/components/schemas/OpenAIMessage'
        tools:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.

            Both `tools` and `toolIds` can be used together.
          items:
            oneOf:
            - $ref: '#/components/schemas/CreateDtmfToolDTO'
            - $ref: '#/components/schemas/CreateEndCallToolDTO'
            - $ref: '#/components/schemas/CreateVoicemailToolDTO'
            - $ref: '#/components/schemas/CreateFunctionToolDTO'
            - $ref: '#/components/schemas/CreateGhlToolDTO'
            - $ref: '#/components/schemas/CreateMakeToolDTO'
            - $ref: '#/components/schemas/CreateTransferCallToolDTO'
            - $ref: '#/components/schemas/CreateQueryToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCreateEventToolDTO'
            - $ref: '#/components/schemas/CreateGoogleSheetsRowAppendToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCheckAvailabilityToolDTO'
            - $ref: '#/components/schemas/CreateSlackSendMessageToolDTO'
        toolIds:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use transient tools, use `tools`.

            Both `tools` and `toolIds` can be used together.
          items:
            type: string
        knowledgeBase:
          description: These are the options for the knowledge base.
          oneOf:
          - $ref: '#/components/schemas/CreateCustomKnowledgeBaseDTO'
        knowledgeBaseId:
          type: string
          description: This is the ID of the knowledge base the model will use.
        model:
          type: string
          description: This is the Google model that will be used.
          enum:
          - gemini-2.0-flash-thinking-exp
          - gemini-2.0-pro-exp-02-05
          - gemini-2.0-flash
          - gemini-2.0-flash-lite
          - gemini-2.0-flash-lite-preview-02-05
          - gemini-2.0-flash-exp
          - gemini-2.0-flash-realtime-exp
          - gemini-1.5-flash
          - gemini-1.5-flash-002
          - gemini-1.5-pro
          - gemini-1.5-pro-002
          - gemini-1.0-pro
        provider:
          type: string
          enum:
          - google
        realtimeConfig:
          description: |-
            This is the session configuration for the Gemini Flash 2.0 Multimodal Live API.
            Only applicable if the model `gemini-2.0-flash-realtime-exp` is selected.
          allOf:
          - $ref: '#/components/schemas/GoogleRealtimeConfig'
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency.
        maxTokens:
          maximum: 10000
          minimum: 50
          type: number
          description: This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250.
        emotionRecognitionEnabled:
          type: boolean
          description: |-
            This determines whether we detect user's emotion while they speak and send it as an additional info to model.

            Default `false` because the model is usually are good at understanding the user's emotion from text.

            @default false
        numFastTurns:
          minimum: 0
          type: number
          description: |-
            This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.

            Default is 0.

            @default 0
    GroqModel:
      required:
      - model
      - provider
      type: object
      properties:
        messages:
          type: array
          description: This is the starting state for the conversation.
          items:
            $ref: '#/components/schemas/OpenAIMessage'
        tools:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.

            Both `tools` and `toolIds` can be used together.
          items:
            oneOf:
            - $ref: '#/components/schemas/CreateDtmfToolDTO'
            - $ref: '#/components/schemas/CreateEndCallToolDTO'
            - $ref: '#/components/schemas/CreateVoicemailToolDTO'
            - $ref: '#/components/schemas/CreateFunctionToolDTO'
            - $ref: '#/components/schemas/CreateGhlToolDTO'
            - $ref: '#/components/schemas/CreateMakeToolDTO'
            - $ref: '#/components/schemas/CreateTransferCallToolDTO'
            - $ref: '#/components/schemas/CreateQueryToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCreateEventToolDTO'
            - $ref: '#/components/schemas/CreateGoogleSheetsRowAppendToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCheckAvailabilityToolDTO'
            - $ref: '#/components/schemas/CreateSlackSendMessageToolDTO'
        toolIds:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use transient tools, use `tools`.

            Both `tools` and `toolIds` can be used together.
          items:
            type: string
        knowledgeBase:
          description: These are the options for the knowledge base.
          oneOf:
          - $ref: '#/components/schemas/CreateCustomKnowledgeBaseDTO'
        knowledgeBaseId:
          type: string
          description: This is the ID of the knowledge base the model will use.
        model:
          type: string
          description: This is the name of the model. Ex. cognitivecomputations/dolphin-mixtral-8x7b
          enum:
          - deepseek-r1-distill-llama-70b
          - llama-3.3-70b-versatile
          - llama-3.1-405b-reasoning
          - llama-3.1-70b-versatile
          - llama-3.1-8b-instant
          - mixtral-8x7b-32768
          - llama3-8b-8192
          - llama3-70b-8192
          - gemma2-9b-it
        provider:
          type: string
          enum:
          - groq
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency.
        maxTokens:
          maximum: 10000
          minimum: 50
          type: number
          description: This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250.
        emotionRecognitionEnabled:
          type: boolean
          description: |-
            This determines whether we detect user's emotion while they speak and send it as an additional info to model.

            Default `false` because the model is usually are good at understanding the user's emotion from text.

            @default false
        numFastTurns:
          minimum: 0
          type: number
          description: |-
            This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.

            Default is 0.

            @default 0
    InflectionAIModel:
      required:
      - model
      - provider
      type: object
      properties:
        messages:
          type: array
          description: This is the starting state for the conversation.
          items:
            $ref: '#/components/schemas/OpenAIMessage'
        tools:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.

            Both `tools` and `toolIds` can be used together.
          items:
            oneOf:
            - $ref: '#/components/schemas/CreateDtmfToolDTO'
            - $ref: '#/components/schemas/CreateEndCallToolDTO'
            - $ref: '#/components/schemas/CreateVoicemailToolDTO'
            - $ref: '#/components/schemas/CreateFunctionToolDTO'
            - $ref: '#/components/schemas/CreateGhlToolDTO'
            - $ref: '#/components/schemas/CreateMakeToolDTO'
            - $ref: '#/components/schemas/CreateTransferCallToolDTO'
            - $ref: '#/components/schemas/CreateQueryToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCreateEventToolDTO'
            - $ref: '#/components/schemas/CreateGoogleSheetsRowAppendToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCheckAvailabilityToolDTO'
            - $ref: '#/components/schemas/CreateSlackSendMessageToolDTO'
        toolIds:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use transient tools, use `tools`.

            Both `tools` and `toolIds` can be used together.
          items:
            type: string
        knowledgeBase:
          description: These are the options for the knowledge base.
          oneOf:
          - $ref: '#/components/schemas/CreateCustomKnowledgeBaseDTO'
        knowledgeBaseId:
          type: string
          description: This is the ID of the knowledge base the model will use.
        model:
          type: string
          description: This is the name of the model. Ex. cognitivecomputations/dolphin-mixtral-8x7b
          enum:
          - inflection_3_pi
        provider:
          type: string
          enum:
          - inflection-ai
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency.
        maxTokens:
          maximum: 10000
          minimum: 50
          type: number
          description: This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250.
        emotionRecognitionEnabled:
          type: boolean
          description: |-
            This determines whether we detect user's emotion while they speak and send it as an additional info to model.

            Default `false` because the model is usually are good at understanding the user's emotion from text.

            @default false
        numFastTurns:
          minimum: 0
          type: number
          description: |-
            This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.

            Default is 0.

            @default 0
    OpenAIModel:
      required:
      - model
      - provider
      type: object
      properties:
        messages:
          type: array
          description: This is the starting state for the conversation.
          items:
            $ref: '#/components/schemas/OpenAIMessage'
        tools:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.

            Both `tools` and `toolIds` can be used together.
          items:
            oneOf:
            - $ref: '#/components/schemas/CreateDtmfToolDTO'
            - $ref: '#/components/schemas/CreateEndCallToolDTO'
            - $ref: '#/components/schemas/CreateVoicemailToolDTO'
            - $ref: '#/components/schemas/CreateFunctionToolDTO'
            - $ref: '#/components/schemas/CreateGhlToolDTO'
            - $ref: '#/components/schemas/CreateMakeToolDTO'
            - $ref: '#/components/schemas/CreateTransferCallToolDTO'
            - $ref: '#/components/schemas/CreateQueryToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCreateEventToolDTO'
            - $ref: '#/components/schemas/CreateGoogleSheetsRowAppendToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCheckAvailabilityToolDTO'
            - $ref: '#/components/schemas/CreateSlackSendMessageToolDTO'
        toolIds:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use transient tools, use `tools`.

            Both `tools` and `toolIds` can be used together.
          items:
            type: string
        knowledgeBase:
          description: These are the options for the knowledge base.
          oneOf:
          - $ref: '#/components/schemas/CreateCustomKnowledgeBaseDTO'
        knowledgeBaseId:
          type: string
          description: This is the ID of the knowledge base the model will use.
        provider:
          type: string
          description: This is the provider that will be used for the model.
          enum:
          - openai
        model:
          type: string
          description: This is the OpenAI model that will be used.
          enum:
          - gpt-4.1
          - gpt-4.1-mini
          - gpt-4.1-nano
          - gpt-4.5-preview
          - chatgpt-4o-latest
          - o3-mini
          - o1-preview
          - o1-preview-2024-09-12
          - o1-mini
          - o1-mini-2024-09-12
          - gpt-4o-realtime-preview-2024-10-01
          - gpt-4o-realtime-preview-2024-12-17
          - gpt-4o-mini-realtime-preview-2024-12-17
          - gpt-4o-mini-2024-07-18
          - gpt-4o-mini
          - gpt-4o
          - gpt-4o-2024-05-13
          - gpt-4o-2024-08-06
          - gpt-4o-2024-11-20
          - gpt-4-turbo
          - gpt-4-turbo-2024-04-09
          - gpt-4-turbo-preview
          - gpt-4-0125-preview
          - gpt-4-1106-preview
          - gpt-4
          - gpt-4-0613
          - gpt-3.5-turbo
          - gpt-3.5-turbo-0125
          - gpt-3.5-turbo-1106
          - gpt-3.5-turbo-16k
          - gpt-3.5-turbo-0613
        fallbackModels:
          type: array
          description: These are the fallback models that will be used if the primary model fails. This shouldn't be specified unless you have a specific reason to do so. Vapi will automatically find the fastest fallbacks that make sense.
          example:
          - gpt-4-0125-preview
          - gpt-4-0613
          items:
            type: string
            enum:
            - gpt-4.1
            - gpt-4.1-mini
            - gpt-4.1-nano
            - gpt-4.5-preview
            - chatgpt-4o-latest
            - o3-mini
            - o1-preview
            - o1-preview-2024-09-12
            - o1-mini
            - o1-mini-2024-09-12
            - gpt-4o-realtime-preview-2024-10-01
            - gpt-4o-realtime-preview-2024-12-17
            - gpt-4o-mini-realtime-preview-2024-12-17
            - gpt-4o-mini-2024-07-18
            - gpt-4o-mini
            - gpt-4o
            - gpt-4o-2024-05-13
            - gpt-4o-2024-08-06
            - gpt-4o-2024-11-20
            - gpt-4-turbo
            - gpt-4-turbo-2024-04-09
            - gpt-4-turbo-preview
            - gpt-4-0125-preview
            - gpt-4-1106-preview
            - gpt-4
            - gpt-4-0613
            - gpt-3.5-turbo
            - gpt-3.5-turbo-0125
            - gpt-3.5-turbo-1106
            - gpt-3.5-turbo-16k
            - gpt-3.5-turbo-0613
          enum:
          - gpt-4.1
          - gpt-4.1-mini
          - gpt-4.1-nano
          - gpt-4.5-preview
          - chatgpt-4o-latest
          - o3-mini
          - o1-preview
          - o1-preview-2024-09-12
          - o1-mini
          - o1-mini-2024-09-12
          - gpt-4o-realtime-preview-2024-10-01
          - gpt-4o-realtime-preview-2024-12-17
          - gpt-4o-mini-realtime-preview-2024-12-17
          - gpt-4o-mini-2024-07-18
          - gpt-4o-mini
          - gpt-4o
          - gpt-4o-2024-05-13
          - gpt-4o-2024-08-06
          - gpt-4o-2024-11-20
          - gpt-4-turbo
          - gpt-4-turbo-2024-04-09
          - gpt-4-turbo-preview
          - gpt-4-0125-preview
          - gpt-4-1106-preview
          - gpt-4
          - gpt-4-0613
          - gpt-3.5-turbo
          - gpt-3.5-turbo-0125
          - gpt-3.5-turbo-1106
          - gpt-3.5-turbo-16k
          - gpt-3.5-turbo-0613
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency.
        maxTokens:
          maximum: 10000
          minimum: 50
          type: number
          description: This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250.
        emotionRecognitionEnabled:
          type: boolean
          description: |-
            This determines whether we detect user's emotion while they speak and send it as an additional info to model.

            Default `false` because the model is usually are good at understanding the user's emotion from text.

            @default false
        numFastTurns:
          minimum: 0
          type: number
          description: |-
            This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.

            Default is 0.

            @default 0
    OpenRouterModel:
      required:
      - model
      - provider
      type: object
      properties:
        messages:
          type: array
          description: This is the starting state for the conversation.
          items:
            $ref: '#/components/schemas/OpenAIMessage'
        tools:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.

            Both `tools` and `toolIds` can be used together.
          items:
            oneOf:
            - $ref: '#/components/schemas/CreateDtmfToolDTO'
            - $ref: '#/components/schemas/CreateEndCallToolDTO'
            - $ref: '#/components/schemas/CreateVoicemailToolDTO'
            - $ref: '#/components/schemas/CreateFunctionToolDTO'
            - $ref: '#/components/schemas/CreateGhlToolDTO'
            - $ref: '#/components/schemas/CreateMakeToolDTO'
            - $ref: '#/components/schemas/CreateTransferCallToolDTO'
            - $ref: '#/components/schemas/CreateQueryToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCreateEventToolDTO'
            - $ref: '#/components/schemas/CreateGoogleSheetsRowAppendToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCheckAvailabilityToolDTO'
            - $ref: '#/components/schemas/CreateSlackSendMessageToolDTO'
        toolIds:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use transient tools, use `tools`.

            Both `tools` and `toolIds` can be used together.
          items:
            type: string
        knowledgeBase:
          description: These are the options for the knowledge base.
          oneOf:
          - $ref: '#/components/schemas/CreateCustomKnowledgeBaseDTO'
        knowledgeBaseId:
          type: string
          description: This is the ID of the knowledge base the model will use.
        provider:
          type: string
          enum:
          - openrouter
        model:
          type: string
          description: This is the name of the model. Ex. cognitivecomputations/dolphin-mixtral-8x7b
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency.
        maxTokens:
          maximum: 10000
          minimum: 50
          type: number
          description: This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250.
        emotionRecognitionEnabled:
          type: boolean
          description: |-
            This determines whether we detect user's emotion while they speak and send it as an additional info to model.

            Default `false` because the model is usually are good at understanding the user's emotion from text.

            @default false
        numFastTurns:
          minimum: 0
          type: number
          description: |-
            This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.

            Default is 0.

            @default 0
    PerplexityAIModel:
      required:
      - model
      - provider
      type: object
      properties:
        messages:
          type: array
          description: This is the starting state for the conversation.
          items:
            $ref: '#/components/schemas/OpenAIMessage'
        tools:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.

            Both `tools` and `toolIds` can be used together.
          items:
            oneOf:
            - $ref: '#/components/schemas/CreateDtmfToolDTO'
            - $ref: '#/components/schemas/CreateEndCallToolDTO'
            - $ref: '#/components/schemas/CreateVoicemailToolDTO'
            - $ref: '#/components/schemas/CreateFunctionToolDTO'
            - $ref: '#/components/schemas/CreateGhlToolDTO'
            - $ref: '#/components/schemas/CreateMakeToolDTO'
            - $ref: '#/components/schemas/CreateTransferCallToolDTO'
            - $ref: '#/components/schemas/CreateQueryToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCreateEventToolDTO'
            - $ref: '#/components/schemas/CreateGoogleSheetsRowAppendToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCheckAvailabilityToolDTO'
            - $ref: '#/components/schemas/CreateSlackSendMessageToolDTO'
        toolIds:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use transient tools, use `tools`.

            Both `tools` and `toolIds` can be used together.
          items:
            type: string
        knowledgeBase:
          description: These are the options for the knowledge base.
          oneOf:
          - $ref: '#/components/schemas/CreateCustomKnowledgeBaseDTO'
        knowledgeBaseId:
          type: string
          description: This is the ID of the knowledge base the model will use.
        provider:
          type: string
          enum:
          - perplexity-ai
        model:
          type: string
          description: This is the name of the model. Ex. cognitivecomputations/dolphin-mixtral-8x7b
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency.
        maxTokens:
          maximum: 10000
          minimum: 50
          type: number
          description: This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250.
        emotionRecognitionEnabled:
          type: boolean
          description: |-
            This determines whether we detect user's emotion while they speak and send it as an additional info to model.

            Default `false` because the model is usually are good at understanding the user's emotion from text.

            @default false
        numFastTurns:
          minimum: 0
          type: number
          description: |-
            This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.

            Default is 0.

            @default 0
    TogetherAIModel:
      required:
      - model
      - provider
      type: object
      properties:
        messages:
          type: array
          description: This is the starting state for the conversation.
          items:
            $ref: '#/components/schemas/OpenAIMessage'
        tools:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.

            Both `tools` and `toolIds` can be used together.
          items:
            oneOf:
            - $ref: '#/components/schemas/CreateDtmfToolDTO'
            - $ref: '#/components/schemas/CreateEndCallToolDTO'
            - $ref: '#/components/schemas/CreateVoicemailToolDTO'
            - $ref: '#/components/schemas/CreateFunctionToolDTO'
            - $ref: '#/components/schemas/CreateGhlToolDTO'
            - $ref: '#/components/schemas/CreateMakeToolDTO'
            - $ref: '#/components/schemas/CreateTransferCallToolDTO'
            - $ref: '#/components/schemas/CreateQueryToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCreateEventToolDTO'
            - $ref: '#/components/schemas/CreateGoogleSheetsRowAppendToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCheckAvailabilityToolDTO'
            - $ref: '#/components/schemas/CreateSlackSendMessageToolDTO'
        toolIds:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use transient tools, use `tools`.

            Both `tools` and `toolIds` can be used together.
          items:
            type: string
        knowledgeBase:
          description: These are the options for the knowledge base.
          oneOf:
          - $ref: '#/components/schemas/CreateCustomKnowledgeBaseDTO'
        knowledgeBaseId:
          type: string
          description: This is the ID of the knowledge base the model will use.
        provider:
          type: string
          enum:
          - together-ai
        model:
          type: string
          description: This is the name of the model. Ex. cognitivecomputations/dolphin-mixtral-8x7b
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency.
        maxTokens:
          maximum: 10000
          minimum: 50
          type: number
          description: This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250.
        emotionRecognitionEnabled:
          type: boolean
          description: |-
            This determines whether we detect user's emotion while they speak and send it as an additional info to model.

            Default `false` because the model is usually are good at understanding the user's emotion from text.

            @default false
        numFastTurns:
          minimum: 0
          type: number
          description: |-
            This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.

            Default is 0.

            @default 0
    AIEdgeCondition:
      required:
      - prompt
      - type
      type: object
      properties:
        type:
          type: string
          enum:
          - ai
        prompt:
          maxLength: 1000
          type: string
          description: This is the prompt for the AI edge condition. It should evaluate to a boolean.
    LogicEdgeCondition:
      required:
      - liquid
      - type
      type: object
      properties:
        type:
          type: string
          enum:
          - logic
        liquid:
          maxLength: 100
          type: string
    FailedEdgeCondition:
      required:
      - type
      type: object
      properties:
        type:
          type: string
          enum:
          - failed
    Edge:
      required:
      - from
      - to
      type: object
      properties:
        condition:
          oneOf:
          - $ref: '#/components/schemas/AIEdgeCondition'
          - $ref: '#/components/schemas/LogicEdgeCondition'
          - $ref: '#/components/schemas/FailedEdgeCondition'
        from:
          maxLength: 80
          type: string
        to:
          maxLength: 80
          type: string
        metadata:
          type: object
          description: This is for metadata you want to store on the edge.
    Workflow:
      required:
      - createdAt
      - edges
      - id
      - name
      - nodes
      - orgId
      - updatedAt
      type: object
      properties:
        nodes:
          type: array
          items:
            oneOf:
            - $ref: '#/components/schemas/Say'
            - $ref: '#/components/schemas/Gather'
            - $ref: '#/components/schemas/ApiRequest'
            - $ref: '#/components/schemas/Hangup'
            - $ref: '#/components/schemas/Transfer'
        model:
          description: These are the options for the workflow's LLM.
          oneOf:
          - $ref: '#/components/schemas/AnthropicModel'
          - $ref: '#/components/schemas/AnyscaleModel'
          - $ref: '#/components/schemas/CerebrasModel'
          - $ref: '#/components/schemas/CustomLLMModel'
          - $ref: '#/components/schemas/DeepInfraModel'
          - $ref: '#/components/schemas/DeepSeekModel'
          - $ref: '#/components/schemas/GoogleModel'
          - $ref: '#/components/schemas/GroqModel'
          - $ref: '#/components/schemas/InflectionAIModel'
          - $ref: '#/components/schemas/OpenAIModel'
          - $ref: '#/components/schemas/OpenRouterModel'
          - $ref: '#/components/schemas/PerplexityAIModel'
          - $ref: '#/components/schemas/TogetherAIModel'
          - $ref: '#/components/schemas/XaiModel'
        id:
          type: string
        orgId:
          type: string
        createdAt:
          type: string
          format: date-time
        updatedAt:
          type: string
          format: date-time
        name:
          maxLength: 80
          type: string
        edges:
          type: array
          items:
            $ref: '#/components/schemas/Edge'
    VapiModel:
      required:
      - model
      - provider
      type: object
      properties:
        messages:
          type: array
          description: This is the starting state for the conversation.
          items:
            $ref: '#/components/schemas/OpenAIMessage'
        tools:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.

            Both `tools` and `toolIds` can be used together.
          items:
            oneOf:
            - $ref: '#/components/schemas/CreateDtmfToolDTO'
            - $ref: '#/components/schemas/CreateEndCallToolDTO'
            - $ref: '#/components/schemas/CreateVoicemailToolDTO'
            - $ref: '#/components/schemas/CreateFunctionToolDTO'
            - $ref: '#/components/schemas/CreateGhlToolDTO'
            - $ref: '#/components/schemas/CreateMakeToolDTO'
            - $ref: '#/components/schemas/CreateTransferCallToolDTO'
            - $ref: '#/components/schemas/CreateQueryToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCreateEventToolDTO'
            - $ref: '#/components/schemas/CreateGoogleSheetsRowAppendToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCheckAvailabilityToolDTO'
            - $ref: '#/components/schemas/CreateSlackSendMessageToolDTO'
        toolIds:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use transient tools, use `tools`.

            Both `tools` and `toolIds` can be used together.
          items:
            type: string
        knowledgeBase:
          description: These are the options for the knowledge base.
          oneOf:
          - $ref: '#/components/schemas/CreateCustomKnowledgeBaseDTO'
        knowledgeBaseId:
          type: string
          description: This is the ID of the knowledge base the model will use.
        provider:
          type: string
          enum:
          - vapi
        workflowId:
          type: string
          description: "This is the workflow that will be used for the call. To use a transient workflow, use `workflow` instead."
        workflow:
          description: "This is the workflow that will be used for the call. To use an existing workflow, use `workflowId` instead."
          allOf:
          - $ref: '#/components/schemas/Workflow'
        model:
          type: string
          description: This is the name of the model. Ex. cognitivecomputations/dolphin-mixtral-8x7b
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency.
        maxTokens:
          maximum: 10000
          minimum: 50
          type: number
          description: This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250.
        emotionRecognitionEnabled:
          type: boolean
          description: |-
            This determines whether we detect user's emotion while they speak and send it as an additional info to model.

            Default `false` because the model is usually are good at understanding the user's emotion from text.

            @default false
        numFastTurns:
          minimum: 0
          type: number
          description: |-
            This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.

            Default is 0.

            @default 0
    XaiModel:
      required:
      - model
      - provider
      type: object
      properties:
        messages:
          type: array
          description: This is the starting state for the conversation.
          items:
            $ref: '#/components/schemas/OpenAIMessage'
        tools:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.

            Both `tools` and `toolIds` can be used together.
          items:
            oneOf:
            - $ref: '#/components/schemas/CreateDtmfToolDTO'
            - $ref: '#/components/schemas/CreateEndCallToolDTO'
            - $ref: '#/components/schemas/CreateVoicemailToolDTO'
            - $ref: '#/components/schemas/CreateFunctionToolDTO'
            - $ref: '#/components/schemas/CreateGhlToolDTO'
            - $ref: '#/components/schemas/CreateMakeToolDTO'
            - $ref: '#/components/schemas/CreateTransferCallToolDTO'
            - $ref: '#/components/schemas/CreateQueryToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCreateEventToolDTO'
            - $ref: '#/components/schemas/CreateGoogleSheetsRowAppendToolDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarCheckAvailabilityToolDTO'
            - $ref: '#/components/schemas/CreateSlackSendMessageToolDTO'
        toolIds:
          type: array
          description: |-
            These are the tools that the assistant can use during the call. To use transient tools, use `tools`.

            Both `tools` and `toolIds` can be used together.
          items:
            type: string
        knowledgeBase:
          description: These are the options for the knowledge base.
          oneOf:
          - $ref: '#/components/schemas/CreateCustomKnowledgeBaseDTO'
        knowledgeBaseId:
          type: string
          description: This is the ID of the knowledge base the model will use.
        model:
          type: string
          description: This is the name of the model. Ex. cognitivecomputations/dolphin-mixtral-8x7b
          enum:
          - grok-beta
          - grok-2
          - grok-3
        provider:
          type: string
          enum:
          - xai
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency.
        maxTokens:
          maximum: 10000
          minimum: 50
          type: number
          description: This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250.
        emotionRecognitionEnabled:
          type: boolean
          description: |-
            This determines whether we detect user's emotion while they speak and send it as an additional info to model.

            Default `false` because the model is usually are good at understanding the user's emotion from text.

            @default false
        numFastTurns:
          minimum: 0
          type: number
          description: |-
            This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.

            Default is 0.

            @default 0
    ExactReplacement:
      required:
      - key
      - type
      - value
      type: object
      properties:
        type:
          type: string
          description: |-
            This is the exact replacement type. You can use this to replace a specific word or phrase with a different word or phrase.

            Usage:
            - Replace "hello" with "hi": { type: 'exact', key: 'hello', value: 'hi' }
            - Replace "good morning" with "good day": { type: 'exact', key: 'good morning', value: 'good day' }
            - Replace a specific name: { type: 'exact', key: 'John Doe', value: 'Jane Smith' }
            - Replace an acronym: { type: 'exact', key: 'AI', value: 'Artificial Intelligence' }
            - Replace a company name with its phonetic pronunciation: { type: 'exact', key: 'Vapi', value: 'Vappy' }
          enum:
          - exact
        replaceAllEnabled:
          type: boolean
          description: |-
            This option let's you control whether to replace all instances of the key or only the first one. By default, it only replaces the first instance.
            Examples:
            - For { type: 'exact', key: 'hello', value: 'hi', replaceAllEnabled: false }. Before: "hello world, hello universe" | After: "hi world, hello universe"
            - For { type: 'exact', key: 'hello', value: 'hi', replaceAllEnabled: true }. Before: "hello world, hello universe" | After: "hi world, hi universe"
            @default false
          default: false
        key:
          type: string
          description: This is the key to replace.
        value:
          maxLength: 1000
          type: string
          description: This is the value that will replace the match.
    RegexOption:
      required:
      - enabled
      - type
      type: object
      properties:
        type:
          type: string
          description: |-
            This is the type of the regex option. Options are:
            - `ignore-case`: Ignores the case of the text being matched. Add
            - `whole-word`: Matches whole words only.
            - `multi-line`: Matches across multiple lines.
          enum:
          - ignore-case
          - whole-word
          - multi-line
        enabled:
          type: boolean
          description: |-
            This is whether to enable the option.

            @default false
    RegexReplacement:
      required:
      - regex
      - type
      - value
      type: object
      properties:
        type:
          type: string
          description: |-
            This is the regex replacement type. You can use this to replace a word or phrase that matches a pattern.

            Usage:
            - Replace all numbers with "some number": { type: 'regex', regex: '\\d+', value: 'some number' }
            - Replace email addresses with "[EMAIL]": { type: 'regex', regex: '\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', value: '[EMAIL]' }
            - Replace phone numbers with a formatted version: { type: 'regex', regex: '(\\d{3})(\\d{3})(\\d{4})', value: '($1) $2-$3' }
            - Replace all instances of "color" or "colour" with "hue": { type: 'regex', regex: 'colou?r', value: 'hue' }
            - Capitalize the first letter of every sentence: { type: 'regex', regex: '(?<=\\. |^)[a-z]', value: (match) => match.toUpperCase() }
          enum:
          - regex
        regex:
          type: string
          description: |-
            This is the regex pattern to replace.

            Note:
            - This works by using the `string.replace` method in Node.JS. Eg. `"hello there".replace(/hello/g, "hi")` will return `"hi there"`.

            Hot tip:
            - In JavaScript, escape `\` when sending the regex pattern. Eg. `"hello\sthere"` will be sent over the wire as `"hellosthere"`. Send `"hello\\sthere"` instead.
        options:
          type: array
          description: |-
            These are the options for the regex replacement. Defaults to all disabled.

            @default []
          items:
            $ref: '#/components/schemas/RegexOption'
        value:
          maxLength: 1000
          type: string
          description: This is the value that will replace the match.
    FormatPlan:
      type: object
      properties:
        enabled:
          type: boolean
          description: |-
            This determines whether the chunk is formatted before being sent to the voice provider. This helps with enunciation. This includes phone numbers, emails and addresses. Default `true`.

            Usage:
            - To rely on the voice provider's formatting logic, set this to `false`.

            If `voice.chunkPlan.enabled` is `false`, this is automatically `false` since there's no chunk to format.

            @default true
          example: true
        numberToDigitsCutoff:
          minimum: 0
          type: number
          description: |-
            This is the cutoff after which a number is converted to individual digits instead of being spoken as words.

            Example:
            - If cutoff 2025, "12345" is converted to "1 2 3 4 5" while "1200" is converted to "twelve hundred".

            Usage:
            - If your use case doesn't involve IDs like zip codes, set this to a high value.
            - If your use case involves IDs that are shorter than 5 digits, set this to a lower value.

            @default 2025
          example: 2025
        replacements:
          type: array
          description: |-
            These are the custom replacements you can make to the chunk before it is sent to the voice provider.

            Usage:
            - To replace a specific word or phrase with a different word or phrase, use the `ExactReplacement` type. Eg. `{ type: 'exact', key: 'hello', value: 'hi' }`
            - To replace a word or phrase that matches a pattern, use the `RegexReplacement` type. Eg. `{ type: 'regex', regex: '\\b[a-zA-Z]{5}\\b', value: 'hi' }`

            @default []
          items:
            oneOf:
            - $ref: '#/components/schemas/ExactReplacement'
            - $ref: '#/components/schemas/RegexReplacement'
        formattersEnabled:
          type: array
          description: |-
            List of formatters to apply. If not provided, all default formatters will be applied.
            If provided, only the specified formatters will be applied.
            Note: Some essential formatters like angle bracket removal will always be applied.
            @default undefined
          items:
            type: string
            enum:
            - markdown
            - asterisk
            - quote
            - dash
            - newline
            - colon
            - acronym
            - dollarAmount
            - email
            - date
            - time
            - distance
            - unit
            - percentage
            - phoneNumber
            - number
          enum:
          - markdown
          - asterisk
          - quote
          - dash
          - newline
          - colon
          - acronym
          - dollarAmount
          - email
          - date
          - time
          - distance
          - unit
          - percentage
          - phoneNumber
          - number
    ChunkPlan:
      type: object
      properties:
        enabled:
          type: boolean
          description: |-
            This determines whether the model output is chunked before being sent to the voice provider. Default `true`.

            Usage:
            - To rely on the voice provider's audio generation logic, set this to `false`.
            - If seeing issues with quality, set this to `true`.

            If disabled, Vapi-provided audio control tokens like <flush /> will not work.

            @default true
          example: true
        minCharacters:
          maximum: 80
          minimum: 1
          type: number
          description: |-
            This is the minimum number of characters in a chunk.

            Usage:
            - To increase quality, set this to a higher value.
            - To decrease latency, set this to a lower value.

            @default 30
          example: 30
        punctuationBoundaries:
          type: array
          description: |-
            These are the punctuations that are considered valid boundaries for a chunk to be created.

            Usage:
            - To increase quality, constrain to fewer boundaries.
            - To decrease latency, enable all.

            Default is automatically set to balance the trade-off between quality and latency based on the provider.
          example:
          - 。
          - ，
          - "."
          - '!'
          - '?'
          - ;
          - ،
          - ۔
          - ।
          - ॥
          - '|'
          - '||'
          - ","
          - ':'
          items:
            type: string
            enum:
            - 。
            - ，
            - "."
            - '!'
            - '?'
            - ;
            - )
            - ،
            - ۔
            - ।
            - ॥
            - '|'
            - '||'
            - ","
            - ':'
          enum:
          - 。
          - ，
          - "."
          - '!'
          - '?'
          - ;
          - )
          - ،
          - ۔
          - ।
          - ॥
          - '|'
          - '||'
          - ","
          - ':'
        formatPlan:
          description: This is the plan for formatting the chunk before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/FormatPlan'
    FallbackPlan:
      required:
      - voices
      type: object
      properties:
        voices:
          type: array
          description: This is the list of voices to fallback to in the event that the primary voice provider fails.
          items:
            oneOf:
            - $ref: '#/components/schemas/FallbackAzureVoice'
            - $ref: '#/components/schemas/FallbackCartesiaVoice'
            - $ref: '#/components/schemas/FallbackHumeVoice'
            - $ref: '#/components/schemas/FallbackCustomVoice'
            - $ref: '#/components/schemas/FallbackDeepgramVoice'
            - $ref: '#/components/schemas/FallbackElevenLabsVoice'
            - $ref: '#/components/schemas/FallbackVapiVoice'
            - $ref: '#/components/schemas/FallbackLMNTVoice'
            - $ref: '#/components/schemas/FallbackOpenAIVoice'
            - $ref: '#/components/schemas/FallbackPlayHTVoice'
            - $ref: '#/components/schemas/FallbackRimeAIVoice'
            - $ref: '#/components/schemas/FallbackSmallestAIVoice'
            - $ref: '#/components/schemas/FallbackTavusVoice'
    AzureVoice:
      required:
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - azure
        voiceId:
          description: This is the provider-specific ID that will be used.
          oneOf:
          - title: Preset Voice Options
            type: string
            enum:
            - andrew
            - brian
            - emma
          - title: Azure Voice ID
            type: string
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
        speed:
          maximum: 2
          minimum: 0.5
          type: number
          description: This is the speed multiplier that will be used.
        fallbackPlan:
          description: This is the plan for voice provider fallbacks in the event that the primary voice provider fails.
          allOf:
          - $ref: '#/components/schemas/FallbackPlan'
    CartesiaExperimentalControls:
      type: object
      properties:
        speed:
          oneOf:
          - type: string
            example: normal
            enum:
            - slowest
            - slow
            - normal
            - fast
            - fastest
          - maximum: 1
            minimum: -1
            type: number
            example: 0.5
        emotion:
          type: string
          example: "[\"happiness:high\"]"
          enum:
          - anger:lowest
          - anger:low
          - anger:high
          - anger:highest
          - positivity:lowest
          - positivity:low
          - positivity:high
          - positivity:highest
          - surprise:lowest
          - surprise:low
          - surprise:high
          - surprise:highest
          - sadness:lowest
          - sadness:low
          - sadness:high
          - sadness:highest
          - curiosity:lowest
          - curiosity:low
          - curiosity:high
          - curiosity:highest
    CartesiaVoice:
      required:
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - cartesia
        voiceId:
          type: string
          description: The ID of the particular voice you want to use.
        model:
          type: string
          description: This is the model that will be used. This is optional and will default to the correct model for the voiceId.
          example: sonic-english
          enum:
          - sonic-2
          - sonic-english
          - sonic-multilingual
          - sonic-preview
          - sonic
        language:
          type: string
          description: This is the language that will be used. This is optional and will default to the correct language for the voiceId.
          example: en
          enum:
          - en
          - de
          - es
          - fr
          - ja
          - pt
          - zh
          - hi
          - it
          - ko
          - nl
          - pl
          - ru
          - sv
          - tr
        experimentalControls:
          description: Experimental controls for Cartesia voice generation
          allOf:
          - $ref: '#/components/schemas/CartesiaExperimentalControls'
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
        fallbackPlan:
          description: This is the plan for voice provider fallbacks in the event that the primary voice provider fails.
          allOf:
          - $ref: '#/components/schemas/FallbackPlan'
    CustomVoice:
      required:
      - provider
      - server
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used. Use `custom-voice` for providers that are not natively supported.
          enum:
          - custom-voice
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
        server:
          description: |-
            This is where the voice request will be sent.

            Request Example:

            POST https://{server.url}
            Content-Type: application/json

            {
              "message": {
                "type": "voice-request",
                "text": "Hello, world!",
                "sampleRate": 24000,
                ...other metadata about the call...
              }
            }

            Response Expected: 1-channel 16-bit raw PCM audio at the sample rate specified in the request. Here is how the response will be piped to the transport:
            ```
            response.on('data', (chunk: Buffer) => {
              outputStream.write(chunk);
            });
            ```
          allOf:
          - $ref: '#/components/schemas/Server'
        fallbackPlan:
          description: This is the plan for voice provider fallbacks in the event that the primary voice provider fails.
          allOf:
          - $ref: '#/components/schemas/FallbackPlan'
    DeepgramVoice:
      required:
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - deepgram
        voiceId:
          title: This is the Deepgram Voice ID
          type: string
          description: This is the provider-specific ID that will be used.
          enum:
          - asteria
          - luna
          - stella
          - athena
          - hera
          - orion
          - arcas
          - perseus
          - angus
          - orpheus
          - helios
          - zeus
          - thalia
          - andromeda
          - helena
          - apollo
          - arcas
          - aries
          - amalthea
          - andromeda
          - apollo
          - arcas
          - aries
          - asteria
          - athena
          - atlas
          - aurora
          - callista
          - cora
          - cordelia
          - delia
          - draco
          - electra
          - harmonia
          - helena
          - hera
          - hermes
          - hyperion
          - iris
          - janus
          - juno
          - jupiter
          - luna
          - mars
          - minerva
          - neptune
          - odysseus
          - ophelia
          - orion
          - orpheus
          - pandora
          - phoebe
          - pluto
          - saturn
          - selene
          - thalia
          - theia
          - vesta
          - zeus
        model:
          type: string
          description: This is the model that will be used. Defaults to 'aura-2' when not specified.
          example: aura-2
          enum:
          - aura
          - aura-2
        mipOptOut:
          type: boolean
          description: |-
            If set to true, this will add mip_opt_out=true as a query parameter of all API requests. See https://developers.deepgram.com/docs/the-deepgram-model-improvement-partnership-program#want-to-opt-out

            This will only be used if you are using your own Deepgram API key.

            @default false
          example: false
          default: false
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
        fallbackPlan:
          description: This is the plan for voice provider fallbacks in the event that the primary voice provider fails.
          allOf:
          - $ref: '#/components/schemas/FallbackPlan'
    ElevenLabsVoice:
      required:
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - 11labs
        voiceId:
          description: This is the provider-specific ID that will be used. Ensure the Voice is present in your 11Labs Voice Library.
          oneOf:
          - title: Preset Voice Options
            type: string
            enum:
            - burt
            - marissa
            - andrea
            - sarah
            - phillip
            - steve
            - joseph
            - myra
            - paula
            - ryan
            - drew
            - paul
            - mrb
            - matilda
            - mark
          - title: 11Labs Voice ID
            type: string
        stability:
          maximum: 1
          minimum: 0
          type: number
          description: Defines the stability for voice settings.
          example: 0.5
        similarityBoost:
          maximum: 1
          minimum: 0
          type: number
          description: Defines the similarity boost for voice settings.
          example: 0.75
        style:
          maximum: 1
          minimum: 0
          type: number
          description: Defines the style for voice settings.
          example: 0
        useSpeakerBoost:
          type: boolean
          description: Defines the use speaker boost for voice settings.
          example: false
        speed:
          maximum: 1.2
          minimum: 0.7
          type: number
          description: Defines the speed for voice settings.
          example: 0.9
        optimizeStreamingLatency:
          maximum: 4
          minimum: 0
          type: number
          description: Defines the optimize streaming latency for voice settings. Defaults to 3.
          example: 3
        enableSsmlParsing:
          type: boolean
          description: |-
            This enables the use of https://elevenlabs.io/docs/speech-synthesis/prompting#pronunciation. Defaults to false to save latency.

            @default false
          example: false
        autoMode:
          type: boolean
          description: Defines the auto mode for voice settings. Defaults to false.
          example: false
        model:
          type: string
          description: This is the model that will be used. Defaults to 'eleven_turbo_v2' if not specified.
          example: eleven_turbo_v2_5
          enum:
          - eleven_multilingual_v2
          - eleven_turbo_v2
          - eleven_turbo_v2_5
          - eleven_flash_v2
          - eleven_flash_v2_5
          - eleven_monolingual_v1
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
        language:
          type: string
          description: "This is the language (ISO 639-1) that is enforced for the model. Currently only Turbo v2.5 supports language enforcement. For other models, an error will be returned if language code is provided."
        fallbackPlan:
          description: This is the plan for voice provider fallbacks in the event that the primary voice provider fails.
          allOf:
          - $ref: '#/components/schemas/FallbackPlan'
    HumeVoice:
      required:
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - hume
        model:
          type: string
          description: This is the model that will be used.
          example: octave
          enum:
          - octave
        voiceId:
          type: string
          description: The ID of the particular voice you want to use.
        isCustomHumeVoice:
          type: boolean
          description: Indicates whether the chosen voice is a preset Hume AI voice or a custom voice.
          example: false
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
        description:
          type: string
          description: |-
            Natural language instructions describing how the synthesized speech should sound, including but not limited to tone, intonation, pacing, and accent (e.g., 'a soft, gentle voice with a strong British accent').

            If a Voice is specified in the request, this description serves as acting instructions.
            If no Voice is specified, a new voice is generated based on this description.
        fallbackPlan:
          description: This is the plan for voice provider fallbacks in the event that the primary voice provider fails.
          allOf:
          - $ref: '#/components/schemas/FallbackPlan'
    LMNTVoice:
      required:
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - lmnt
        voiceId:
          description: This is the provider-specific ID that will be used.
          oneOf:
          - title: Preset Voice Options
            type: string
            enum:
            - lily
            - daniel
          - title: LMNT Voice ID
            type: string
        speed:
          maximum: 2
          minimum: 0.25
          type: number
          description: This is the speed multiplier that will be used.
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
        fallbackPlan:
          description: This is the plan for voice provider fallbacks in the event that the primary voice provider fails.
          allOf:
          - $ref: '#/components/schemas/FallbackPlan'
    NeuphonicVoice:
      required:
      - language
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - neuphonic
        voiceId:
          description: This is the provider-specific ID that will be used.
          oneOf:
          - title: Preset Voice Options
            type: string
          - title: Neuphonic Voice ID
            type: string
        model:
          type: string
          description: This is the model that will be used. Defaults to 'neu_fast' if not specified.
          example: neu_fast
          enum:
          - neu_hq
          - neu_fast
        language:
          type: object
          description: This is the language (ISO 639-1) that is enforced for the model.
          example: en
        speed:
          maximum: 2
          minimum: 0.25
          type: number
          description: This is the speed multiplier that will be used.
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
        fallbackPlan:
          description: This is the plan for voice provider fallbacks in the event that the primary voice provider fails.
          allOf:
          - $ref: '#/components/schemas/FallbackPlan'
    OpenAIVoice:
      required:
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - openai
        voiceId:
          description: |-
            This is the provider-specific ID that will be used.
            Please note that ash, ballad, coral, sage, and verse may only be used with realtime models.
          oneOf:
          - title: Preset Voice Options
            type: string
            enum:
            - alloy
            - echo
            - fable
            - onyx
            - nova
            - shimmer
          - title: OpenAI Voice ID
            type: string
        model:
          type: string
          description: This is the model that will be used for text-to-speech.
          enum:
          - tts-1
          - tts-1-hd
          - gpt-4o-mini-tts
        instructions:
          maxLength: 10000
          type: string
          description: |-
            This is a prompt that allows you to control the voice of your generated audio.
            Does not work with 'tts-1' or 'tts-1-hd' models.
        speed:
          maximum: 4
          minimum: 0.25
          type: number
          description: This is the speed multiplier that will be used.
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
        fallbackPlan:
          description: This is the plan for voice provider fallbacks in the event that the primary voice provider fails.
          allOf:
          - $ref: '#/components/schemas/FallbackPlan'
    PlayHTVoice:
      required:
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - playht
        voiceId:
          description: This is the provider-specific ID that will be used.
          oneOf:
          - title: Preset Voice Options
            type: string
            enum:
            - jennifer
            - melissa
            - will
            - chris
            - matt
            - jack
            - ruby
            - davis
            - donna
            - michael
          - title: PlayHT Voice ID
            type: string
        speed:
          maximum: 5
          minimum: 0.1
          type: number
          description: This is the speed multiplier that will be used.
        temperature:
          maximum: 2
          minimum: 0.1
          type: number
          description: "A floating point number between 0, exclusive, and 2, inclusive. If equal to null or not provided, the model's default temperature will be used. The temperature parameter controls variance. Lower temperatures result in more predictable results, higher temperatures allow each run to vary more, so the voice may sound less like the baseline voice."
        emotion:
          type: string
          description: An emotion to be applied to the speech.
          enum:
          - female_happy
          - female_sad
          - female_angry
          - female_fearful
          - female_disgust
          - female_surprised
          - male_happy
          - male_sad
          - male_angry
          - male_fearful
          - male_disgust
          - male_surprised
        voiceGuidance:
          maximum: 6
          minimum: 1
          type: number
          description: A number between 1 and 6. Use lower numbers to reduce how unique your chosen voice will be compared to other voices.
        styleGuidance:
          maximum: 30
          minimum: 1
          type: number
          description: A number between 1 and 30. Use lower numbers to to reduce how strong your chosen emotion will be. Higher numbers will create a very emotional performance.
        textGuidance:
          maximum: 2
          minimum: 1
          type: number
          description: "A number between 1 and 2. This number influences how closely the generated speech adheres to the input text. Use lower values to create more fluid speech, but with a higher chance of deviating from the input text. Higher numbers will make the generated speech more accurate to the input text, ensuring that the words spoken align closely with the provided text."
        model:
          type: string
          description: Playht voice model/engine to use.
          enum:
          - PlayHT2.0
          - PlayHT2.0-turbo
          - Play3.0-mini
          - PlayDialog
        language:
          type: string
          description: The language to use for the speech.
          enum:
          - afrikaans
          - albanian
          - amharic
          - arabic
          - bengali
          - bulgarian
          - catalan
          - croatian
          - czech
          - danish
          - dutch
          - english
          - french
          - galician
          - german
          - greek
          - hebrew
          - hindi
          - hungarian
          - indonesian
          - italian
          - japanese
          - korean
          - malay
          - mandarin
          - polish
          - portuguese
          - russian
          - serbian
          - spanish
          - swedish
          - tagalog
          - thai
          - turkish
          - ukrainian
          - urdu
          - xhosa
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
        fallbackPlan:
          description: This is the plan for voice provider fallbacks in the event that the primary voice provider fails.
          allOf:
          - $ref: '#/components/schemas/FallbackPlan'
    RimeAIVoice:
      required:
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - rime-ai
        voiceId:
          description: This is the provider-specific ID that will be used.
          oneOf:
          - title: Preset Voice Options
            type: string
            enum:
            - abbie
            - allison
            - ally
            - alona
            - amber
            - ana
            - antoine
            - armon
            - brenda
            - brittany
            - carol
            - colin
            - courtney
            - elena
            - elliot
            - eva
            - geoff
            - gerald
            - hank
            - helen
            - hera
            - jen
            - joe
            - joy
            - juan
            - kendra
            - kendrick
            - kenneth
            - kevin
            - kris
            - linda
            - madison
            - marge
            - marina
            - marissa
            - marta
            - maya
            - nicholas
            - nyles
            - phil
            - reba
            - rex
            - rick
            - ritu
            - rob
            - rodney
            - rohan
            - rosco
            - samantha
            - sandy
            - selena
            - seth
            - sharon
            - stan
            - tamra
            - tanya
            - tibur
            - tj
            - tyler
            - viv
            - yadira
            - marsh
            - bayou
            - creek
            - brook
            - flower
            - spore
            - glacier
            - gulch
            - alpine
            - cove
            - lagoon
            - tundra
            - steppe
            - mesa
            - grove
            - rainforest
            - moraine
            - wildflower
            - peak
            - boulder
            - gypsum
            - zest
          - title: RimeAI Voice ID
            type: string
        model:
          type: string
          description: This is the model that will be used. Defaults to 'v1' when not specified.
          example: mistv2
          enum:
          - v1
          - mist
          - mistv2
        speed:
          minimum: 0.1
          type: number
          description: This is the speed multiplier that will be used.
        pauseBetweenBrackets:
          type: boolean
          description: "This is a flag that controls whether to add slight pauses using angle brackets. Example: “Hi. <200> I’d love to have a conversation with you.” adds a 200ms pause between the first and second sentences."
          example: false
        phonemizeBetweenBrackets:
          type: boolean
          description: "This is a flag that controls whether text inside brackets should be phonemized (converted to phonetic pronunciation) - Example: \"{h'El.o} World\" will pronounce \"Hello\" as expected."
          example: false
        reduceLatency:
          type: boolean
          description: This is a flag that controls whether to optimize for reduced latency in streaming. https://docs.rime.ai/api-reference/endpoint/websockets#param-reduce-latency
          example: false
        inlineSpeedAlpha:
          type: string
          description: This is a string that allows inline speed control using alpha notation. https://docs.rime.ai/api-reference/endpoint/websockets#param-inline-speed-alpha
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
        fallbackPlan:
          description: This is the plan for voice provider fallbacks in the event that the primary voice provider fails.
          allOf:
          - $ref: '#/components/schemas/FallbackPlan'
    SmallestAIVoice:
      required:
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - smallest-ai
        voiceId:
          description: This is the provider-specific ID that will be used.
          oneOf:
          - title: Preset Voice Options
            type: string
            enum:
            - emily
            - jasmine
            - arman
            - james
            - mithali
            - aravind
            - raj
            - diya
            - raman
            - ananya
            - isha
            - william
            - aarav
            - monika
            - niharika
            - deepika
            - raghav
            - kajal
            - radhika
            - mansi
            - nisha
            - saurabh
            - pooja
            - saina
            - sanya
          - title: Smallest AI Voice ID
            type: string
        model:
          type: string
          description: Smallest AI voice model to use. Defaults to 'lightning' when not specified.
          enum:
          - lightning
        speed:
          type: number
          description: This is the speed multiplier that will be used.
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
        fallbackPlan:
          description: This is the plan for voice provider fallbacks in the event that the primary voice provider fails.
          allOf:
          - $ref: '#/components/schemas/FallbackPlan'
    TavusConversationProperties:
      type: object
      properties:
        maxCallDuration:
          type: number
          description: |-
            The maximum duration of the call in seconds. The default `maxCallDuration` is 3600 seconds (1 hour).
            Once the time limit specified by this parameter has been reached, the conversation will automatically shut down.
        participantLeftTimeout:
          type: number
          description: The duration in seconds after which the call will be automatically shut down once the last participant leaves.
        participantAbsentTimeout:
          type: number
          description: |-
            Starting from conversation creation, the duration in seconds after which the call will be automatically shut down if no participant joins the call.
            Default is 300 seconds (5 minutes).
        enableRecording:
          type: boolean
          description: "If true, the user will be able to record the conversation."
        enableTranscription:
          type: boolean
          description: |-
            If true, the user will be able to transcribe the conversation.
            You can find more instructions on displaying transcriptions if you are using your custom DailyJS components here.
            You need to have an event listener on Daily that listens for `app-messages`.
        applyGreenscreen:
          type: boolean
          description: |-
            If true, the background will be replaced with a greenscreen (RGB values: `[0, 255, 155]`).
            You can use WebGL on the frontend to make the greenscreen transparent or change its color.
        language:
          type: string
          description: |-
            The language of the conversation. Please provide the **full language name**, not the two-letter code.
            If you are using your own TTS voice, please ensure it supports the language you provide.
            If you are using a stock replica or default persona, please note that only ElevenLabs and Cartesia supported languages are available.
            You can find a full list of supported languages for Cartesia here, for ElevenLabs here, and for PlayHT here.
        recordingS3BucketName:
          type: string
          description: The name of the S3 bucket where the recording will be stored.
        recordingS3BucketRegion:
          type: string
          description: The region of the S3 bucket where the recording will be stored.
        awsAssumeRoleArn:
          type: string
          description: The ARN of the role that will be assumed to access the S3 bucket.
    TavusVoice:
      required:
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - tavus
        voiceId:
          description: This is the provider-specific ID that will be used.
          oneOf:
          - title: Preset Voice Options
            type: string
            enum:
            - r52da2535a
          - title: Tavus Voice ID
            type: string
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
        personaId:
          type: string
          description: This is the unique identifier for the persona that the replica will use in the conversation.
        callbackUrl:
          type: string
          description: This is the url that will receive webhooks with updates regarding the conversation state.
        conversationName:
          type: string
          description: This is the name for the conversation.
        conversationalContext:
          type: string
          description: "This is the context that will be appended to any context provided in the persona, if one is provided."
        customGreeting:
          type: string
          description: This is the custom greeting that the replica will give once a participant joines the conversation.
        properties:
          description: These are optional properties used to customize the conversation.
          allOf:
          - $ref: '#/components/schemas/TavusConversationProperties'
        fallbackPlan:
          description: This is the plan for voice provider fallbacks in the event that the primary voice provider fails.
          allOf:
          - $ref: '#/components/schemas/FallbackPlan'
    VapiVoice:
      required:
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - vapi
        voiceId:
          type: string
          description: The voices provided by Vapi
          enum:
          - Elliot
          - Rohan
          - Lily
          - Savannah
          - Hana
          - Neha
          - Cole
          - Harry
          - Paige
          - Spencer
        speed:
          maximum: 2
          minimum: 0.25
          type: number
          description: |-
            This is the speed multiplier that will be used.

            @default 1
          default: 1
        language:
          type: string
          description: |-
            This is the language code (ISO 639-1) that will be used.

            @default 'en-US'
          default: en-US
          enum:
          - en-US
          - en-GB
          - en-AU
          - en-CA
          - ja
          - zh
          - de
          - hi
          - fr-FR
          - fr-CA
          - ko
          - pt-BR
          - pt-PT
          - it
          - es-ES
          - es-MX
          - id
          - nl
          - tr
          - fil
          - pl
          - sv
          - bg
          - ro
          - ar-SA
          - ar-AE
          - cs
          - el
          - fi
          - hr
          - ms
          - sk
          - da
          - ta
          - uk
          - ru
          - hu
          - "no"
          - vi
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
        fallbackPlan:
          description: This is the plan for voice provider fallbacks in the event that the primary voice provider fails.
          allOf:
          - $ref: '#/components/schemas/FallbackPlan'
    FallbackAzureVoice:
      required:
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - azure
        voiceId:
          description: This is the provider-specific ID that will be used.
          oneOf:
          - title: Preset Voice Options
            type: string
            enum:
            - andrew
            - brian
            - emma
          - title: Azure Voice ID
            type: string
        speed:
          maximum: 2
          minimum: 0.5
          type: number
          description: This is the speed multiplier that will be used.
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
    FallbackCartesiaVoice:
      required:
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - cartesia
        voiceId:
          type: string
          description: The ID of the particular voice you want to use.
        model:
          type: string
          description: This is the model that will be used. This is optional and will default to the correct model for the voiceId.
          example: sonic-english
          enum:
          - sonic-2
          - sonic-english
          - sonic-multilingual
          - sonic-preview
          - sonic
        language:
          type: string
          description: This is the language that will be used. This is optional and will default to the correct language for the voiceId.
          example: en
          enum:
          - en
          - de
          - es
          - fr
          - ja
          - pt
          - zh
          - hi
          - it
          - ko
          - nl
          - pl
          - ru
          - sv
          - tr
        experimentalControls:
          description: Experimental controls for Cartesia voice generation
          allOf:
          - $ref: '#/components/schemas/CartesiaExperimentalControls'
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
    FallbackCustomVoice:
      required:
      - provider
      - server
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used. Use `custom-voice` for providers that are not natively supported.
          enum:
          - custom-voice
        server:
          description: |-
            This is where the voice request will be sent.

            Request Example:

            POST https://{server.url}
            Content-Type: application/json

            {
              "message": {
                "type": "voice-request",
                "text": "Hello, world!",
                "sampleRate": 24000,
                ...other metadata about the call...
              }
            }

            Response Expected: 1-channel 16-bit raw PCM audio at the sample rate specified in the request. Here is how the response will be piped to the transport:
            ```
            response.on('data', (chunk: Buffer) => {
              outputStream.write(chunk);
            });
            ```
          allOf:
          - $ref: '#/components/schemas/Server'
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
    FallbackDeepgramVoice:
      required:
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - deepgram
        voiceId:
          title: This is the Deepgram Voice ID
          type: string
          description: This is the provider-specific ID that will be used.
          enum:
          - asteria
          - luna
          - stella
          - athena
          - hera
          - orion
          - arcas
          - perseus
          - angus
          - orpheus
          - helios
          - zeus
          - thalia
          - andromeda
          - helena
          - apollo
          - arcas
          - aries
          - amalthea
          - andromeda
          - apollo
          - arcas
          - aries
          - asteria
          - athena
          - atlas
          - aurora
          - callista
          - cora
          - cordelia
          - delia
          - draco
          - electra
          - harmonia
          - helena
          - hera
          - hermes
          - hyperion
          - iris
          - janus
          - juno
          - jupiter
          - luna
          - mars
          - minerva
          - neptune
          - odysseus
          - ophelia
          - orion
          - orpheus
          - pandora
          - phoebe
          - pluto
          - saturn
          - selene
          - thalia
          - theia
          - vesta
          - zeus
        model:
          type: string
          description: This is the model that will be used. Defaults to 'aura-2' when not specified.
          example: aura-2
          enum:
          - aura
          - aura-2
        mipOptOut:
          type: boolean
          description: |-
            If set to true, this will add mip_opt_out=true as a query parameter of all API requests. See https://developers.deepgram.com/docs/the-deepgram-model-improvement-partnership-program#want-to-opt-out

            This will only be used if you are using your own Deepgram API key.

            @default false
          example: false
          default: false
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
    FallbackElevenLabsVoice:
      required:
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - 11labs
        voiceId:
          description: This is the provider-specific ID that will be used. Ensure the Voice is present in your 11Labs Voice Library.
          oneOf:
          - title: Preset Voice Options
            type: string
            enum:
            - burt
            - marissa
            - andrea
            - sarah
            - phillip
            - steve
            - joseph
            - myra
            - paula
            - ryan
            - drew
            - paul
            - mrb
            - matilda
            - mark
          - title: 11Labs Voice ID
            type: string
        stability:
          maximum: 1
          minimum: 0
          type: number
          description: Defines the stability for voice settings.
          example: 0.5
        similarityBoost:
          maximum: 1
          minimum: 0
          type: number
          description: Defines the similarity boost for voice settings.
          example: 0.75
        style:
          maximum: 1
          minimum: 0
          type: number
          description: Defines the style for voice settings.
          example: 0
        useSpeakerBoost:
          type: boolean
          description: Defines the use speaker boost for voice settings.
          example: false
        speed:
          maximum: 1.2
          minimum: 0.7
          type: number
          description: Defines the speed for voice settings.
          example: 0.9
        optimizeStreamingLatency:
          maximum: 4
          minimum: 0
          type: number
          description: Defines the optimize streaming latency for voice settings. Defaults to 3.
          example: 3
        enableSsmlParsing:
          type: boolean
          description: |-
            This enables the use of https://elevenlabs.io/docs/speech-synthesis/prompting#pronunciation. Defaults to false to save latency.

            @default false
          example: false
        autoMode:
          type: boolean
          description: Defines the auto mode for voice settings. Defaults to false.
          example: false
        model:
          type: string
          description: This is the model that will be used. Defaults to 'eleven_turbo_v2' if not specified.
          example: eleven_turbo_v2_5
          enum:
          - eleven_multilingual_v2
          - eleven_turbo_v2
          - eleven_turbo_v2_5
          - eleven_flash_v2
          - eleven_flash_v2_5
          - eleven_monolingual_v1
        language:
          type: string
          description: "This is the language (ISO 639-1) that is enforced for the model. Currently only Turbo v2.5 supports language enforcement. For other models, an error will be returned if language code is provided."
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
    FallbackHumeVoice:
      required:
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - hume
        model:
          type: string
          description: This is the model that will be used.
          example: octave
          enum:
          - octave
        voiceId:
          type: string
          description: The ID of the particular voice you want to use.
        isCustomHumeVoice:
          type: boolean
          description: Indicates whether the chosen voice is a preset Hume AI voice or a custom voice.
          example: false
        description:
          type: string
          description: |-
            Natural language instructions describing how the synthesized speech should sound, including but not limited to tone, intonation, pacing, and accent (e.g., 'a soft, gentle voice with a strong British accent').

            If a Voice is specified in the request, this description serves as acting instructions.
            If no Voice is specified, a new voice is generated based on this description.
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
    FallbackLMNTVoice:
      required:
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - lmnt
        voiceId:
          description: This is the provider-specific ID that will be used.
          oneOf:
          - title: Preset Voice Options
            type: string
            enum:
            - lily
            - daniel
          - title: LMNT Voice ID
            type: string
        speed:
          maximum: 2
          minimum: 0.25
          type: number
          description: This is the speed multiplier that will be used.
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
    FallbackNeuphonicVoice:
      required:
      - language
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - neuphonic
        voiceId:
          description: This is the provider-specific ID that will be used.
          oneOf:
          - title: Preset Voice Options
            type: string
          - title: Neuphonic Voice ID
            type: string
        model:
          type: string
          description: This is the model that will be used. Defaults to 'neu_fast' if not specified.
          example: neu_fast
          enum:
          - neu_hq
          - neu_fast
        language:
          type: object
          description: This is the language (ISO 639-1) that is enforced for the model.
          example: en
        speed:
          maximum: 2
          minimum: 0.25
          type: number
          description: This is the speed multiplier that will be used.
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
    FallbackOpenAIVoice:
      required:
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - openai
        voiceId:
          description: |-
            This is the provider-specific ID that will be used.
            Please note that ash, ballad, coral, sage, and verse may only be used with realtime models.
          oneOf:
          - title: Preset Voice Options
            type: string
            enum:
            - alloy
            - echo
            - fable
            - onyx
            - nova
            - shimmer
          - title: OpenAI Voice ID
            type: string
        model:
          type: string
          description: This is the model that will be used for text-to-speech.
          enum:
          - tts-1
          - tts-1-hd
          - gpt-4o-mini-tts
        instructions:
          maxLength: 10000
          type: string
          description: |-
            This is a prompt that allows you to control the voice of your generated audio.
            Does not work with 'tts-1' or 'tts-1-hd' models.
        speed:
          maximum: 4
          minimum: 0.25
          type: number
          description: This is the speed multiplier that will be used.
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
    FallbackPlayHTVoice:
      required:
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - playht
        voiceId:
          description: This is the provider-specific ID that will be used.
          oneOf:
          - title: Preset Voice Options
            type: string
            enum:
            - jennifer
            - melissa
            - will
            - chris
            - matt
            - jack
            - ruby
            - davis
            - donna
            - michael
          - title: PlayHT Voice ID
            type: string
        speed:
          maximum: 5
          minimum: 0.1
          type: number
          description: This is the speed multiplier that will be used.
        temperature:
          maximum: 2
          minimum: 0.1
          type: number
          description: "A floating point number between 0, exclusive, and 2, inclusive. If equal to null or not provided, the model's default temperature will be used. The temperature parameter controls variance. Lower temperatures result in more predictable results, higher temperatures allow each run to vary more, so the voice may sound less like the baseline voice."
        emotion:
          type: string
          description: An emotion to be applied to the speech.
          enum:
          - female_happy
          - female_sad
          - female_angry
          - female_fearful
          - female_disgust
          - female_surprised
          - male_happy
          - male_sad
          - male_angry
          - male_fearful
          - male_disgust
          - male_surprised
        voiceGuidance:
          maximum: 6
          minimum: 1
          type: number
          description: A number between 1 and 6. Use lower numbers to reduce how unique your chosen voice will be compared to other voices.
        styleGuidance:
          maximum: 30
          minimum: 1
          type: number
          description: A number between 1 and 30. Use lower numbers to to reduce how strong your chosen emotion will be. Higher numbers will create a very emotional performance.
        textGuidance:
          maximum: 2
          minimum: 1
          type: number
          description: "A number between 1 and 2. This number influences how closely the generated speech adheres to the input text. Use lower values to create more fluid speech, but with a higher chance of deviating from the input text. Higher numbers will make the generated speech more accurate to the input text, ensuring that the words spoken align closely with the provided text."
        model:
          type: string
          description: Playht voice model/engine to use.
          enum:
          - PlayHT2.0
          - PlayHT2.0-turbo
          - Play3.0-mini
          - PlayDialog
        language:
          type: string
          description: The language to use for the speech.
          enum:
          - afrikaans
          - albanian
          - amharic
          - arabic
          - bengali
          - bulgarian
          - catalan
          - croatian
          - czech
          - danish
          - dutch
          - english
          - french
          - galician
          - german
          - greek
          - hebrew
          - hindi
          - hungarian
          - indonesian
          - italian
          - japanese
          - korean
          - malay
          - mandarin
          - polish
          - portuguese
          - russian
          - serbian
          - spanish
          - swedish
          - tagalog
          - thai
          - turkish
          - ukrainian
          - urdu
          - xhosa
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
    FallbackRimeAIVoice:
      required:
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - rime-ai
        voiceId:
          description: This is the provider-specific ID that will be used.
          oneOf:
          - title: Preset Voice Options
            type: string
            enum:
            - abbie
            - allison
            - ally
            - alona
            - amber
            - ana
            - antoine
            - armon
            - brenda
            - brittany
            - carol
            - colin
            - courtney
            - elena
            - elliot
            - eva
            - geoff
            - gerald
            - hank
            - helen
            - hera
            - jen
            - joe
            - joy
            - juan
            - kendra
            - kendrick
            - kenneth
            - kevin
            - kris
            - linda
            - madison
            - marge
            - marina
            - marissa
            - marta
            - maya
            - nicholas
            - nyles
            - phil
            - reba
            - rex
            - rick
            - ritu
            - rob
            - rodney
            - rohan
            - rosco
            - samantha
            - sandy
            - selena
            - seth
            - sharon
            - stan
            - tamra
            - tanya
            - tibur
            - tj
            - tyler
            - viv
            - yadira
            - marsh
            - bayou
            - creek
            - brook
            - flower
            - spore
            - glacier
            - gulch
            - alpine
            - cove
            - lagoon
            - tundra
            - steppe
            - mesa
            - grove
            - rainforest
            - moraine
            - wildflower
            - peak
            - boulder
            - gypsum
            - zest
          - title: RimeAI Voice ID
            type: string
        model:
          type: string
          description: This is the model that will be used. Defaults to 'v1' when not specified.
          example: mistv2
          enum:
          - v1
          - mist
          - mistv2
        speed:
          minimum: 0.1
          type: number
          description: This is the speed multiplier that will be used.
        pauseBetweenBrackets:
          type: boolean
          description: "This is a flag that controls whether to add slight pauses using angle brackets. Example: “Hi. <200> I’d love to have a conversation with you.” adds a 200ms pause between the first and second sentences."
          example: false
        phonemizeBetweenBrackets:
          type: boolean
          description: "This is a flag that controls whether text inside brackets should be phonemized (converted to phonetic pronunciation) - Example: \"{h'El.o} World\" will pronounce \"Hello\" as expected."
          example: false
        reduceLatency:
          type: boolean
          description: This is a flag that controls whether to optimize for reduced latency in streaming. https://docs.rime.ai/api-reference/endpoint/websockets#param-reduce-latency
          example: false
        inlineSpeedAlpha:
          type: string
          description: This is a string that allows inline speed control using alpha notation. https://docs.rime.ai/api-reference/endpoint/websockets#param-inline-speed-alpha
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
    FallbackSmallestAIVoice:
      required:
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - smallest-ai
        voiceId:
          description: This is the provider-specific ID that will be used.
          oneOf:
          - title: Preset Voice Options
            type: string
            enum:
            - emily
            - jasmine
            - arman
            - james
            - mithali
            - aravind
            - raj
            - diya
            - raman
            - ananya
            - isha
            - william
            - aarav
            - monika
            - niharika
            - deepika
            - raghav
            - kajal
            - radhika
            - mansi
            - nisha
            - saurabh
            - pooja
            - saina
            - sanya
          - title: Smallest AI Voice ID
            type: string
        model:
          type: string
          description: Smallest AI voice model to use. Defaults to 'lightning' when not specified.
          enum:
          - lightning
        speed:
          type: number
          description: This is the speed multiplier that will be used.
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
    FallbackTavusVoice:
      required:
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - tavus
        voiceId:
          description: This is the provider-specific ID that will be used.
          oneOf:
          - title: Preset Voice Options
            type: string
            enum:
            - r52da2535a
          - title: Tavus Voice ID
            type: string
        personaId:
          type: string
          description: This is the unique identifier for the persona that the replica will use in the conversation.
        callbackUrl:
          type: string
          description: This is the url that will receive webhooks with updates regarding the conversation state.
        conversationName:
          type: string
          description: This is the name for the conversation.
        conversationalContext:
          type: string
          description: "This is the context that will be appended to any context provided in the persona, if one is provided."
        customGreeting:
          type: string
          description: This is the custom greeting that the replica will give once a participant joines the conversation.
        properties:
          description: These are optional properties used to customize the conversation.
          allOf:
          - $ref: '#/components/schemas/TavusConversationProperties'
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
    FallbackVapiVoice:
      required:
      - provider
      - voiceId
      type: object
      properties:
        provider:
          type: string
          description: This is the voice provider that will be used.
          enum:
          - vapi
        voiceId:
          type: string
          description: The voices provided by Vapi
          enum:
          - Elliot
          - Rohan
          - Lily
          - Savannah
          - Hana
          - Neha
          - Cole
          - Harry
          - Paige
          - Spencer
        speed:
          maximum: 2
          minimum: 0.25
          type: number
          description: |-
            This is the speed multiplier that will be used.

            @default 1
          default: 1
        language:
          type: string
          description: |-
            This is the language code (ISO 639-1) that will be used.

            @default 'en-US'
          default: en-US
          enum:
          - en-US
          - en-GB
          - en-AU
          - en-CA
          - ja
          - zh
          - de
          - hi
          - fr-FR
          - fr-CA
          - ko
          - pt-BR
          - pt-PT
          - it
          - es-ES
          - es-MX
          - id
          - nl
          - tr
          - fil
          - pl
          - sv
          - bg
          - ro
          - ar-SA
          - ar-AE
          - cs
          - el
          - fi
          - hr
          - ms
          - sk
          - da
          - ta
          - uk
          - ru
          - hu
          - "no"
          - vi
        chunkPlan:
          description: This is the plan for chunking the model output before it is sent to the voice provider.
          allOf:
          - $ref: '#/components/schemas/ChunkPlan'
    TransportConfigurationTwilio:
      required:
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - twilio
        timeout:
          maximum: 600
          minimum: 1
          type: number
          description: |-
            The integer number of seconds that we should allow the phone to ring before assuming there is no answer.
            The default is `60` seconds and the maximum is `600` seconds.
            For some call flows, we will add a 5-second buffer to the timeout value you provide.
            For this reason, a timeout value of 10 seconds could result in an actual timeout closer to 15 seconds.
            You can set this to a short time, such as `15` seconds, to hang up before reaching an answering machine or voicemail.

            @default 60
          example: 60
        record:
          type: boolean
          description: |-
            Whether to record the call.
            Can be `true` to record the phone call, or `false` to not.
            The default is `false`.

            @default false
          example: false
        recordingChannels:
          type: string
          description: |-
            The number of channels in the final recording.
            Can be: `mono` or `dual`.
            The default is `mono`.
            `mono` records both legs of the call in a single channel of the recording file.
            `dual` records each leg to a separate channel of the recording file.
            The first channel of a dual-channel recording contains the parent call and the second channel contains the child call.

            @default 'mono'
          example: mono
          enum:
          - mono
          - dual
    CreateAnthropicCredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - anthropic
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateAnyscaleCredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - anyscale
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateAssemblyAICredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - assembly-ai
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    AzureBlobStorageBucketPlan:
      required:
      - connectionString
      - containerName
      type: object
      properties:
        connectionString:
          type: string
          description: This is the blob storage connection string for the Azure resource.
        containerName:
          type: string
          description: This is the container name for the Azure blob storage.
        path:
          type: string
          description: |-
            This is the path where call artifacts will be stored.

            Usage:
            - To store call artifacts in a specific folder, set this to the full path. Eg. "/folder-name1/folder-name2".
            - To store call artifacts in the root of the bucket, leave this blank.

            @default "/"
    CreateAzureCredentialDTO:
      required:
      - provider
      - service
      type: object
      properties:
        provider:
          type: string
          enum:
          - azure
        service:
          type: string
          description: This is the service being used in Azure.
          default: speech
          enum:
          - speech
          - blob_storage
        region:
          type: string
          description: This is the region of the Azure resource.
          enum:
          - australia
          - canadaeast
          - canadacentral
          - eastus2
          - eastus
          - france
          - india
          - japaneast
          - japanwest
          - uaenorth
          - northcentralus
          - norway
          - southcentralus
          - swedencentral
          - switzerland
          - uk
          - westus
          - westus3
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        bucketPlan:
          description: This is the bucket plan that can be provided to store call artifacts in Azure Blob Storage.
          allOf:
          - $ref: '#/components/schemas/AzureBlobStorageBucketPlan'
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateAzureOpenAICredentialDTO:
      required:
      - models
      - openAIEndpoint
      - openAIKey
      - provider
      - region
      type: object
      properties:
        provider:
          type: string
          enum:
          - azure-openai
        region:
          type: string
          enum:
          - australia
          - canadaeast
          - canadacentral
          - eastus2
          - eastus
          - france
          - india
          - japaneast
          - japanwest
          - uaenorth
          - northcentralus
          - norway
          - southcentralus
          - swedencentral
          - switzerland
          - uk
          - westus
          - westus3
        models:
          type: array
          example:
          - gpt-4-0125-preview
          - gpt-4-0613
          items:
            type: string
            enum:
            - gpt-4o-2024-11-20
            - gpt-4o-2024-08-06
            - gpt-4o-mini-2024-07-18
            - gpt-4o-2024-05-13
            - gpt-4-turbo-2024-04-09
            - gpt-4-0125-preview
            - gpt-4-1106-preview
            - gpt-4-0613
            - gpt-35-turbo-0125
            - gpt-35-turbo-1106
          enum:
          - gpt-4o-2024-11-20
          - gpt-4o-2024-08-06
          - gpt-4o-mini-2024-07-18
          - gpt-4o-2024-05-13
          - gpt-4-turbo-2024-04-09
          - gpt-4-0125-preview
          - gpt-4-1106-preview
          - gpt-4-0613
          - gpt-35-turbo-0125
          - gpt-35-turbo-1106
        openAIKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        ocpApimSubscriptionKey:
          type: string
          description: This is not returned in the API.
        openAIEndpoint:
          maxLength: 10000
          type: string
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    SipTrunkGateway:
      required:
      - ip
      type: object
      properties:
        ip:
          type: string
          description: This is the address of the gateway. It can be an IPv4 address like 1.1.1.1 or a fully qualified domain name like my-sip-trunk.pstn.twilio.com.
        port:
          maximum: 65535
          minimum: 1
          type: number
          description: |-
            This is the port number of the gateway. Default is 5060.

            @default 5060
        netmask:
          maximum: 32
          minimum: 24
          type: number
          description: |-
            This is the netmask of the gateway. Defaults to 32.

            @default 32
        inboundEnabled:
          type: boolean
          description: |-
            This is whether inbound calls are allowed from this gateway. Default is true.

            @default true
        outboundEnabled:
          type: boolean
          description: |-
            This is whether outbound calls should be sent to this gateway. Default is true.

            Note, if netmask is less than 32, it doesn't affect the outbound IPs that are tried. 1 attempt is made to `ip:port`.

            @default true
        outboundProtocol:
          type: string
          description: |-
            This is the protocol to use for SIP signaling outbound calls. Default is udp.

            @default udp
          enum:
          - tls/srtp
          - tcp
          - tls
          - udp
        optionsPingEnabled:
          type: boolean
          description: |-
            This is whether to send options ping to the gateway. This can be used to check if the gateway is reachable. Default is false.

            This is useful for high availability setups where you want to check if the gateway is reachable before routing calls to it. Note, if no gateway for a trunk is reachable, outbound calls will be rejected.

            @default false
    SipTrunkOutboundSipRegisterPlan:
      type: object
      properties:
        domain:
          type: string
        username:
          type: string
        realm:
          type: string
    SipTrunkOutboundAuthenticationPlan:
      type: object
      properties:
        authPassword:
          type: string
          description: This is not returned in the API.
        authUsername:
          type: string
        sipRegisterPlan:
          description: "This can be used to configure if SIP register is required by the SIP trunk. If not provided, no SIP registration will be attempted."
          allOf:
          - $ref: '#/components/schemas/SipTrunkOutboundSipRegisterPlan'
    SbcConfiguration:
      type: object
      properties: {}
    CreateByoSipTrunkCredentialDTO:
      required:
      - gateways
      type: object
      properties:
        provider:
          type: string
          description: This can be used to bring your own SIP trunks or to connect to a Carrier.
          enum:
          - byo-sip-trunk
        gateways:
          type: array
          description: This is the list of SIP trunk's gateways.
          items:
            $ref: '#/components/schemas/SipTrunkGateway'
        outboundAuthenticationPlan:
          description: This can be used to configure the outbound authentication if required by the SIP trunk.
          allOf:
          - $ref: '#/components/schemas/SipTrunkOutboundAuthenticationPlan'
        outboundLeadingPlusEnabled:
          type: boolean
          description: |-
            This ensures the outbound origination attempts have a leading plus. Defaults to false to match conventional telecom behavior.

            Usage:
            - Vonage/Twilio requires leading plus for all outbound calls. Set this to true.

            @default false
        techPrefix:
          maxLength: 10000
          type: string
          description: This can be used to configure the tech prefix on outbound calls. This is an advanced property.
        sipDiversionHeader:
          maxLength: 10000
          type: string
          description: This can be used to enable the SIP diversion header for authenticating the calling number if the SIP trunk supports it. This is an advanced property.
        sbcConfiguration:
          description: "This is an advanced configuration for enterprise deployments. This uses the onprem SBC to trunk into the SIP trunk's `gateways`, rather than the managed SBC provided by Vapi."
          allOf:
          - $ref: '#/components/schemas/SbcConfiguration'
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateCartesiaCredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - cartesia
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CloudflareR2BucketPlan:
      required:
      - name
      type: object
      properties:
        accessKeyId:
          type: string
          description: Cloudflare R2 Access key ID.
        secretAccessKey:
          type: string
          description: Cloudflare R2 access key secret. This is not returned in the API.
        url:
          type: string
          description: Cloudflare R2 base url.
        name:
          type: string
          description: This is the name of the bucket.
        path:
          type: string
          description: |-
            This is the path where call artifacts will be stored.

            Usage:
            - To store call artifacts in a specific folder, set this to the full path. Eg. "/folder-name1/folder-name2".
            - To store call artifacts in the root of the bucket, leave this blank.

            @default "/"
    CreateCloudflareCredentialDTO:
      required:
      - provider
      type: object
      properties:
        provider:
          type: string
          description: Credential provider. Only allowed value is cloudflare
          enum:
          - cloudflare
        accountId:
          type: string
          description: Cloudflare Account Id.
        apiKey:
          type: string
          description: Cloudflare API Key / Token.
        accountEmail:
          type: string
          description: Cloudflare Account Email.
        bucketPlan:
          description: This is the bucket plan that can be provided to store call artifacts in R2
          allOf:
          - $ref: '#/components/schemas/CloudflareR2BucketPlan'
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    OAuth2AuthenticationPlan:
      required:
      - clientId
      - clientSecret
      - type
      - url
      type: object
      properties:
        type:
          type: string
          enum:
          - oauth2
        url:
          type: string
          description: This is the OAuth2 URL.
        clientId:
          type: string
          description: This is the OAuth2 client ID.
        clientSecret:
          type: string
          description: This is the OAuth2 client secret.
        scope:
          maxLength: 1000
          type: string
          description: This is the scope of the OAuth2 token.
    CreateCustomLLMCredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - custom-llm
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        authenticationPlan:
          description: "This is the authentication plan. Currently supports OAuth2 RFC 6749. To use Bearer authentication, use apiKey"
          allOf:
          - $ref: '#/components/schemas/OAuth2AuthenticationPlan'
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateDeepgramCredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - deepgram
        apiKey:
          type: string
          description: This is not returned in the API.
        apiUrl:
          type: string
          description: This can be used to point to an onprem Deepgram instance. Defaults to api.deepgram.com.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateDeepInfraCredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - deepinfra
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateDeepSeekCredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - deep-seek
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateElevenLabsCredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - 11labs
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    GcpKey:
      required:
      - authProviderX509CertUrl
      - authUri
      - clientEmail
      - clientId
      - clientX509CertUrl
      - privateKey
      - privateKeyId
      - projectId
      - tokenUri
      - type
      - universeDomain
      type: object
      properties:
        type:
          type: string
          description: "This is the type of the key. Most likely, this is \"service_account\"."
        projectId:
          type: string
          description: This is the ID of the Google Cloud project associated with this key.
        privateKeyId:
          type: string
          description: This is the unique identifier for the private key.
        privateKey:
          type: string
          description: |-
            This is the private key in PEM format.

            Note: This is not returned in the API.
        clientEmail:
          type: string
          description: This is the email address associated with the service account.
        clientId:
          type: string
          description: This is the unique identifier for the client.
        authUri:
          type: string
          description: This is the URI for the auth provider's authorization endpoint.
        tokenUri:
          type: string
          description: This is the URI for the auth provider's token endpoint.
        authProviderX509CertUrl:
          type: string
          description: This is the URL of the public x509 certificate for the auth provider.
        clientX509CertUrl:
          type: string
          description: This is the URL of the public x509 certificate for the client.
        universeDomain:
          type: string
          description: This is the domain associated with the universe this service account belongs to.
    BucketPlan:
      required:
      - name
      type: object
      properties:
        name:
          type: string
          description: This is the name of the bucket.
        region:
          type: string
          description: |-
            This is the region of the bucket.

            Usage:
            - If `credential.type` is `aws`, then this is required.
            - If `credential.type` is `gcp`, then this is optional since GCP allows buckets to be accessed without a region but region is required for data residency requirements. Read here: https://cloud.google.com/storage/docs/request-endpoints
        path:
          type: string
          description: |-
            This is the path where call artifacts will be stored.

            Usage:
            - To store call artifacts in a specific folder, set this to the full path. Eg. "/folder-name1/folder-name2".
            - To store call artifacts in the root of the bucket, leave this blank.

            @default "/"
        hmacAccessKey:
          type: string
          description: |-
            This is the HMAC access key offered by GCP for interoperability with S3 clients. Here is the guide on how to create: https://cloud.google.com/storage/docs/authentication/managing-hmackeys#console

            Usage:
            - If `credential.type` is `gcp`, then this is required.
            - If `credential.type` is `aws`, then this is not required since credential.awsAccessKeyId is used instead.
        hmacSecret:
          type: string
          description: |-
            This is the secret for the HMAC access key. Here is the guide on how to create: https://cloud.google.com/storage/docs/authentication/managing-hmackeys#console

            Usage:
            - If `credential.type` is `gcp`, then this is required.
            - If `credential.type` is `aws`, then this is not required since credential.awsSecretAccessKey is used instead.

            Note: This is not returned in the API.
    CreateGcpCredentialDTO:
      required:
      - gcpKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - gcp
        gcpKey:
          description: |-
            This is the GCP key. This is the JSON that can be generated in the Google Cloud Console at https://console.cloud.google.com/iam-admin/serviceaccounts/details/<service-account-id>/keys.

            The schema is identical to the JSON that GCP outputs.
          allOf:
          - $ref: '#/components/schemas/GcpKey'
        bucketPlan:
          description: This is the bucket plan that can be provided to store call artifacts in GCP.
          allOf:
          - $ref: '#/components/schemas/BucketPlan'
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateGladiaCredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - gladia
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateGoHighLevelCredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - gohighlevel
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateGroqCredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - groq
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateLangfuseCredentialDTO:
      required:
      - apiKey
      - apiUrl
      - provider
      - publicKey
      type: object
      properties:
        provider:
          type: string
          enum:
          - langfuse
        publicKey:
          type: string
          description: "The public key for Langfuse project. Eg: pk-lf-..."
        apiKey:
          type: string
          description: "The secret key for Langfuse project. Eg: sk-lf-... .This is not returned in the API."
        apiUrl:
          type: string
          description: "The host URL for Langfuse project. Eg: https://cloud.langfuse.com"
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateLmntCredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - lmnt
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateMakeCredentialDTO:
      required:
      - apiKey
      - provider
      - region
      - teamId
      type: object
      properties:
        provider:
          type: string
          enum:
          - make
        teamId:
          type: string
          description: Team ID
        region:
          type: string
          description: "Region of your application. For example: eu1, eu2, us1, us2"
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateOpenAICredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - openai
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateOpenRouterCredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - openrouter
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreatePerplexityAICredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - perplexity-ai
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreatePlayHTCredentialDTO:
      required:
      - apiKey
      - provider
      - userId
      type: object
      properties:
        provider:
          type: string
          enum:
          - playht
        apiKey:
          type: string
          description: This is not returned in the API.
        userId:
          type: string
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateRimeAICredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - rime-ai
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateRunpodCredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - runpod
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateS3CredentialDTO:
      required:
      - awsAccessKeyId
      - awsSecretAccessKey
      - provider
      - region
      - s3BucketName
      - s3PathPrefix
      type: object
      properties:
        provider:
          type: string
          description: Credential provider. Only allowed value is s3
          enum:
          - s3
        awsAccessKeyId:
          type: string
          description: AWS access key ID.
        awsSecretAccessKey:
          type: string
          description: AWS access key secret. This is not returned in the API.
        region:
          type: string
          description: AWS region in which the S3 bucket is located.
        s3BucketName:
          type: string
          description: AWS S3 bucket name.
        s3PathPrefix:
          type: string
          description: The path prefix for the uploaded recording. Ex. "recordings/"
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    SupabaseBucketPlan:
      required:
      - accessKeyId
      - name
      - region
      - secretAccessKey
      - url
      type: object
      properties:
        region:
          type: string
          description: |-
            This is the S3 Region. It should look like us-east-1
            It should be one of the supabase regions defined in the SUPABASE_REGION enum
            Check https://supabase.com/docs/guides/platform/regions for up to date regions
          enum:
          - us-west-1
          - us-east-1
          - us-east-2
          - ca-central-1
          - eu-west-1
          - eu-west-2
          - eu-west-3
          - eu-central-1
          - eu-central-2
          - eu-north-1
          - ap-south-1
          - ap-southeast-1
          - ap-northeast-1
          - ap-northeast-2
          - ap-southeast-2
          - sa-east-1
        url:
          type: string
          description: |-
            This is the S3 compatible URL for Supabase S3
            This should look like https://<project-ID>.supabase.co/storage/v1/s3
        accessKeyId:
          type: string
          description: |-
            This is the Supabase S3 Access Key ID.
            The user creates this in the Supabase project Storage settings
        secretAccessKey:
          type: string
          description: |-
            This is the Supabase S3 Secret Access Key.
            The user creates this in the Supabase project Storage settings along with the access key id
        name:
          type: string
          description: |-
            This is the Supabase S3 Bucket Name.
            The user must create this in Supabase under Storage > Buckets
            A bucket that does not exist will not be checked now, but file uploads will fail
        path:
          type: string
          description: |-
            This is the Supabase S3 Bucket Folder Path.
            The user can create this in Supabase under Storage > Buckets
            A path that does not exist will not be checked now, but file uploads will fail
            A Path is like a folder in the bucket
            Eg. If the bucket is called "my-bucket" and the path is "my-folder", the full path is "my-bucket/my-folder"
    CreateSupabaseCredentialDTO:
      required:
      - provider
      type: object
      properties:
        provider:
          type: string
          description: This is for supabase storage.
          enum:
          - supabase
        bucketPlan:
          $ref: '#/components/schemas/SupabaseBucketPlan'
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateSmallestAICredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - smallest-ai
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateTavusCredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - tavus
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateTogetherAICredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - together-ai
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateTwilioCredentialDTO:
      required:
      - accountSid
      - authToken
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - twilio
        authToken:
          type: string
          description: This is not returned in the API.
        accountSid:
          type: string
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateVonageCredentialDTO:
      required:
      - apiKey
      - apiSecret
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - vonage
        apiSecret:
          type: string
          description: This is not returned in the API.
        apiKey:
          type: string
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateWebhookCredentialDTO:
      required:
      - authenticationPlan
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - webhook
        authenticationPlan:
          description: This is the authentication plan. Currently supports OAuth2 RFC 6749.
          allOf:
          - $ref: '#/components/schemas/OAuth2AuthenticationPlan'
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateXAiCredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          description: "This is the api key for Grok in XAi's console. Get it from here: https://console.x.ai"
          enum:
          - xai
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateGoogleCalendarOAuth2ClientCredentialDTO:
      required:
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - google.calendar.oauth2-client
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateGoogleCalendarOAuth2AuthorizationCredentialDTO:
      required:
      - authorizationId
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - google.calendar.oauth2-authorization
        authorizationId:
          type: string
          description: The authorization ID for the OAuth2 authorization
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateGoogleSheetsOAuth2AuthorizationCredentialDTO:
      required:
      - authorizationId
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - google.sheets.oauth2-authorization
        authorizationId:
          type: string
          description: The authorization ID for the OAuth2 authorization
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateSlackOAuth2AuthorizationCredentialDTO:
      required:
      - authorizationId
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - slack.oauth2-authorization
        authorizationId:
          type: string
          description: The authorization ID for the OAuth2 authorization
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    TransferAssistantHookAction:
      required:
      - type
      type: object
      properties:
        type:
          type: string
          description: This is the type of action - must be "transfer"
          enum:
          - transfer
        destination:
          description: This is the destination details for the transfer - can be a phone number or SIP URI
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
    GoogleVoicemailDetectionPlan:
      required:
      - provider
      - voicemailExpectedDurationSeconds
      type: object
      properties:
        provider:
          type: string
          description: This is the provider to use for voicemail detection.
          enum:
          - google
        voicemailExpectedDurationSeconds:
          maximum: 60
          minimum: 5
          type: number
          description: |-
            This is how long should we listen in order to determine if we were sent to voicemail or not?

            @default 15
          default: 25
    OpenAIVoicemailDetectionPlan:
      required:
      - provider
      - voicemailExpectedDurationSeconds
      type: object
      properties:
        provider:
          type: string
          description: This is the provider to use for voicemail detection.
          enum:
          - openai
        voicemailExpectedDurationSeconds:
          maximum: 60
          minimum: 5
          type: number
          description: |-
            This is how long should we listen in order to determine if we were sent to voicemail or not?

            @default 15
          default: 25
    TwilioVoicemailDetectionPlan:
      required:
      - provider
      type: object
      properties:
        provider:
          type: string
          description: This is the provider to use for voicemail detection.
          enum:
          - twilio
        voicemailDetectionTypes:
          type: array
          description: |-
            These are the AMD messages from Twilio that are considered as voicemail. Default is ['machine_end_beep', 'machine_end_silence'].

            @default {Array} ['machine_end_beep', 'machine_end_silence']
          example:
          - machine_end_beep
          - machine_end_silence
          items:
            type: string
            enum:
            - machine_start
            - human
            - fax
            - unknown
            - machine_end_beep
            - machine_end_silence
            - machine_end_other
          enum:
          - machine_start
          - human
          - fax
          - unknown
          - machine_end_beep
          - machine_end_silence
          - machine_end_other
        enabled:
          type: boolean
          description: |-
            This sets whether the assistant should detect voicemail. Defaults to true.

            @default true
        machineDetectionTimeout:
          maximum: 59
          minimum: 3
          type: number
          description: |-
            The number of seconds that Twilio should attempt to perform answering machine detection before timing out and returning AnsweredBy as unknown. Default is 30 seconds.

            Increasing this value will provide the engine more time to make a determination. This can be useful when DetectMessageEnd is provided in the MachineDetection parameter and there is an expectation of long answering machine greetings that can exceed 30 seconds.

            Decreasing this value will reduce the amount of time the engine has to make a determination. This can be particularly useful when the Enable option is provided in the MachineDetection parameter and you want to limit the time for initial detection.

            Check the [Twilio docs](https://www.twilio.com/docs/voice/answering-machine-detection#optional-api-tuning-parameters) for more info.

            @default 30
        machineDetectionSpeechThreshold:
          maximum: 6000
          minimum: 1000
          type: number
          description: |-
            The number of milliseconds that is used as the measuring stick for the length of the speech activity. Durations lower than this value will be interpreted as a human, longer as a machine. Default is 2400 milliseconds.

            Increasing this value will reduce the chance of a False Machine (detected machine, actually human) for a long human greeting (e.g., a business greeting) but increase the time it takes to detect a machine.

            Decreasing this value will reduce the chances of a False Human (detected human, actually machine) for short voicemail greetings. The value of this parameter may need to be reduced by more than 1000ms to detect very short voicemail greetings. A reduction of that significance can result in increased False Machine detections. Adjusting the MachineDetectionSpeechEndThreshold is likely the better approach for short voicemails. Decreasing MachineDetectionSpeechThreshold will also reduce the time it takes to detect a machine.

            Check the [Twilio docs](https://www.twilio.com/docs/voice/answering-machine-detection#optional-api-tuning-parameters) for more info.

            @default 2400
        machineDetectionSpeechEndThreshold:
          maximum: 5000
          minimum: 500
          type: number
          description: |-
            The number of milliseconds of silence after speech activity at which point the speech activity is considered complete. Default is 1200 milliseconds.

            Increasing this value will typically be used to better address the short voicemail greeting scenarios. For short voicemails, there is typically 1000-2000ms of audio followed by 1200-2400ms of silence and then additional audio before the beep. Increasing the MachineDetectionSpeechEndThreshold to ~2500ms will treat the 1200-2400ms of silence as a gap in the greeting but not the end of the greeting and will result in a machine detection. The downsides of such a change include:
            - Increasing the delay for human detection by the amount you increase this parameter, e.g., a change of 1200ms to 2500ms increases human detection delay by 1300ms.
            - Cases where a human has two utterances separated by a period of silence (e.g. a "Hello", then 2000ms of silence, and another "Hello") may be interpreted as a machine.

            Decreasing this value will result in faster human detection. The consequence is that it can lead to increased False Human (detected human, actually machine) detections because a silence gap in a voicemail greeting (not necessarily just in short voicemail scenarios) can be incorrectly interpreted as the end of speech.

            Check the [Twilio docs](https://www.twilio.com/docs/voice/answering-machine-detection#optional-api-tuning-parameters) for more info.

            @default 1200
        machineDetectionSilenceTimeout:
          maximum: 10000
          minimum: 2000
          type: number
          description: |-
            The number of milliseconds of initial silence after which an unknown AnsweredBy result will be returned. Default is 5000 milliseconds.

            Increasing this value will result in waiting for a longer period of initial silence before returning an 'unknown' AMD result.

            Decreasing this value will result in waiting for a shorter period of initial silence before returning an 'unknown' AMD result.

            Check the [Twilio docs](https://www.twilio.com/docs/voice/answering-machine-detection#optional-api-tuning-parameters) for more info.

            @default 5000
    CompliancePlan:
      type: object
      properties:
        hipaaEnabled:
          type: boolean
          description: |-
            When this is enabled, no logs, recordings, or transcriptions will be stored.
            At the end of the call, you will still receive an end-of-call-report message to store on your server. Defaults to false.
          example: false
        pciEnabled:
          type: boolean
          description: |-
            When this is enabled, the user will be restricted to use PCI-compliant providers, and no logs or transcripts are stored.
            At the end of the call, you will receive an end-of-call-report message to store on your server. Defaults to false.
          example: false
    StructuredDataPlan:
      type: object
      properties:
        messages:
          type: array
          description: |-
            These are the messages used to generate the structured data.

            @default: ```
            [
              {
                "role": "system",
                "content": "You are an expert data extractor. You will be given a transcript of a call. Extract structured data per the JSON Schema. DO NOT return anything except the structured data.\n\nJson Schema:\\n{{schema}}\n\nOnly respond with the JSON."
              },
              {
                "role": "user",
                "content": "Here is the transcript:\n\n{{transcript}}\n\n"
              }
            ]```

            You can customize by providing any messages you want.

            Here are the template variables available:
            - {{transcript}}: the transcript of the call from `call.artifact.transcript`- {{systemPrompt}}: the system prompt of the call from `assistant.model.messages[type=system].content`- {{schema}}: the schema of the structured data from `structuredDataPlan.schema`
          items:
            type: object
        enabled:
          type: boolean
          description: |-
            This determines whether structured data is generated and stored in `call.analysis.structuredData`. Defaults to false.

            Usage:
            - If you want to extract structured data, set this to true and provide a `schema`.

            @default false
        schema:
          description: |-
            This is the schema of the structured data. The output is stored in `call.analysis.structuredData`.

            Complete guide on JSON Schema can be found [here](https://ajv.js.org/json-schema.html#json-data-type).
          allOf:
          - $ref: '#/components/schemas/JsonSchema'
        timeoutSeconds:
          maximum: 60
          minimum: 1
          type: number
          description: |-
            This is how long the request is tried before giving up. When request times out, `call.analysis.structuredData` will be empty.

            Usage:
            - To guarantee the structured data is generated, set this value high. Note, this will delay the end of call report in cases where model is slow to respond.

            @default 5 seconds
    StructuredDataMultiPlan:
      required:
      - key
      - plan
      type: object
      properties:
        key:
          type: string
          description: This is the key of the structured data plan in the catalog.
        plan:
          description: This is an individual structured data plan in the catalog.
          allOf:
          - $ref: '#/components/schemas/StructuredDataPlan'
    SuccessEvaluationPlan:
      type: object
      properties:
        rubric:
          type: string
          description: |-
            This enforces the rubric of the evaluation. The output is stored in `call.analysis.successEvaluation`.

            Options include:
            - 'NumericScale': A scale of 1 to 10.
            - 'DescriptiveScale': A scale of Excellent, Good, Fair, Poor.
            - 'Checklist': A checklist of criteria and their status.
            - 'Matrix': A grid that evaluates multiple criteria across different performance levels.
            - 'PercentageScale': A scale of 0% to 100%.
            - 'LikertScale': A scale of Strongly Agree, Agree, Neutral, Disagree, Strongly Disagree.
            - 'AutomaticRubric': Automatically break down evaluation into several criteria, each with its own score.
            - 'PassFail': A simple 'true' if call passed, 'false' if not.

            Default is 'PassFail'.
          enum:
          - NumericScale
          - DescriptiveScale
          - Checklist
          - Matrix
          - PercentageScale
          - LikertScale
          - AutomaticRubric
          - PassFail
        messages:
          type: array
          description: |-
            These are the messages used to generate the success evaluation.

            @default: ```
            [
              {
                "role": "system",
                "content": "You are an expert call evaluator. You will be given a transcript of a call and the system prompt of the AI participant. Determine if the call was successful based on the objectives inferred from the system prompt. DO NOT return anything except the result.\n\nRubric:\\n{{rubric}}\n\nOnly respond with the result."
              },
              {
                "role": "user",
                "content": "Here is the transcript:\n\n{{transcript}}\n\n"
              },
              {
                "role": "user",
                "content": "Here was the system prompt of the call:\n\n{{systemPrompt}}\n\n"
              }
            ]```

            You can customize by providing any messages you want.

            Here are the template variables available:
            - {{transcript}}: the transcript of the call from `call.artifact.transcript`- {{systemPrompt}}: the system prompt of the call from `assistant.model.messages[type=system].content`- {{rubric}}: the rubric of the success evaluation from `successEvaluationPlan.rubric`
          items:
            type: object
        enabled:
          type: boolean
          description: |-
            This determines whether a success evaluation is generated and stored in `call.analysis.successEvaluation`. Defaults to true.

            Usage:
            - If you want to disable the success evaluation, set this to false.

            @default true
        timeoutSeconds:
          maximum: 60
          minimum: 1
          type: number
          description: |-
            This is how long the request is tried before giving up. When request times out, `call.analysis.successEvaluation` will be empty.

            Usage:
            - To guarantee the success evaluation is generated, set this value high. Note, this will delay the end of call report in cases where model is slow to respond.

            @default 5 seconds
    AnalysisPlan:
      type: object
      properties:
        summaryPlan:
          description: This is the plan for generating the summary of the call. This outputs to `call.analysis.summary`.
          allOf:
          - $ref: '#/components/schemas/SummaryPlan'
        structuredDataPlan:
          description: This is the plan for generating the structured data from the call. This outputs to `call.analysis.structuredData`.
          allOf:
          - $ref: '#/components/schemas/StructuredDataPlan'
        structuredDataMultiPlan:
          type: array
          description: This is an array of structured data plan catalogs. Each entry includes a `key` and a `plan` for generating the structured data from the call. This outputs to `call.analysis.structuredDataMulti`.
          items:
            $ref: '#/components/schemas/StructuredDataMultiPlan'
        successEvaluationPlan:
          description: This is the plan for generating the success evaluation of the call. This outputs to `call.analysis.successEvaluation`.
          allOf:
          - $ref: '#/components/schemas/SuccessEvaluationPlan'
    MessagePlan:
      type: object
      properties:
        idleMessages:
          type: array
          description: |-
            This are the messages that the assistant will speak when the user hasn't responded for `idleTimeoutSeconds`. Each time the timeout is triggered, a random message will be chosen from this array.

            Usage:
            - If user gets distracted and doesn't respond for a while, this can be used to grab their attention.
            - If the transcriber doesn't pick up what the user said, this can be used to ask the user to repeat themselves. (From the perspective of the assistant, the conversation is idle since it didn't "hear" any user messages.)

            @default null (no idle message is spoken)
          items:
            maxLength: 1000
            type: string
        idleMessageMaxSpokenCount:
          maximum: 10
          minimum: 1
          type: number
          description: |-
            This determines the maximum number of times `idleMessages` can be spoken during the call.

            @default 3
        idleTimeoutSeconds:
          maximum: 60
          minimum: 5
          type: number
          description: |-
            This is the timeout in seconds before a message from `idleMessages` is spoken. The clock starts when the assistant finishes speaking and remains active until the user speaks.

            @default 10
        silenceTimeoutMessage:
          maxLength: 1000
          type: string
          description: |-
            This is the message that the assistant will say if the call ends due to silence.

            If unspecified, it will hang up without saying anything.
    AssistantCustomEndpointingRule:
      required:
      - regex
      - timeoutSeconds
      - type
      type: object
      properties:
        type:
          type: string
          description: |-
            This endpointing rule is based on the last assistant message before customer started speaking.

            Flow:
            - Assistant speaks
            - Customer starts speaking
            - Customer transcription comes in
            - This rule is evaluated on the last assistant message
            - If a match is found based on `regex`, the endpointing timeout is set to `timeoutSeconds`

            Usage:
            - If you have yes/no questions in your use case like "are you interested in a loan?", you can set a shorter timeout.
            - If you have questions where the customer may pause to look up information like "what's my account number?", you can set a longer timeout.
          enum:
          - assistant
        regex:
          type: string
          description: |-
            This is the regex pattern to match.

            Note:
            - This works by using the `RegExp.test` method in Node.JS. Eg. `/hello/.test("hello there")` will return `true`.

            Hot tip:
            - In JavaScript, escape `\` when sending the regex pattern. Eg. `"hello\sthere"` will be sent over the wire as `"hellosthere"`. Send `"hello\\sthere"` instead.
            - `RegExp.test` does substring matching, so `/cat/.test("I love cats")` will return `true`. To do full string matching, send "^cat$".
        regexOptions:
          type: array
          description: |-
            These are the options for the regex match. Defaults to all disabled.

            @default []
          items:
            $ref: '#/components/schemas/RegexOption'
        timeoutSeconds:
          maximum: 15
          minimum: 0
          type: number
          description: "This is the endpointing timeout in seconds, if the rule is matched."
    CustomerCustomEndpointingRule:
      required:
      - regex
      - timeoutSeconds
      - type
      type: object
      properties:
        type:
          type: string
          description: |-
            This endpointing rule is based on current customer message as they are speaking.

            Flow:
            - Assistant speaks
            - Customer starts speaking
            - Customer transcription comes in
            - This rule is evaluated on the current customer transcription
            - If a match is found based on `regex`, the endpointing timeout is set to `timeoutSeconds`

            Usage:
            - If you want to wait longer while customer is speaking numbers, you can set a longer timeout.
          enum:
          - customer
        regex:
          type: string
          description: |-
            This is the regex pattern to match.

            Note:
            - This works by using the `RegExp.test` method in Node.JS. Eg. `/hello/.test("hello there")` will return `true`.

            Hot tip:
            - In JavaScript, escape `\` when sending the regex pattern. Eg. `"hello\sthere"` will be sent over the wire as `"hellosthere"`. Send `"hello\\sthere"` instead.
            - `RegExp.test` does substring matching, so `/cat/.test("I love cats")` will return `true`. To do full string matching, send "^cat$".
        regexOptions:
          type: array
          description: |-
            These are the options for the regex match. Defaults to all disabled.

            @default []
          items:
            $ref: '#/components/schemas/RegexOption'
        timeoutSeconds:
          maximum: 15
          minimum: 0
          type: number
          description: "This is the endpointing timeout in seconds, if the rule is matched."
    BothCustomEndpointingRule:
      required:
      - assistantRegex
      - customerRegex
      - timeoutSeconds
      - type
      type: object
      properties:
        type:
          type: string
          description: |-
            This endpointing rule is based on both the last assistant message and the current customer message as they are speaking.

            Flow:
            - Assistant speaks
            - Customer starts speaking
            - Customer transcription comes in
            - This rule is evaluated on the last assistant message and the current customer transcription
            - If assistant message matches `assistantRegex` AND customer message matches `customerRegex`, the endpointing timeout is set to `timeoutSeconds`

            Usage:
            - If you want to wait longer while customer is speaking numbers, you can set a longer timeout.
          enum:
          - both
        assistantRegex:
          type: string
          description: |-
            This is the regex pattern to match the assistant's message.

            Note:
            - This works by using the `RegExp.test` method in Node.JS. Eg. `/hello/.test("hello there")` will return `true`.

            Hot tip:
            - In JavaScript, escape `\` when sending the regex pattern. Eg. `"hello\sthere"` will be sent over the wire as `"hellosthere"`. Send `"hello\\sthere"` instead.
            - `RegExp.test` does substring matching, so `/cat/.test("I love cats")` will return `true`. To do full string matching, send "^cat$".
        assistantRegexOptions:
          type: array
          description: |-
            These are the options for the assistant's message regex match. Defaults to all disabled.

            @default []
          items:
            $ref: '#/components/schemas/RegexOption'
        customerRegex:
          type: string
        customerRegexOptions:
          type: array
          description: |-
            These are the options for the customer's message regex match. Defaults to all disabled.

            @default []
          items:
            $ref: '#/components/schemas/RegexOption'
        timeoutSeconds:
          maximum: 15
          minimum: 0
          type: number
          description: "This is the endpointing timeout in seconds, if the rule is matched."
    VapiSmartEndpointingPlan:
      required:
      - provider
      type: object
      properties:
        provider:
          type: string
          description: This is the provider for the smart endpointing plan.
          example: vapi
          enum:
          - vapi
          - livekit
    LivekitSmartEndpointingPlan:
      required:
      - provider
      type: object
      properties:
        provider:
          type: string
          description: This is the provider for the smart endpointing plan.
          example: livekit
          enum:
          - vapi
          - livekit
        waitFunction:
          type: string
          description: |-
            This expression describes how long the bot will wait to start speaking based on the likelihood that the user has reached an endpoint.

            This is a millisecond valued function. It maps probabilities (real numbers on [0,1]) to milliseconds that the bot should wait before speaking ([0, \infty]). Any negative values that are returned are set to zero (the bot can't start talking in the past).

            A probability of zero represents very high confidence that the caller has stopped speaking, and would like the bot to speak to them. A probability of one represents very high confidence that the caller is still speaking.

            Under the hood, this is parsed into a mathjs expression. Whatever you use to write your expression needs to be valid with respect to mathjs

            @default "70 + 4000 * x"
    TranscriptionEndpointingPlan:
      type: object
      properties:
        onPunctuationSeconds:
          maximum: 3
          minimum: 0
          type: number
          description: |-
            The minimum number of seconds to wait after transcription ending with punctuation before sending a request to the model. Defaults to 0.1.

            This setting exists because the transcriber punctuates the transcription when it's more confident that customer has completed a thought.

            @default 0.1
          example: 0.1
        onNoPunctuationSeconds:
          maximum: 3
          minimum: 0
          type: number
          description: |-
            The minimum number of seconds to wait after transcription ending without punctuation before sending a request to the model. Defaults to 1.5.

            This setting exists to catch the cases where the transcriber was not confident enough to punctuate the transcription, but the customer is done and has been silent for a long time.

            @default 1.5
          example: 1.5
        onNumberSeconds:
          maximum: 3
          minimum: 0
          type: number
          description: |-
            The minimum number of seconds to wait after transcription ending with a number before sending a request to the model. Defaults to 0.4.

            This setting exists because the transcriber will sometimes punctuate the transcription ending with a number, even though the customer hasn't uttered the full number. This happens commonly for long numbers when the customer reads the number in chunks.

            @default 0.5
          example: 0.5
    StartSpeakingPlan:
      type: object
      properties:
        waitSeconds:
          maximum: 5
          minimum: 0
          type: number
          description: |-
            This is how long assistant waits before speaking. Defaults to 0.4.

            This is the minimum it will wait but if there is latency is the pipeline, this minimum will be exceeded. This is intended as a stopgap in case the pipeline is moving too fast.

            Example:
            - If model generates tokens and voice generates bytes within 100ms, the pipeline still waits 300ms before outputting speech.

            Usage:
            - If the customer is taking long pauses, set this to a higher value.
            - If the assistant is accidentally jumping in too much, set this to a higher value.

            @default 0.4
          example: 0.4
        smartEndpointingEnabled:
          type: object
          example: false
          deprecated: true
        smartEndpointingPlan:
          description: |-
            This is the plan for smart endpointing. Pick between Vapi smart endpointing or LiveKit smart endpointing (or nothing). We strongly recommend using livekit endpointing when working in English. LiveKit endpointing is not supported in other languages, yet.

            If this is set, it will override and take precedence over `transcriptionEndpointingPlan`.
            This plan will still be overridden by any matching `customEndpointingRules`.
          oneOf:
          - $ref: '#/components/schemas/VapiSmartEndpointingPlan'
          - $ref: '#/components/schemas/LivekitSmartEndpointingPlan'
        customEndpointingRules:
          type: array
          description: |-
            These are the custom endpointing rules to set an endpointing timeout based on a regex on the customer's speech or the assistant's last message.

            Usage:
            - If you have yes/no questions like "are you interested in a loan?", you can set a shorter timeout.
            - If you have questions where the customer may pause to look up information like "what's my account number?", you can set a longer timeout.
            - If you want to wait longer while customer is enumerating a list of numbers, you can set a longer timeout.

            These rules have the highest precedence and will override both `smartEndpointingPlan` and `transcriptionEndpointingPlan` when a rule is matched.

            The rules are evaluated in order and the first one that matches will be used.

            Order of precedence for endpointing:
            1. customEndpointingRules (if any match)
            2. smartEndpointingPlan (if set)
            3. transcriptionEndpointingPlan

            @default []
          items:
            oneOf:
            - $ref: '#/components/schemas/AssistantCustomEndpointingRule'
            - $ref: '#/components/schemas/CustomerCustomEndpointingRule'
            - $ref: '#/components/schemas/BothCustomEndpointingRule'
        transcriptionEndpointingPlan:
          description: |-
            This determines how a customer speech is considered done (endpointing) using the transcription of customer's speech.

            Once an endpoint is triggered, the request is sent to `assistant.model`.

            Note: This plan is only used if `smartEndpointingPlan` is not set. If both are provided, `smartEndpointingPlan` takes precedence.
            This plan will also be overridden by any matching `customEndpointingRules`.
          allOf:
          - $ref: '#/components/schemas/TranscriptionEndpointingPlan'
    StopSpeakingPlan:
      type: object
      properties:
        numWords:
          maximum: 10
          minimum: 0
          type: number
          description: |-
            This is the number of words that the customer has to say before the assistant will stop talking.

            Words like "stop", "actually", "no", etc. will always interrupt immediately regardless of this value.

            Words like "okay", "yeah", "right" will never interrupt.

            When set to 0, `voiceSeconds` is used in addition to the transcriptions to determine the customer has started speaking.

            Defaults to 0.

            @default 0
          example: 0
        voiceSeconds:
          maximum: 0.5
          minimum: 0
          type: number
          description: |-
            This is the seconds customer has to speak before the assistant stops talking. This uses the VAD (Voice Activity Detection) spike to determine if the customer has started speaking.

            Considerations:
            - A lower value might be more responsive but could potentially pick up non-speech sounds.
            - A higher value reduces false positives but might slightly delay the detection of speech onset.

            This is only used if `numWords` is set to 0.

            Defaults to 0.2

            @default 0.2
          example: 0.2
        backoffSeconds:
          maximum: 10
          minimum: 0
          type: number
          description: |-
            This is the seconds to wait before the assistant will start talking again after being interrupted.

            Defaults to 1.

            @default 1
          example: 1
        acknowledgementPhrases:
          type: array
          description: |-
            These are the phrases that will never interrupt the assistant, even if numWords threshold is met.
            These are typically acknowledgement or backchanneling phrases.
          example:
          - i understand
          - i see
          - i got it
          - i hear you
          - im listening
          - im with you
          - right
          - okay
          - ok
          - sure
          - alright
          - got it
          - understood
          - yeah
          - "yes"
          - uh-huh
          - mm-hmm
          - gotcha
          - mhmm
          - ah
          - yeah okay
          - yeah sure
          items:
            maxLength: 240
            type: string
          default:
          - i understand
          - i see
          - i got it
          - i hear you
          - im listening
          - im with you
          - right
          - okay
          - ok
          - sure
          - alright
          - got it
          - understood
          - yeah
          - "yes"
          - uh-huh
          - mm-hmm
          - gotcha
          - mhmm
          - ah
          - yeah okay
          - yeah sure
        interruptionPhrases:
          type: array
          description: |-
            These are the phrases that will always interrupt the assistant immediately, regardless of numWords.
            These are typically phrases indicating disagreement or desire to stop.
          example:
          - stop
          - shut
          - up
          - enough
          - quiet
          - silence
          - but
          - dont
          - not
          - "no"
          - hold
          - wait
          - cut
          - pause
          - nope
          - nah
          - nevermind
          - never
          - bad
          - actually
          items:
            maxLength: 240
            type: string
          default:
          - stop
          - shut
          - up
          - enough
          - quiet
          - silence
          - but
          - dont
          - not
          - "no"
          - hold
          - wait
          - cut
          - pause
          - nope
          - nah
          - nevermind
          - never
          - bad
          - actually
    MonitorPlan:
      type: object
      properties:
        listenEnabled:
          type: boolean
          description: |-
            This determines whether the assistant's calls allow live listening. Defaults to true.

            Fetch `call.monitor.listenUrl` to get the live listening URL.

            @default true
          example: false
        controlEnabled:
          type: boolean
          description: |-
            This determines whether the assistant's calls allow live control. Defaults to true.

            Fetch `call.monitor.controlUrl` to get the live control URL.

            To use, send any control message via a POST request to `call.monitor.controlUrl`. Here are the types of controls supported: https://docs.vapi.ai/api-reference/messages/client-inbound-message

            @default true
          example: false
    AssistantHookFilter:
      required:
      - key
      - oneOf
      - type
      type: object
      properties:
        type:
          maxLength: 1000
          type: string
          description: This is the type of filter - currently only "oneOf" is supported
          enum:
          - oneOf
        key:
          maxLength: 1000
          type: string
          description: This is the key to filter on (e.g. "call.endedReason")
        oneOf:
          type: array
          description: This is the array of possible values to match against
          items:
            maxLength: 1000
            type: string
    AssistantHookActionBase:
      type: object
      properties: {}
    AssistantHooks:
      required:
      - do
      - "on"
      type: object
      properties:
        "on":
          maxLength: 1000
          type: string
          description: This is the event that triggers this hook
          enum:
          - call.ending
        filters:
          type: array
          description: This is the set of filters that must match for the hook to trigger
          items:
            $ref: '#/components/schemas/AssistantHookFilter'
        do:
          type: array
          description: This is the set of actions to perform when the hook triggers
          items:
            $ref: '#/components/schemas/AssistantHookActionBase'
    KeypadInputPlan:
      type: object
      properties:
        enabled:
          type: boolean
          description: |-
            This keeps track of whether the user has enabled keypad input.
            By default, it is off.

            @default false
        timeoutSeconds:
          maximum: 10
          minimum: 0
          type: number
          description: |-
            This is the time in seconds to wait before processing the input.
            If the input is not received within this time, the input will be ignored.
            If set to "off", the input will be processed when the user enters a delimiter or immediately if no delimiter is used.

            @default 2
        delimiters:
          type: string
          description: |-
            This is the delimiter(s) that will be used to process the input.
            Can be '#', '*', or an empty array.
          enum:
          - '#'
          - '*'
          - ""
    CreateAssistantDTO:
      type: object
      properties:
        transcriber:
          description: These are the options for the assistant's transcriber.
          oneOf:
          - $ref: '#/components/schemas/AssemblyAITranscriber'
          - $ref: '#/components/schemas/AzureSpeechTranscriber'
          - $ref: '#/components/schemas/CustomTranscriber'
          - $ref: '#/components/schemas/DeepgramTranscriber'
          - $ref: '#/components/schemas/ElevenLabsTranscriber'
          - $ref: '#/components/schemas/GladiaTranscriber'
          - $ref: '#/components/schemas/SpeechmaticsTranscriber'
          - $ref: '#/components/schemas/TalkscriberTranscriber'
          - $ref: '#/components/schemas/GoogleTranscriber'
          - $ref: '#/components/schemas/OpenAITranscriber'
        model:
          description: These are the options for the assistant's LLM.
          oneOf:
          - $ref: '#/components/schemas/AnyscaleModel'
          - $ref: '#/components/schemas/AnthropicModel'
          - $ref: '#/components/schemas/CerebrasModel'
          - $ref: '#/components/schemas/CustomLLMModel'
          - $ref: '#/components/schemas/DeepInfraModel'
          - $ref: '#/components/schemas/DeepSeekModel'
          - $ref: '#/components/schemas/GoogleModel'
          - $ref: '#/components/schemas/GroqModel'
          - $ref: '#/components/schemas/InflectionAIModel'
          - $ref: '#/components/schemas/OpenAIModel'
          - $ref: '#/components/schemas/OpenRouterModel'
          - $ref: '#/components/schemas/PerplexityAIModel'
          - $ref: '#/components/schemas/TogetherAIModel'
          - $ref: '#/components/schemas/VapiModel'
          - $ref: '#/components/schemas/XaiModel'
        voice:
          description: These are the options for the assistant's voice.
          oneOf:
          - $ref: '#/components/schemas/AzureVoice'
          - $ref: '#/components/schemas/CartesiaVoice'
          - $ref: '#/components/schemas/CustomVoice'
          - $ref: '#/components/schemas/DeepgramVoice'
          - $ref: '#/components/schemas/ElevenLabsVoice'
          - $ref: '#/components/schemas/HumeVoice'
          - $ref: '#/components/schemas/LMNTVoice'
          - $ref: '#/components/schemas/NeuphonicVoice'
          - $ref: '#/components/schemas/OpenAIVoice'
          - $ref: '#/components/schemas/PlayHTVoice'
          - $ref: '#/components/schemas/RimeAIVoice'
          - $ref: '#/components/schemas/SmallestAIVoice'
          - $ref: '#/components/schemas/TavusVoice'
          - $ref: '#/components/schemas/VapiVoice'
          default:
            provider: playht
            voiceId: jennifer
        firstMessage:
          type: string
          description: |-
            This is the first message that the assistant will say. This can also be a URL to a containerized audio file (mp3, wav, etc.).

            If unspecified, assistant will wait for user to speak and use the model to respond once they speak.
          example: Hello! How can I help you today?
        firstMessageInterruptionsEnabled:
          type: boolean
          default: false
        firstMessageMode:
          type: string
          description: |-
            This is the mode for the first message. Default is 'assistant-speaks-first'.

            Use:
            - 'assistant-speaks-first' to have the assistant speak first.
            - 'assistant-waits-for-user' to have the assistant wait for the user to speak first.
            - 'assistant-speaks-first-with-model-generated-message' to have the assistant speak first with a message generated by the model based on the conversation state. (`assistant.model.messages` at call start, `call.messages` at squad transfer points).

            @default 'assistant-speaks-first'
          example: assistant-speaks-first
          enum:
          - assistant-speaks-first
          - assistant-speaks-first-with-model-generated-message
          - assistant-waits-for-user
        voicemailDetection:
          description: |-
            These are the settings to configure or disable voicemail detection. Alternatively, voicemail detection can be configured using the model.tools=[VoicemailTool].
            This uses Twilio's built-in detection while the VoicemailTool relies on the model to detect if a voicemail was reached.
            You can use neither of them, one of them, or both of them. By default, Twilio built-in detection is enabled while VoicemailTool is not.
          oneOf:
          - $ref: '#/components/schemas/GoogleVoicemailDetectionPlan'
          - $ref: '#/components/schemas/OpenAIVoicemailDetectionPlan'
          - $ref: '#/components/schemas/TwilioVoicemailDetectionPlan'
        clientMessages:
          type: array
          description: "These are the messages that will be sent to your Client SDKs. Default is conversation-update,function-call,hang,model-output,speech-update,status-update,transfer-update,transcript,tool-calls,user-interrupted,voice-input,workflow.node.started. You can check the shape of the messages in ClientMessage schema."
          example:
          - conversation-update
          - function-call
          - hang
          - model-output
          - speech-update
          - status-update
          - transfer-update
          - transcript
          - tool-calls
          - user-interrupted
          - voice-input
          - workflow.node.started
          items:
            type: string
            enum:
            - conversation-update
            - function-call
            - function-call-result
            - hang
            - language-changed
            - metadata
            - model-output
            - speech-update
            - status-update
            - transcript
            - tool-calls
            - tool-calls-result
            - transfer-update
            - user-interrupted
            - voice-input
            - workflow.node.started
          enum:
          - conversation-update
          - function-call
          - function-call-result
          - hang
          - language-changed
          - metadata
          - model-output
          - speech-update
          - status-update
          - transcript
          - tool-calls
          - tool-calls-result
          - transfer-update
          - user-interrupted
          - voice-input
          - workflow.node.started
        serverMessages:
          type: array
          description: "These are the messages that will be sent to your Server URL. Default is conversation-update,end-of-call-report,function-call,hang,speech-update,status-update,tool-calls,transfer-destination-request,user-interrupted. You can check the shape of the messages in ServerMessage schema."
          example:
          - conversation-update
          - end-of-call-report
          - function-call
          - hang
          - speech-update
          - status-update
          - tool-calls
          - transfer-destination-request
          - user-interrupted
          items:
            type: string
            enum:
            - conversation-update
            - end-of-call-report
            - function-call
            - hang
            - language-changed
            - language-change-detected
            - model-output
            - phone-call-control
            - speech-update
            - status-update
            - transcript
            - "transcript[transcriptType=\"final\"]"
            - tool-calls
            - transfer-destination-request
            - transfer-update
            - user-interrupted
            - voice-input
          enum:
          - conversation-update
          - end-of-call-report
          - function-call
          - hang
          - language-changed
          - language-change-detected
          - model-output
          - phone-call-control
          - speech-update
          - status-update
          - transcript
          - "transcript[transcriptType=\"final\"]"
          - tool-calls
          - transfer-destination-request
          - transfer-update
          - user-interrupted
          - voice-input
        silenceTimeoutSeconds:
          maximum: 3600
          minimum: 10
          type: number
          description: |-
            How many seconds of silence to wait before ending the call. Defaults to 30.

            @default 30
          example: 30
        maxDurationSeconds:
          maximum: 43200
          minimum: 10
          type: number
          description: |-
            This is the maximum number of seconds that the call will last. When the call reaches this duration, it will be ended.

            @default 600 (10 minutes)
          example: 600
        backgroundSound:
          maxLength: 1000
          description: |-
            This is the background sound in the call. Default for phone calls is 'office' and default for web calls is 'off'.
            You can also provide a custom sound by providing a URL to an audio file.
          oneOf:
          - type: string
            example: office
            enum:
            - "false"
            - office
          - type: string
            format: uri
            example: https://www.soundjay.com/ambient/sounds/people-in-lounge-1.mp3
        backgroundDenoisingEnabled:
          type: boolean
          description: |-
            This enables filtering of noise and background speech while the user is talking.

            Default `false` while in beta.

            @default false
          example: false
        modelOutputInMessagesEnabled:
          type: boolean
          description: |-
            This determines whether the model's output is used in conversation history rather than the transcription of assistant's speech.

            Default `false` while in beta.

            @default false
          example: false
        transportConfigurations:
          type: array
          description: "These are the configurations to be passed to the transport providers of assistant's calls, like Twilio. You can store multiple configurations for different transport providers. For a call, only the configuration matching the call transport provider is used."
          items:
            oneOf:
            - $ref: '#/components/schemas/TransportConfigurationTwilio'
        observabilityPlan:
          description: |-
            This is the plan for observability configuration of assistant's calls.
            Currently supports Langfuse for tracing and monitoring.
          allOf:
          - $ref: '#/components/schemas/LangfuseObservabilityPlan'
          oneOf:
          - $ref: '#/components/schemas/LangfuseObservabilityPlan'
        credentials:
          type: array
          description: "These are dynamic credentials that will be used for the assistant calls. By default, all the credentials are available for use in the call but you can supplement an additional credentials using this. Dynamic credentials override existing credentials."
          items:
            discriminator:
              propertyName: provider
              mapping:
                "11labs": '#/components/schemas/CreateElevenLabsCredentialDTO'
                anthropic: '#/components/schemas/CreateAnthropicCredentialDTO'
                anyscale: '#/components/schemas/CreateAnyscaleCredentialDTO'
                assembly-ai: '#/components/schemas/CreateAssemblyAICredentialDTO'
                azure-openai: '#/components/schemas/CreateAzureOpenAICredentialDTO'
                azure: '#/components/schemas/CreateAzureCredentialDTO'
                byo-sip-trunk: '#/components/schemas/CreateByoSipTrunkCredentialDTO'
                cartesia: '#/components/schemas/CreateCartesiaCredentialDTO'
                cerebras: '#/components/schemas/CreateCerebrasCredentialDTO'
                cloudflare: '#/components/schemas/CreateCloudflareCredentialDTO'
                custom-llm: '#/components/schemas/CreateCustomLLMCredentialDTO'
                deepgram: '#/components/schemas/CreateDeepgramCredentialDTO'
                deepinfra: '#/components/schemas/CreateDeepInfraCredentialDTO'
                deep-seek: '#/components/schemas/CreateDeepSeekCredentialDTO'
                gcp: '#/components/schemas/CreateGcpCredentialDTO'
                gladia: '#/components/schemas/CreateGladiaCredentialDTO'
                gohighlevel: '#/components/schemas/CreateGoHighLevelCredentialDTO'
                google: '#/components/schemas/CreateGoogleCredentialDTO'
                groq: '#/components/schemas/CreateGroqCredentialDTO'
                inflection-ai: '#/components/schemas/CreateInflectionAICredentialDTO'
                langfuse: '#/components/schemas/CreateLangfuseCredentialDTO'
                lmnt: '#/components/schemas/CreateLmntCredentialDTO'
                make: '#/components/schemas/CreateMakeCredentialDTO'
                openai: '#/components/schemas/CreateOpenAICredentialDTO'
                openrouter: '#/components/schemas/CreateOpenRouterCredentialDTO'
                perplexity-ai: '#/components/schemas/CreatePerplexityAICredentialDTO'
                playht: '#/components/schemas/CreatePlayHTCredentialDTO'
                rime-ai: '#/components/schemas/CreateRimeAICredentialDTO'
                runpod: '#/components/schemas/CreateRunpodCredentialDTO'
                s3: '#/components/schemas/CreateS3CredentialDTO'
                supabase: '#/components/schemas/CreateSupabaseCredentialDTO'
                smallest-ai: '#/components/schemas/CreateSmallestAICredentialDTO'
                tavus: '#/components/schemas/CreateTavusCredentialDTO'
                together-ai: '#/components/schemas/CreateTogetherAICredentialDTO'
                twilio: '#/components/schemas/CreateTwilioCredentialDTO'
                vonage: '#/components/schemas/CreateVonageCredentialDTO'
                webhook: '#/components/schemas/CreateWebhookCredentialDTO'
                xai: '#/components/schemas/CreateXAiCredentialDTO'
                neuphonic: '#/components/schemas/CreateNeuphonicCredentialDTO'
                hume: '#/components/schemas/CreateHumeCredentialDTO'
                mistral: '#/components/schemas/CreateMistralCredentialDTO'
                speechmatics: '#/components/schemas/CreateSpeechmaticsCredentialDTO'
                trieve: '#/components/schemas/CreateTrieveCredentialDTO'
                google.calendar.oauth2-client: '#/components/schemas/CreateGoogleCalendarOAuth2ClientCredentialDTO'
                google.calendar.oauth2-authorization: '#/components/schemas/CreateGoogleCalendarOAuth2AuthorizationCredentialDTO'
                google.sheets.oauth2-authorization: '#/components/schemas/CreateGoogleSheetsOAuth2AuthorizationCredentialDTO'
                slack.oauth2-authorization: '#/components/schemas/CreateSlackOAuth2AuthorizationCredentialDTO'
            oneOf:
            - $ref: '#/components/schemas/CreateAnthropicCredentialDTO'
            - $ref: '#/components/schemas/CreateAnyscaleCredentialDTO'
            - $ref: '#/components/schemas/CreateAssemblyAICredentialDTO'
            - $ref: '#/components/schemas/CreateAzureCredentialDTO'
            - $ref: '#/components/schemas/CreateAzureOpenAICredentialDTO'
            - $ref: '#/components/schemas/CreateByoSipTrunkCredentialDTO'
            - $ref: '#/components/schemas/CreateCartesiaCredentialDTO'
            - $ref: '#/components/schemas/CreateCerebrasCredentialDTO'
            - $ref: '#/components/schemas/CreateCloudflareCredentialDTO'
            - $ref: '#/components/schemas/CreateCustomLLMCredentialDTO'
            - $ref: '#/components/schemas/CreateDeepgramCredentialDTO'
            - $ref: '#/components/schemas/CreateDeepInfraCredentialDTO'
            - $ref: '#/components/schemas/CreateDeepSeekCredentialDTO'
            - $ref: '#/components/schemas/CreateElevenLabsCredentialDTO'
            - $ref: '#/components/schemas/CreateGcpCredentialDTO'
            - $ref: '#/components/schemas/CreateGladiaCredentialDTO'
            - $ref: '#/components/schemas/CreateGoHighLevelCredentialDTO'
            - $ref: '#/components/schemas/CreateGoogleCredentialDTO'
            - $ref: '#/components/schemas/CreateGroqCredentialDTO'
            - $ref: '#/components/schemas/CreateHumeCredentialDTO'
            - $ref: '#/components/schemas/CreateInflectionAICredentialDTO'
            - $ref: '#/components/schemas/CreateLangfuseCredentialDTO'
            - $ref: '#/components/schemas/CreateLmntCredentialDTO'
            - $ref: '#/components/schemas/CreateMakeCredentialDTO'
            - $ref: '#/components/schemas/CreateMistralCredentialDTO'
            - $ref: '#/components/schemas/CreateNeuphonicCredentialDTO'
            - $ref: '#/components/schemas/CreateOpenAICredentialDTO'
            - $ref: '#/components/schemas/CreateOpenRouterCredentialDTO'
            - $ref: '#/components/schemas/CreatePerplexityAICredentialDTO'
            - $ref: '#/components/schemas/CreatePlayHTCredentialDTO'
            - $ref: '#/components/schemas/CreateRimeAICredentialDTO'
            - $ref: '#/components/schemas/CreateRunpodCredentialDTO'
            - $ref: '#/components/schemas/CreateS3CredentialDTO'
            - $ref: '#/components/schemas/CreateSmallestAICredentialDTO'
            - $ref: '#/components/schemas/CreateSpeechmaticsCredentialDTO'
            - $ref: '#/components/schemas/CreateSupabaseCredentialDTO'
            - $ref: '#/components/schemas/CreateTavusCredentialDTO'
            - $ref: '#/components/schemas/CreateTogetherAICredentialDTO'
            - $ref: '#/components/schemas/CreateTrieveCredentialDTO'
            - $ref: '#/components/schemas/CreateTwilioCredentialDTO'
            - $ref: '#/components/schemas/CreateVonageCredentialDTO'
            - $ref: '#/components/schemas/CreateWebhookCredentialDTO'
            - $ref: '#/components/schemas/CreateXAiCredentialDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarOAuth2ClientCredentialDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarOAuth2AuthorizationCredentialDTO'
            - $ref: '#/components/schemas/CreateGoogleSheetsOAuth2AuthorizationCredentialDTO'
            - $ref: '#/components/schemas/CreateSlackOAuth2AuthorizationCredentialDTO'
        name:
          maxLength: 40
          type: string
          description: |-
            This is the name of the assistant.

            This is required when you want to transfer between assistants in a call.
        voicemailMessage:
          maxLength: 1000
          type: string
          description: |-
            This is the message that the assistant will say if the call is forwarded to voicemail.

            If unspecified, it will hang up.
        endCallMessage:
          maxLength: 1000
          type: string
          description: |-
            This is the message that the assistant will say if it ends the call.

            If unspecified, it will hang up without saying anything.
        endCallPhrases:
          type: array
          description: "This list contains phrases that, if spoken by the assistant, will trigger the call to be hung up. Case insensitive."
          items:
            maxLength: 140
            minLength: 2
            type: string
        compliancePlan:
          $ref: '#/components/schemas/CompliancePlan'
        metadata:
          type: object
          description: This is for metadata you want to store on the assistant.
        analysisPlan:
          description: This is the plan for analysis of assistant's calls. Stored in `call.analysis`.
          allOf:
          - $ref: '#/components/schemas/AnalysisPlan'
        artifactPlan:
          description: |-
            This is the plan for artifacts generated during assistant's calls. Stored in `call.artifact`.

            Note: `recordingEnabled` is currently at the root level. It will be moved to `artifactPlan` in the future, but will remain backwards compatible.
          allOf:
          - $ref: '#/components/schemas/ArtifactPlan'
        messagePlan:
          description: |-
            This is the plan for static predefined messages that can be spoken by the assistant during the call, like `idleMessages`.

            Note: `firstMessage`, `voicemailMessage`, and `endCallMessage` are currently at the root level. They will be moved to `messagePlan` in the future, but will remain backwards compatible.
          allOf:
          - $ref: '#/components/schemas/MessagePlan'
        startSpeakingPlan:
          description: |-
            This is the plan for when the assistant should start talking.

            You should configure this if you're running into these issues:
            - The assistant is too slow to start talking after the customer is done speaking.
            - The assistant is too fast to start talking after the customer is done speaking.
            - The assistant is so fast that it's actually interrupting the customer.
          allOf:
          - $ref: '#/components/schemas/StartSpeakingPlan'
        stopSpeakingPlan:
          description: |-
            This is the plan for when assistant should stop talking on customer interruption.

            You should configure this if you're running into these issues:
            - The assistant is too slow to recognize customer's interruption.
            - The assistant is too fast to recognize customer's interruption.
            - The assistant is getting interrupted by phrases that are just acknowledgments.
            - The assistant is getting interrupted by background noises.
            - The assistant is not properly stopping -- it starts talking right after getting interrupted.
          allOf:
          - $ref: '#/components/schemas/StopSpeakingPlan'
        monitorPlan:
          description: |-
            This is the plan for real-time monitoring of the assistant's calls.

            Usage:
            - To enable live listening of the assistant's calls, set `monitorPlan.listenEnabled` to `true`.
            - To enable live control of the assistant's calls, set `monitorPlan.controlEnabled` to `true`.

            Note, `serverMessages`, `clientMessages`, `serverUrl` and `serverUrlSecret` are currently at the root level but will be moved to `monitorPlan` in the future. Will remain backwards compatible
          allOf:
          - $ref: '#/components/schemas/MonitorPlan'
        credentialIds:
          type: array
          description: "These are the credentials that will be used for the assistant calls. By default, all the credentials are available for use in the call but you can provide a subset using this."
          items:
            type: string
        server:
          description: |-
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. assistant.server.url
            2. phoneNumber.serverUrl
            3. org.serverUrl
          allOf:
          - $ref: '#/components/schemas/Server'
        hooks:
          type: array
          description: This is a set of actions that will be performed on certain events.
          items:
            $ref: '#/components/schemas/AssistantHooks'
        keypadInputPlan:
          $ref: '#/components/schemas/KeypadInputPlan'
    AssistantOverrides:
      type: object
      properties:
        transcriber:
          description: These are the options for the assistant's transcriber.
          oneOf:
          - $ref: '#/components/schemas/AssemblyAITranscriber'
          - $ref: '#/components/schemas/AzureSpeechTranscriber'
          - $ref: '#/components/schemas/CustomTranscriber'
          - $ref: '#/components/schemas/DeepgramTranscriber'
          - $ref: '#/components/schemas/ElevenLabsTranscriber'
          - $ref: '#/components/schemas/GladiaTranscriber'
          - $ref: '#/components/schemas/SpeechmaticsTranscriber'
          - $ref: '#/components/schemas/TalkscriberTranscriber'
          - $ref: '#/components/schemas/GoogleTranscriber'
          - $ref: '#/components/schemas/OpenAITranscriber'
        model:
          description: These are the options for the assistant's LLM.
          oneOf:
          - $ref: '#/components/schemas/AnyscaleModel'
          - $ref: '#/components/schemas/AnthropicModel'
          - $ref: '#/components/schemas/CerebrasModel'
          - $ref: '#/components/schemas/CustomLLMModel'
          - $ref: '#/components/schemas/DeepInfraModel'
          - $ref: '#/components/schemas/DeepSeekModel'
          - $ref: '#/components/schemas/GoogleModel'
          - $ref: '#/components/schemas/GroqModel'
          - $ref: '#/components/schemas/InflectionAIModel'
          - $ref: '#/components/schemas/OpenAIModel'
          - $ref: '#/components/schemas/OpenRouterModel'
          - $ref: '#/components/schemas/PerplexityAIModel'
          - $ref: '#/components/schemas/TogetherAIModel'
          - $ref: '#/components/schemas/VapiModel'
          - $ref: '#/components/schemas/XaiModel'
        voice:
          description: These are the options for the assistant's voice.
          oneOf:
          - $ref: '#/components/schemas/AzureVoice'
          - $ref: '#/components/schemas/CartesiaVoice'
          - $ref: '#/components/schemas/CustomVoice'
          - $ref: '#/components/schemas/DeepgramVoice'
          - $ref: '#/components/schemas/ElevenLabsVoice'
          - $ref: '#/components/schemas/HumeVoice'
          - $ref: '#/components/schemas/LMNTVoice'
          - $ref: '#/components/schemas/NeuphonicVoice'
          - $ref: '#/components/schemas/OpenAIVoice'
          - $ref: '#/components/schemas/PlayHTVoice'
          - $ref: '#/components/schemas/RimeAIVoice'
          - $ref: '#/components/schemas/SmallestAIVoice'
          - $ref: '#/components/schemas/TavusVoice'
          - $ref: '#/components/schemas/VapiVoice'
          default:
            provider: playht
            voiceId: jennifer
        firstMessage:
          type: string
          description: |-
            This is the first message that the assistant will say. This can also be a URL to a containerized audio file (mp3, wav, etc.).

            If unspecified, assistant will wait for user to speak and use the model to respond once they speak.
          example: Hello! How can I help you today?
        firstMessageInterruptionsEnabled:
          type: boolean
          default: false
        firstMessageMode:
          type: string
          description: |-
            This is the mode for the first message. Default is 'assistant-speaks-first'.

            Use:
            - 'assistant-speaks-first' to have the assistant speak first.
            - 'assistant-waits-for-user' to have the assistant wait for the user to speak first.
            - 'assistant-speaks-first-with-model-generated-message' to have the assistant speak first with a message generated by the model based on the conversation state. (`assistant.model.messages` at call start, `call.messages` at squad transfer points).

            @default 'assistant-speaks-first'
          example: assistant-speaks-first
          enum:
          - assistant-speaks-first
          - assistant-speaks-first-with-model-generated-message
          - assistant-waits-for-user
        voicemailDetection:
          description: |-
            These are the settings to configure or disable voicemail detection. Alternatively, voicemail detection can be configured using the model.tools=[VoicemailTool].
            This uses Twilio's built-in detection while the VoicemailTool relies on the model to detect if a voicemail was reached.
            You can use neither of them, one of them, or both of them. By default, Twilio built-in detection is enabled while VoicemailTool is not.
          oneOf:
          - $ref: '#/components/schemas/GoogleVoicemailDetectionPlan'
          - $ref: '#/components/schemas/OpenAIVoicemailDetectionPlan'
          - $ref: '#/components/schemas/TwilioVoicemailDetectionPlan'
        clientMessages:
          type: array
          description: "These are the messages that will be sent to your Client SDKs. Default is conversation-update,function-call,hang,model-output,speech-update,status-update,transfer-update,transcript,tool-calls,user-interrupted,voice-input,workflow.node.started. You can check the shape of the messages in ClientMessage schema."
          example:
          - conversation-update
          - function-call
          - hang
          - model-output
          - speech-update
          - status-update
          - transfer-update
          - transcript
          - tool-calls
          - user-interrupted
          - voice-input
          - workflow.node.started
          items:
            type: string
            enum:
            - conversation-update
            - function-call
            - function-call-result
            - hang
            - language-changed
            - metadata
            - model-output
            - speech-update
            - status-update
            - transcript
            - tool-calls
            - tool-calls-result
            - transfer-update
            - user-interrupted
            - voice-input
            - workflow.node.started
          enum:
          - conversation-update
          - function-call
          - function-call-result
          - hang
          - language-changed
          - metadata
          - model-output
          - speech-update
          - status-update
          - transcript
          - tool-calls
          - tool-calls-result
          - transfer-update
          - user-interrupted
          - voice-input
          - workflow.node.started
        serverMessages:
          type: array
          description: "These are the messages that will be sent to your Server URL. Default is conversation-update,end-of-call-report,function-call,hang,speech-update,status-update,tool-calls,transfer-destination-request,user-interrupted. You can check the shape of the messages in ServerMessage schema."
          example:
          - conversation-update
          - end-of-call-report
          - function-call
          - hang
          - speech-update
          - status-update
          - tool-calls
          - transfer-destination-request
          - user-interrupted
          items:
            type: string
            enum:
            - conversation-update
            - end-of-call-report
            - function-call
            - hang
            - language-changed
            - language-change-detected
            - model-output
            - phone-call-control
            - speech-update
            - status-update
            - transcript
            - "transcript[transcriptType=\"final\"]"
            - tool-calls
            - transfer-destination-request
            - transfer-update
            - user-interrupted
            - voice-input
          enum:
          - conversation-update
          - end-of-call-report
          - function-call
          - hang
          - language-changed
          - language-change-detected
          - model-output
          - phone-call-control
          - speech-update
          - status-update
          - transcript
          - "transcript[transcriptType=\"final\"]"
          - tool-calls
          - transfer-destination-request
          - transfer-update
          - user-interrupted
          - voice-input
        silenceTimeoutSeconds:
          maximum: 3600
          minimum: 10
          type: number
          description: |-
            How many seconds of silence to wait before ending the call. Defaults to 30.

            @default 30
          example: 30
        maxDurationSeconds:
          maximum: 43200
          minimum: 10
          type: number
          description: |-
            This is the maximum number of seconds that the call will last. When the call reaches this duration, it will be ended.

            @default 600 (10 minutes)
          example: 600
        backgroundSound:
          maxLength: 1000
          description: |-
            This is the background sound in the call. Default for phone calls is 'office' and default for web calls is 'off'.
            You can also provide a custom sound by providing a URL to an audio file.
          oneOf:
          - type: string
            example: office
            enum:
            - "false"
            - office
          - type: string
            format: uri
            example: https://www.soundjay.com/ambient/sounds/people-in-lounge-1.mp3
        backgroundDenoisingEnabled:
          type: boolean
          description: |-
            This enables filtering of noise and background speech while the user is talking.

            Default `false` while in beta.

            @default false
          example: false
        modelOutputInMessagesEnabled:
          type: boolean
          description: |-
            This determines whether the model's output is used in conversation history rather than the transcription of assistant's speech.

            Default `false` while in beta.

            @default false
          example: false
        transportConfigurations:
          type: array
          description: "These are the configurations to be passed to the transport providers of assistant's calls, like Twilio. You can store multiple configurations for different transport providers. For a call, only the configuration matching the call transport provider is used."
          items:
            oneOf:
            - $ref: '#/components/schemas/TransportConfigurationTwilio'
        observabilityPlan:
          description: |-
            This is the plan for observability configuration of assistant's calls.
            Currently supports Langfuse for tracing and monitoring.
          allOf:
          - $ref: '#/components/schemas/LangfuseObservabilityPlan'
          oneOf:
          - $ref: '#/components/schemas/LangfuseObservabilityPlan'
        credentials:
          type: array
          description: "These are dynamic credentials that will be used for the assistant calls. By default, all the credentials are available for use in the call but you can supplement an additional credentials using this. Dynamic credentials override existing credentials."
          items:
            discriminator:
              propertyName: provider
              mapping:
                "11labs": '#/components/schemas/CreateElevenLabsCredentialDTO'
                anthropic: '#/components/schemas/CreateAnthropicCredentialDTO'
                anyscale: '#/components/schemas/CreateAnyscaleCredentialDTO'
                assembly-ai: '#/components/schemas/CreateAssemblyAICredentialDTO'
                azure-openai: '#/components/schemas/CreateAzureOpenAICredentialDTO'
                azure: '#/components/schemas/CreateAzureCredentialDTO'
                byo-sip-trunk: '#/components/schemas/CreateByoSipTrunkCredentialDTO'
                cartesia: '#/components/schemas/CreateCartesiaCredentialDTO'
                cerebras: '#/components/schemas/CreateCerebrasCredentialDTO'
                cloudflare: '#/components/schemas/CreateCloudflareCredentialDTO'
                custom-llm: '#/components/schemas/CreateCustomLLMCredentialDTO'
                deepgram: '#/components/schemas/CreateDeepgramCredentialDTO'
                deepinfra: '#/components/schemas/CreateDeepInfraCredentialDTO'
                deep-seek: '#/components/schemas/CreateDeepSeekCredentialDTO'
                gcp: '#/components/schemas/CreateGcpCredentialDTO'
                gladia: '#/components/schemas/CreateGladiaCredentialDTO'
                gohighlevel: '#/components/schemas/CreateGoHighLevelCredentialDTO'
                google: '#/components/schemas/CreateGoogleCredentialDTO'
                groq: '#/components/schemas/CreateGroqCredentialDTO'
                inflection-ai: '#/components/schemas/CreateInflectionAICredentialDTO'
                langfuse: '#/components/schemas/CreateLangfuseCredentialDTO'
                lmnt: '#/components/schemas/CreateLmntCredentialDTO'
                make: '#/components/schemas/CreateMakeCredentialDTO'
                openai: '#/components/schemas/CreateOpenAICredentialDTO'
                openrouter: '#/components/schemas/CreateOpenRouterCredentialDTO'
                perplexity-ai: '#/components/schemas/CreatePerplexityAICredentialDTO'
                playht: '#/components/schemas/CreatePlayHTCredentialDTO'
                rime-ai: '#/components/schemas/CreateRimeAICredentialDTO'
                runpod: '#/components/schemas/CreateRunpodCredentialDTO'
                s3: '#/components/schemas/CreateS3CredentialDTO'
                supabase: '#/components/schemas/CreateSupabaseCredentialDTO'
                smallest-ai: '#/components/schemas/CreateSmallestAICredentialDTO'
                tavus: '#/components/schemas/CreateTavusCredentialDTO'
                together-ai: '#/components/schemas/CreateTogetherAICredentialDTO'
                twilio: '#/components/schemas/CreateTwilioCredentialDTO'
                vonage: '#/components/schemas/CreateVonageCredentialDTO'
                webhook: '#/components/schemas/CreateWebhookCredentialDTO'
                xai: '#/components/schemas/CreateXAiCredentialDTO'
                neuphonic: '#/components/schemas/CreateNeuphonicCredentialDTO'
                hume: '#/components/schemas/CreateHumeCredentialDTO'
                mistral: '#/components/schemas/CreateMistralCredentialDTO'
                speechmatics: '#/components/schemas/CreateSpeechmaticsCredentialDTO'
                trieve: '#/components/schemas/CreateTrieveCredentialDTO'
                google.calendar.oauth2-client: '#/components/schemas/CreateGoogleCalendarOAuth2ClientCredentialDTO'
                google.calendar.oauth2-authorization: '#/components/schemas/CreateGoogleCalendarOAuth2AuthorizationCredentialDTO'
                google.sheets.oauth2-authorization: '#/components/schemas/CreateGoogleSheetsOAuth2AuthorizationCredentialDTO'
                slack.oauth2-authorization: '#/components/schemas/CreateSlackOAuth2AuthorizationCredentialDTO'
            oneOf:
            - $ref: '#/components/schemas/CreateAnthropicCredentialDTO'
            - $ref: '#/components/schemas/CreateAnyscaleCredentialDTO'
            - $ref: '#/components/schemas/CreateAssemblyAICredentialDTO'
            - $ref: '#/components/schemas/CreateAzureCredentialDTO'
            - $ref: '#/components/schemas/CreateAzureOpenAICredentialDTO'
            - $ref: '#/components/schemas/CreateByoSipTrunkCredentialDTO'
            - $ref: '#/components/schemas/CreateCartesiaCredentialDTO'
            - $ref: '#/components/schemas/CreateCerebrasCredentialDTO'
            - $ref: '#/components/schemas/CreateCloudflareCredentialDTO'
            - $ref: '#/components/schemas/CreateCustomLLMCredentialDTO'
            - $ref: '#/components/schemas/CreateDeepgramCredentialDTO'
            - $ref: '#/components/schemas/CreateDeepInfraCredentialDTO'
            - $ref: '#/components/schemas/CreateDeepSeekCredentialDTO'
            - $ref: '#/components/schemas/CreateElevenLabsCredentialDTO'
            - $ref: '#/components/schemas/CreateGcpCredentialDTO'
            - $ref: '#/components/schemas/CreateGladiaCredentialDTO'
            - $ref: '#/components/schemas/CreateGoHighLevelCredentialDTO'
            - $ref: '#/components/schemas/CreateGoogleCredentialDTO'
            - $ref: '#/components/schemas/CreateGroqCredentialDTO'
            - $ref: '#/components/schemas/CreateHumeCredentialDTO'
            - $ref: '#/components/schemas/CreateInflectionAICredentialDTO'
            - $ref: '#/components/schemas/CreateLangfuseCredentialDTO'
            - $ref: '#/components/schemas/CreateLmntCredentialDTO'
            - $ref: '#/components/schemas/CreateMakeCredentialDTO'
            - $ref: '#/components/schemas/CreateMistralCredentialDTO'
            - $ref: '#/components/schemas/CreateNeuphonicCredentialDTO'
            - $ref: '#/components/schemas/CreateOpenAICredentialDTO'
            - $ref: '#/components/schemas/CreateOpenRouterCredentialDTO'
            - $ref: '#/components/schemas/CreatePerplexityAICredentialDTO'
            - $ref: '#/components/schemas/CreatePlayHTCredentialDTO'
            - $ref: '#/components/schemas/CreateRimeAICredentialDTO'
            - $ref: '#/components/schemas/CreateRunpodCredentialDTO'
            - $ref: '#/components/schemas/CreateS3CredentialDTO'
            - $ref: '#/components/schemas/CreateSmallestAICredentialDTO'
            - $ref: '#/components/schemas/CreateSpeechmaticsCredentialDTO'
            - $ref: '#/components/schemas/CreateSupabaseCredentialDTO'
            - $ref: '#/components/schemas/CreateTavusCredentialDTO'
            - $ref: '#/components/schemas/CreateTogetherAICredentialDTO'
            - $ref: '#/components/schemas/CreateTrieveCredentialDTO'
            - $ref: '#/components/schemas/CreateTwilioCredentialDTO'
            - $ref: '#/components/schemas/CreateVonageCredentialDTO'
            - $ref: '#/components/schemas/CreateWebhookCredentialDTO'
            - $ref: '#/components/schemas/CreateXAiCredentialDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarOAuth2ClientCredentialDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarOAuth2AuthorizationCredentialDTO'
            - $ref: '#/components/schemas/CreateGoogleSheetsOAuth2AuthorizationCredentialDTO'
            - $ref: '#/components/schemas/CreateSlackOAuth2AuthorizationCredentialDTO'
        variableValues:
          type: object
          description: |-
            These are values that will be used to replace the template variables in the assistant messages and other text-based fields.
            This uses LiquidJS syntax. https://liquidjs.com/tutorials/intro-to-liquid.html

            So for example, `{{ name }}` will be replaced with the value of `name` in `variableValues`.
            `{{"now" | date: "%b %d, %Y, %I:%M %p", "America/New_York"}}` will be replaced with the current date and time in New York.
             Some VAPI reserved defaults:
             - *customer* - the customer object
        name:
          maxLength: 40
          type: string
          description: |-
            This is the name of the assistant.

            This is required when you want to transfer between assistants in a call.
        voicemailMessage:
          maxLength: 1000
          type: string
          description: |-
            This is the message that the assistant will say if the call is forwarded to voicemail.

            If unspecified, it will hang up.
        endCallMessage:
          maxLength: 1000
          type: string
          description: |-
            This is the message that the assistant will say if it ends the call.

            If unspecified, it will hang up without saying anything.
        endCallPhrases:
          type: array
          description: "This list contains phrases that, if spoken by the assistant, will trigger the call to be hung up. Case insensitive."
          items:
            maxLength: 140
            minLength: 2
            type: string
        compliancePlan:
          $ref: '#/components/schemas/CompliancePlan'
        metadata:
          type: object
          description: This is for metadata you want to store on the assistant.
        analysisPlan:
          description: This is the plan for analysis of assistant's calls. Stored in `call.analysis`.
          allOf:
          - $ref: '#/components/schemas/AnalysisPlan'
        artifactPlan:
          description: |-
            This is the plan for artifacts generated during assistant's calls. Stored in `call.artifact`.

            Note: `recordingEnabled` is currently at the root level. It will be moved to `artifactPlan` in the future, but will remain backwards compatible.
          allOf:
          - $ref: '#/components/schemas/ArtifactPlan'
        messagePlan:
          description: |-
            This is the plan for static predefined messages that can be spoken by the assistant during the call, like `idleMessages`.

            Note: `firstMessage`, `voicemailMessage`, and `endCallMessage` are currently at the root level. They will be moved to `messagePlan` in the future, but will remain backwards compatible.
          allOf:
          - $ref: '#/components/schemas/MessagePlan'
        startSpeakingPlan:
          description: |-
            This is the plan for when the assistant should start talking.

            You should configure this if you're running into these issues:
            - The assistant is too slow to start talking after the customer is done speaking.
            - The assistant is too fast to start talking after the customer is done speaking.
            - The assistant is so fast that it's actually interrupting the customer.
          allOf:
          - $ref: '#/components/schemas/StartSpeakingPlan'
        stopSpeakingPlan:
          description: |-
            This is the plan for when assistant should stop talking on customer interruption.

            You should configure this if you're running into these issues:
            - The assistant is too slow to recognize customer's interruption.
            - The assistant is too fast to recognize customer's interruption.
            - The assistant is getting interrupted by phrases that are just acknowledgments.
            - The assistant is getting interrupted by background noises.
            - The assistant is not properly stopping -- it starts talking right after getting interrupted.
          allOf:
          - $ref: '#/components/schemas/StopSpeakingPlan'
        monitorPlan:
          description: |-
            This is the plan for real-time monitoring of the assistant's calls.

            Usage:
            - To enable live listening of the assistant's calls, set `monitorPlan.listenEnabled` to `true`.
            - To enable live control of the assistant's calls, set `monitorPlan.controlEnabled` to `true`.

            Note, `serverMessages`, `clientMessages`, `serverUrl` and `serverUrlSecret` are currently at the root level but will be moved to `monitorPlan` in the future. Will remain backwards compatible
          allOf:
          - $ref: '#/components/schemas/MonitorPlan'
        credentialIds:
          type: array
          description: "These are the credentials that will be used for the assistant calls. By default, all the credentials are available for use in the call but you can provide a subset using this."
          items:
            type: string
        server:
          description: |-
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. assistant.server.url
            2. phoneNumber.serverUrl
            3. org.serverUrl
          allOf:
          - $ref: '#/components/schemas/Server'
        hooks:
          type: array
          description: This is a set of actions that will be performed on certain events.
          items:
            $ref: '#/components/schemas/AssistantHooks'
        keypadInputPlan:
          $ref: '#/components/schemas/KeypadInputPlan'
    SquadMemberDTO:
      type: object
      properties:
        assistantId:
          type: string
          description: "This is the assistant that will be used for the call. To use a transient assistant, use `assistant` instead."
          nullable: true
        assistant:
          description: "This is the assistant that will be used for the call. To use an existing assistant, use `assistantId` instead."
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        assistantOverrides:
          description: This can be used to override the assistant's settings and provide values for it's template variables.
          allOf:
          - $ref: '#/components/schemas/AssistantOverrides'
        assistantDestinations:
          type: array
          description: |-
            These are the others assistants that this assistant can transfer to.

            If the assistant already has transfer call tool, these destinations are just appended to existing ones.
          items:
            $ref: '#/components/schemas/TransferDestinationAssistant'
    CreateSquadDTO:
      required:
      - members
      type: object
      properties:
        name:
          type: string
          description: This is the name of the squad.
        members:
          type: array
          description: |-
            This is the list of assistants that make up the squad.

            The call will start with the first assistant in the list.
          items:
            $ref: '#/components/schemas/SquadMemberDTO'
        membersOverrides:
          description: |-
            This can be used to override all the assistants' settings and provide values for their template variables.

            Both `membersOverrides` and `members[n].assistantOverrides` can be used together. First, `members[n].assistantOverrides` is applied. Then, `membersOverrides` is applied as a global override.
          allOf:
          - $ref: '#/components/schemas/AssistantOverrides'
    ImportTwilioPhoneNumberDTO:
      required:
      - twilioAccountSid
      - twilioAuthToken
      - twilioPhoneNumber
      type: object
      properties:
        fallbackDestination:
          description: |-
            This is the fallback destination an inbound call will be transferred to if:
            1. `assistantId` is not set
            2. `squadId` is not set
            3. and, `assistant-request` message to the `serverUrl` fails

            If this is not set and above conditions are met, the inbound call is hung up with an error message.
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
        hooks:
          type: array
          description: This is the hooks that will be used for incoming calls to this phone number.
          items: {}
        twilioPhoneNumber:
          type: string
          description: These are the digits of the phone number you own on your Twilio.
          deprecated: true
        twilioAccountSid:
          type: string
          description: This is your Twilio Account SID that will be used to handle this phone number.
        twilioAuthToken:
          type: string
          description: This is the Twilio Auth Token that will be used to handle this phone number.
        name:
          maxLength: 40
          type: string
          description: This is the name of the phone number. This is just for your own reference.
        assistantId:
          type: string
          description: |-
            This is the assistant that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        squadId:
          type: string
          description: |-
            This is the squad that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        server:
          description: |-
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. assistant.server
            2. phoneNumber.server
            3. org.server
          allOf:
          - $ref: '#/components/schemas/Server'
    CreateCustomerDTO:
      type: object
      properties:
        numberE164CheckEnabled:
          type: boolean
          description: |-
            This is the flag to toggle the E164 check for the `number` field. This is an advanced property which should be used if you know your use case requires it.

            Use cases:
            - `false`: To allow non-E164 numbers like `+001234567890`, `1234`, or `abc`. This is useful for dialing out to non-E164 numbers on your SIP trunks.
            - `true` (default): To allow only E164 numbers like `+14155551234`. This is standard for PSTN calls.

            If `false`, the `number` is still required to only contain alphanumeric characters (regex: `/^\+?[a-zA-Z0-9]+$/`).

            @default true (E164 check is enabled)
          default: true
        extension:
          maxLength: 10
          type: string
          description: This is the extension that will be dialed after the call is answered.
        assistantOverrides:
          description: |-
            These are the overrides for the assistant's settings and template variables specific to this customer.
            This allows customization of the assistant's behavior for individual customers in batch calls.
          allOf:
          - $ref: '#/components/schemas/AssistantOverrides'
        number:
          maxLength: 40
          minLength: 3
          type: string
          description: This is the number of the customer.
        sipUri:
          type: string
          description: This is the SIP URI of the customer.
        name:
          maxLength: 40
          type: string
          description: |-
            This is the name of the customer. This is just for your own reference.

            For SIP inbound calls, this is extracted from the `From` SIP header with format `"Display Name" <sip:username@domain>`.
    SchedulePlan:
      required:
      - earliestAt
      type: object
      properties:
        earliestAt:
          type: string
          description: This is the ISO 8601 date-time string of the earliest time the call can be scheduled.
          format: date-time
        latestAt:
          type: string
          description: This is the ISO 8601 date-time string of the latest time the call can be scheduled.
          format: date-time
    Call:
      required:
      - createdAt
      - id
      - orgId
      - updatedAt
      type: object
      properties:
        type:
          type: string
          description: This is the type of call.
          enum:
          - inboundPhoneCall
          - outboundPhoneCall
          - webCall
          - vapi.websocketCall
        costs:
          type: array
          description: These are the costs of individual components of the call in USD.
          items:
            oneOf:
            - $ref: '#/components/schemas/TransportCost'
            - $ref: '#/components/schemas/TranscriberCost'
            - $ref: '#/components/schemas/ModelCost'
            - $ref: '#/components/schemas/VoiceCost'
            - $ref: '#/components/schemas/VapiCost'
            - $ref: '#/components/schemas/VoicemailDetectionCost'
            - $ref: '#/components/schemas/AnalysisCost'
        messages:
          type: array
          items:
            oneOf:
            - $ref: '#/components/schemas/UserMessage'
            - $ref: '#/components/schemas/SystemMessage'
            - $ref: '#/components/schemas/BotMessage'
            - $ref: '#/components/schemas/ToolCallMessage'
            - $ref: '#/components/schemas/ToolCallResultMessage'
        phoneCallProvider:
          type: string
          description: |-
            This is the provider of the call.

            Only relevant for `outboundPhoneCall` and `inboundPhoneCall` type.
          enum:
          - twilio
          - vonage
          - vapi
          - telnyx
        phoneCallTransport:
          type: string
          description: |-
            This is the transport of the phone call.

            Only relevant for `outboundPhoneCall` and `inboundPhoneCall` type.
          enum:
          - sip
          - pstn
        status:
          type: string
          description: This is the status of the call.
          enum:
          - scheduled
          - queued
          - ringing
          - in-progress
          - forwarding
          - ended
        endedReason:
          type: string
          description: This is the explanation for how the call ended.
          enum:
          - call-start-error-neither-assistant-nor-server-set
          - assistant-request-failed
          - assistant-request-returned-error
          - assistant-request-returned-unspeakable-error
          - assistant-request-returned-invalid-assistant
          - assistant-request-returned-no-assistant
          - assistant-request-returned-forwarding-phone-number
          - call.start.error-get-org
          - call.start.error-get-subscription
          - call.start.error-get-assistant
          - call.start.error-get-phone-number
          - call.start.error-get-customer
          - call.start.error-get-resources-validation
          - call.start.error-vapi-number-international
          - call.start.error-vapi-number-outbound-daily-limit
          - call.start.error-get-transport
          - assistant-not-valid
          - database-error
          - assistant-not-found
          - pipeline-error-openai-voice-failed
          - pipeline-error-cartesia-voice-failed
          - pipeline-error-deepgram-voice-failed
          - pipeline-error-eleven-labs-voice-failed
          - pipeline-error-playht-voice-failed
          - pipeline-error-lmnt-voice-failed
          - pipeline-error-azure-voice-failed
          - pipeline-error-rime-ai-voice-failed
          - pipeline-error-smallest-ai-voice-failed
          - pipeline-error-neuphonic-voice-failed
          - pipeline-error-hume-voice-failed
          - pipeline-error-sesame-voice-failed
          - pipeline-error-tavus-video-failed
          - call.in-progress.error-vapifault-openai-voice-failed
          - call.in-progress.error-vapifault-cartesia-voice-failed
          - call.in-progress.error-vapifault-deepgram-voice-failed
          - call.in-progress.error-vapifault-eleven-labs-voice-failed
          - call.in-progress.error-vapifault-playht-voice-failed
          - call.in-progress.error-vapifault-lmnt-voice-failed
          - call.in-progress.error-vapifault-azure-voice-failed
          - call.in-progress.error-vapifault-rime-ai-voice-failed
          - call.in-progress.error-vapifault-smallest-ai-voice-failed
          - call.in-progress.error-vapifault-neuphonic-voice-failed
          - call.in-progress.error-vapifault-hume-voice-failed
          - call.in-progress.error-vapifault-sesame-voice-failed
          - call.in-progress.error-vapifault-tavus-video-failed
          - pipeline-error-vapi-llm-failed
          - pipeline-error-vapi-400-bad-request-validation-failed
          - pipeline-error-vapi-401-unauthorized
          - pipeline-error-vapi-403-model-access-denied
          - pipeline-error-vapi-429-exceeded-quota
          - pipeline-error-vapi-500-server-error
          - pipeline-error-vapi-503-server-overloaded-error
          - call.in-progress.error-vapifault-vapi-llm-failed
          - call.in-progress.error-vapifault-vapi-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-vapi-401-unauthorized
          - call.in-progress.error-vapifault-vapi-403-model-access-denied
          - call.in-progress.error-vapifault-vapi-429-exceeded-quota
          - call.in-progress.error-providerfault-vapi-500-server-error
          - call.in-progress.error-providerfault-vapi-503-server-overloaded-error
          - pipeline-error-deepgram-transcriber-failed
          - call.in-progress.error-vapifault-deepgram-transcriber-failed
          - pipeline-error-gladia-transcriber-failed
          - call.in-progress.error-vapifault-gladia-transcriber-failed
          - pipeline-error-speechmatics-transcriber-failed
          - call.in-progress.error-vapifault-speechmatics-transcriber-failed
          - pipeline-error-assembly-ai-transcriber-failed
          - pipeline-error-assembly-ai-returning-400-insufficent-funds
          - pipeline-error-assembly-ai-returning-400-paid-only-feature
          - pipeline-error-assembly-ai-returning-401-invalid-credentials
          - pipeline-error-assembly-ai-returning-500-invalid-schema
          - pipeline-error-assembly-ai-returning-500-word-boost-parsing-failed
          - call.in-progress.error-vapifault-assembly-ai-transcriber-failed
          - call.in-progress.error-vapifault-assembly-ai-returning-400-insufficent-funds
          - call.in-progress.error-vapifault-assembly-ai-returning-400-paid-only-feature
          - call.in-progress.error-vapifault-assembly-ai-returning-401-invalid-credentials
          - call.in-progress.error-vapifault-assembly-ai-returning-500-invalid-schema
          - call.in-progress.error-vapifault-assembly-ai-returning-500-word-boost-parsing-failed
          - pipeline-error-talkscriber-transcriber-failed
          - call.in-progress.error-vapifault-talkscriber-transcriber-failed
          - pipeline-error-azure-speech-transcriber-failed
          - call.in-progress.error-vapifault-azure-speech-transcriber-failed
          - call.in-progress.error-pipeline-no-available-llm-model
          - worker-shutdown
          - unknown-error
          - vonage-disconnected
          - vonage-failed-to-connect-call
          - vonage-completed
          - phone-call-provider-bypass-enabled-but-no-call-received
          - call.in-progress.error-vapifault-transport-never-connected
          - call.in-progress.error-vapifault-transport-connected-but-call-not-active
          - call.in-progress.error-vapifault-call-started-but-connection-to-transport-missing
          - call.in-progress.error-vapifault-openai-llm-failed
          - call.in-progress.error-vapifault-azure-openai-llm-failed
          - call.in-progress.error-vapifault-groq-llm-failed
          - call.in-progress.error-vapifault-google-llm-failed
          - call.in-progress.error-vapifault-xai-llm-failed
          - call.in-progress.error-vapifault-mistral-llm-failed
          - call.in-progress.error-vapifault-inflection-ai-llm-failed
          - call.in-progress.error-vapifault-cerebras-llm-failed
          - call.in-progress.error-vapifault-deep-seek-llm-failed
          - pipeline-error-openai-400-bad-request-validation-failed
          - pipeline-error-openai-401-unauthorized
          - pipeline-error-openai-401-incorrect-api-key
          - pipeline-error-openai-401-account-not-in-organization
          - pipeline-error-openai-403-model-access-denied
          - pipeline-error-openai-429-exceeded-quota
          - pipeline-error-openai-429-rate-limit-reached
          - pipeline-error-openai-500-server-error
          - pipeline-error-openai-503-server-overloaded-error
          - pipeline-error-openai-llm-failed
          - call.in-progress.error-vapifault-openai-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-openai-401-unauthorized
          - call.in-progress.error-vapifault-openai-401-incorrect-api-key
          - call.in-progress.error-vapifault-openai-401-account-not-in-organization
          - call.in-progress.error-vapifault-openai-403-model-access-denied
          - call.in-progress.error-vapifault-openai-429-exceeded-quota
          - call.in-progress.error-vapifault-openai-429-rate-limit-reached
          - call.in-progress.error-providerfault-openai-500-server-error
          - call.in-progress.error-providerfault-openai-503-server-overloaded-error
          - pipeline-error-azure-openai-400-bad-request-validation-failed
          - pipeline-error-azure-openai-401-unauthorized
          - pipeline-error-azure-openai-403-model-access-denied
          - pipeline-error-azure-openai-429-exceeded-quota
          - pipeline-error-azure-openai-500-server-error
          - pipeline-error-azure-openai-503-server-overloaded-error
          - pipeline-error-azure-openai-llm-failed
          - call.in-progress.error-vapifault-azure-openai-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-azure-openai-401-unauthorized
          - call.in-progress.error-vapifault-azure-openai-403-model-access-denied
          - call.in-progress.error-vapifault-azure-openai-429-exceeded-quota
          - call.in-progress.error-providerfault-azure-openai-500-server-error
          - call.in-progress.error-providerfault-azure-openai-503-server-overloaded-error
          - pipeline-error-google-400-bad-request-validation-failed
          - pipeline-error-google-401-unauthorized
          - pipeline-error-google-403-model-access-denied
          - pipeline-error-google-429-exceeded-quota
          - pipeline-error-google-500-server-error
          - pipeline-error-google-503-server-overloaded-error
          - pipeline-error-google-llm-failed
          - call.in-progress.error-vapifault-google-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-google-401-unauthorized
          - call.in-progress.error-vapifault-google-403-model-access-denied
          - call.in-progress.error-vapifault-google-429-exceeded-quota
          - call.in-progress.error-providerfault-google-500-server-error
          - call.in-progress.error-providerfault-google-503-server-overloaded-error
          - pipeline-error-xai-400-bad-request-validation-failed
          - pipeline-error-xai-401-unauthorized
          - pipeline-error-xai-403-model-access-denied
          - pipeline-error-xai-429-exceeded-quota
          - pipeline-error-xai-500-server-error
          - pipeline-error-xai-503-server-overloaded-error
          - pipeline-error-xai-llm-failed
          - call.in-progress.error-vapifault-xai-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-xai-401-unauthorized
          - call.in-progress.error-vapifault-xai-403-model-access-denied
          - call.in-progress.error-vapifault-xai-429-exceeded-quota
          - call.in-progress.error-providerfault-xai-500-server-error
          - call.in-progress.error-providerfault-xai-503-server-overloaded-error
          - pipeline-error-mistral-400-bad-request-validation-failed
          - pipeline-error-mistral-401-unauthorized
          - pipeline-error-mistral-403-model-access-denied
          - pipeline-error-mistral-429-exceeded-quota
          - pipeline-error-mistral-500-server-error
          - pipeline-error-mistral-503-server-overloaded-error
          - pipeline-error-mistral-llm-failed
          - call.in-progress.error-vapifault-mistral-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-mistral-401-unauthorized
          - call.in-progress.error-vapifault-mistral-403-model-access-denied
          - call.in-progress.error-vapifault-mistral-429-exceeded-quota
          - call.in-progress.error-providerfault-mistral-500-server-error
          - call.in-progress.error-providerfault-mistral-503-server-overloaded-error
          - pipeline-error-inflection-ai-400-bad-request-validation-failed
          - pipeline-error-inflection-ai-401-unauthorized
          - pipeline-error-inflection-ai-403-model-access-denied
          - pipeline-error-inflection-ai-429-exceeded-quota
          - pipeline-error-inflection-ai-500-server-error
          - pipeline-error-inflection-ai-503-server-overloaded-error
          - pipeline-error-inflection-ai-llm-failed
          - call.in-progress.error-vapifault-inflection-ai-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-inflection-ai-401-unauthorized
          - call.in-progress.error-vapifault-inflection-ai-403-model-access-denied
          - call.in-progress.error-vapifault-inflection-ai-429-exceeded-quota
          - call.in-progress.error-providerfault-inflection-ai-500-server-error
          - call.in-progress.error-providerfault-inflection-ai-503-server-overloaded-error
          - pipeline-error-deep-seek-400-bad-request-validation-failed
          - pipeline-error-deep-seek-401-unauthorized
          - pipeline-error-deep-seek-403-model-access-denied
          - pipeline-error-deep-seek-429-exceeded-quota
          - pipeline-error-deep-seek-500-server-error
          - pipeline-error-deep-seek-503-server-overloaded-error
          - pipeline-error-deep-seek-llm-failed
          - call.in-progress.error-vapifault-deep-seek-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-deep-seek-401-unauthorized
          - call.in-progress.error-vapifault-deep-seek-403-model-access-denied
          - call.in-progress.error-vapifault-deep-seek-429-exceeded-quota
          - call.in-progress.error-providerfault-deep-seek-500-server-error
          - call.in-progress.error-providerfault-deep-seek-503-server-overloaded-error
          - pipeline-error-groq-400-bad-request-validation-failed
          - pipeline-error-groq-401-unauthorized
          - pipeline-error-groq-403-model-access-denied
          - pipeline-error-groq-429-exceeded-quota
          - pipeline-error-groq-500-server-error
          - pipeline-error-groq-503-server-overloaded-error
          - pipeline-error-groq-llm-failed
          - call.in-progress.error-vapifault-groq-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-groq-401-unauthorized
          - call.in-progress.error-vapifault-groq-403-model-access-denied
          - call.in-progress.error-vapifault-groq-429-exceeded-quota
          - call.in-progress.error-providerfault-groq-500-server-error
          - call.in-progress.error-providerfault-groq-503-server-overloaded-error
          - pipeline-error-cerebras-400-bad-request-validation-failed
          - pipeline-error-cerebras-401-unauthorized
          - pipeline-error-cerebras-403-model-access-denied
          - pipeline-error-cerebras-429-exceeded-quota
          - pipeline-error-cerebras-500-server-error
          - pipeline-error-cerebras-503-server-overloaded-error
          - pipeline-error-cerebras-llm-failed
          - call.in-progress.error-vapifault-cerebras-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-cerebras-401-unauthorized
          - call.in-progress.error-vapifault-cerebras-403-model-access-denied
          - call.in-progress.error-vapifault-cerebras-429-exceeded-quota
          - call.in-progress.error-providerfault-cerebras-500-server-error
          - call.in-progress.error-providerfault-cerebras-503-server-overloaded-error
          - pipeline-error-anthropic-400-bad-request-validation-failed
          - pipeline-error-anthropic-401-unauthorized
          - pipeline-error-anthropic-403-model-access-denied
          - pipeline-error-anthropic-429-exceeded-quota
          - pipeline-error-anthropic-500-server-error
          - pipeline-error-anthropic-503-server-overloaded-error
          - pipeline-error-anthropic-llm-failed
          - call.in-progress.error-vapifault-anthropic-llm-failed
          - call.in-progress.error-vapifault-anthropic-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-anthropic-401-unauthorized
          - call.in-progress.error-vapifault-anthropic-403-model-access-denied
          - call.in-progress.error-vapifault-anthropic-429-exceeded-quota
          - call.in-progress.error-providerfault-anthropic-500-server-error
          - call.in-progress.error-providerfault-anthropic-503-server-overloaded-error
          - pipeline-error-anthropic-bedrock-400-bad-request-validation-failed
          - pipeline-error-anthropic-bedrock-401-unauthorized
          - pipeline-error-anthropic-bedrock-403-model-access-denied
          - pipeline-error-anthropic-bedrock-429-exceeded-quota
          - pipeline-error-anthropic-bedrock-500-server-error
          - pipeline-error-anthropic-bedrock-503-server-overloaded-error
          - pipeline-error-anthropic-bedrock-llm-failed
          - call.in-progress.error-vapifault-anthropic-bedrock-llm-failed
          - call.in-progress.error-vapifault-anthropic-bedrock-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-anthropic-bedrock-401-unauthorized
          - call.in-progress.error-vapifault-anthropic-bedrock-403-model-access-denied
          - call.in-progress.error-vapifault-anthropic-bedrock-429-exceeded-quota
          - call.in-progress.error-providerfault-anthropic-bedrock-500-server-error
          - call.in-progress.error-providerfault-anthropic-bedrock-503-server-overloaded-error
          - pipeline-error-anthropic-vertex-400-bad-request-validation-failed
          - pipeline-error-anthropic-vertex-401-unauthorized
          - pipeline-error-anthropic-vertex-403-model-access-denied
          - pipeline-error-anthropic-vertex-429-exceeded-quota
          - pipeline-error-anthropic-vertex-500-server-error
          - pipeline-error-anthropic-vertex-503-server-overloaded-error
          - pipeline-error-anthropic-vertex-llm-failed
          - call.in-progress.error-vapifault-anthropic-vertex-llm-failed
          - call.in-progress.error-vapifault-anthropic-vertex-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-anthropic-vertex-401-unauthorized
          - call.in-progress.error-vapifault-anthropic-vertex-403-model-access-denied
          - call.in-progress.error-vapifault-anthropic-vertex-429-exceeded-quota
          - call.in-progress.error-providerfault-anthropic-vertex-500-server-error
          - call.in-progress.error-providerfault-anthropic-vertex-503-server-overloaded-error
          - pipeline-error-together-ai-400-bad-request-validation-failed
          - pipeline-error-together-ai-401-unauthorized
          - pipeline-error-together-ai-403-model-access-denied
          - pipeline-error-together-ai-429-exceeded-quota
          - pipeline-error-together-ai-500-server-error
          - pipeline-error-together-ai-503-server-overloaded-error
          - pipeline-error-together-ai-llm-failed
          - call.in-progress.error-vapifault-together-ai-llm-failed
          - call.in-progress.error-vapifault-together-ai-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-together-ai-401-unauthorized
          - call.in-progress.error-vapifault-together-ai-403-model-access-denied
          - call.in-progress.error-vapifault-together-ai-429-exceeded-quota
          - call.in-progress.error-providerfault-together-ai-500-server-error
          - call.in-progress.error-providerfault-together-ai-503-server-overloaded-error
          - pipeline-error-anyscale-400-bad-request-validation-failed
          - pipeline-error-anyscale-401-unauthorized
          - pipeline-error-anyscale-403-model-access-denied
          - pipeline-error-anyscale-429-exceeded-quota
          - pipeline-error-anyscale-500-server-error
          - pipeline-error-anyscale-503-server-overloaded-error
          - pipeline-error-anyscale-llm-failed
          - call.in-progress.error-vapifault-anyscale-llm-failed
          - call.in-progress.error-vapifault-anyscale-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-anyscale-401-unauthorized
          - call.in-progress.error-vapifault-anyscale-403-model-access-denied
          - call.in-progress.error-vapifault-anyscale-429-exceeded-quota
          - call.in-progress.error-providerfault-anyscale-500-server-error
          - call.in-progress.error-providerfault-anyscale-503-server-overloaded-error
          - pipeline-error-openrouter-400-bad-request-validation-failed
          - pipeline-error-openrouter-401-unauthorized
          - pipeline-error-openrouter-403-model-access-denied
          - pipeline-error-openrouter-429-exceeded-quota
          - pipeline-error-openrouter-500-server-error
          - pipeline-error-openrouter-503-server-overloaded-error
          - pipeline-error-openrouter-llm-failed
          - call.in-progress.error-vapifault-openrouter-llm-failed
          - call.in-progress.error-vapifault-openrouter-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-openrouter-401-unauthorized
          - call.in-progress.error-vapifault-openrouter-403-model-access-denied
          - call.in-progress.error-vapifault-openrouter-429-exceeded-quota
          - call.in-progress.error-providerfault-openrouter-500-server-error
          - call.in-progress.error-providerfault-openrouter-503-server-overloaded-error
          - pipeline-error-perplexity-ai-400-bad-request-validation-failed
          - pipeline-error-perplexity-ai-401-unauthorized
          - pipeline-error-perplexity-ai-403-model-access-denied
          - pipeline-error-perplexity-ai-429-exceeded-quota
          - pipeline-error-perplexity-ai-500-server-error
          - pipeline-error-perplexity-ai-503-server-overloaded-error
          - pipeline-error-perplexity-ai-llm-failed
          - call.in-progress.error-vapifault-perplexity-ai-llm-failed
          - call.in-progress.error-vapifault-perplexity-ai-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-perplexity-ai-401-unauthorized
          - call.in-progress.error-vapifault-perplexity-ai-403-model-access-denied
          - call.in-progress.error-vapifault-perplexity-ai-429-exceeded-quota
          - call.in-progress.error-providerfault-perplexity-ai-500-server-error
          - call.in-progress.error-providerfault-perplexity-ai-503-server-overloaded-error
          - pipeline-error-deepinfra-400-bad-request-validation-failed
          - pipeline-error-deepinfra-401-unauthorized
          - pipeline-error-deepinfra-403-model-access-denied
          - pipeline-error-deepinfra-429-exceeded-quota
          - pipeline-error-deepinfra-500-server-error
          - pipeline-error-deepinfra-503-server-overloaded-error
          - pipeline-error-deepinfra-llm-failed
          - call.in-progress.error-vapifault-deepinfra-llm-failed
          - call.in-progress.error-vapifault-deepinfra-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-deepinfra-401-unauthorized
          - call.in-progress.error-vapifault-deepinfra-403-model-access-denied
          - call.in-progress.error-vapifault-deepinfra-429-exceeded-quota
          - call.in-progress.error-providerfault-deepinfra-500-server-error
          - call.in-progress.error-providerfault-deepinfra-503-server-overloaded-error
          - pipeline-error-runpod-400-bad-request-validation-failed
          - pipeline-error-runpod-401-unauthorized
          - pipeline-error-runpod-403-model-access-denied
          - pipeline-error-runpod-429-exceeded-quota
          - pipeline-error-runpod-500-server-error
          - pipeline-error-runpod-503-server-overloaded-error
          - pipeline-error-runpod-llm-failed
          - call.in-progress.error-vapifault-runpod-llm-failed
          - call.in-progress.error-vapifault-runpod-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-runpod-401-unauthorized
          - call.in-progress.error-vapifault-runpod-403-model-access-denied
          - call.in-progress.error-vapifault-runpod-429-exceeded-quota
          - call.in-progress.error-providerfault-runpod-500-server-error
          - call.in-progress.error-providerfault-runpod-503-server-overloaded-error
          - pipeline-error-custom-llm-400-bad-request-validation-failed
          - pipeline-error-custom-llm-401-unauthorized
          - pipeline-error-custom-llm-403-model-access-denied
          - pipeline-error-custom-llm-429-exceeded-quota
          - pipeline-error-custom-llm-500-server-error
          - pipeline-error-custom-llm-503-server-overloaded-error
          - pipeline-error-custom-llm-llm-failed
          - call.in-progress.error-vapifault-custom-llm-llm-failed
          - call.in-progress.error-vapifault-custom-llm-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-custom-llm-401-unauthorized
          - call.in-progress.error-vapifault-custom-llm-403-model-access-denied
          - call.in-progress.error-vapifault-custom-llm-429-exceeded-quota
          - call.in-progress.error-providerfault-custom-llm-500-server-error
          - call.in-progress.error-providerfault-custom-llm-503-server-overloaded-error
          - pipeline-error-custom-voice-failed
          - pipeline-error-cartesia-socket-hang-up
          - pipeline-error-cartesia-requested-payment
          - pipeline-error-cartesia-500-server-error
          - pipeline-error-cartesia-503-server-error
          - pipeline-error-cartesia-522-server-error
          - call.in-progress.error-vapifault-cartesia-socket-hang-up
          - call.in-progress.error-vapifault-cartesia-requested-payment
          - call.in-progress.error-providerfault-cartesia-500-server-error
          - call.in-progress.error-providerfault-cartesia-503-server-error
          - call.in-progress.error-providerfault-cartesia-522-server-error
          - pipeline-error-eleven-labs-voice-not-found
          - pipeline-error-eleven-labs-quota-exceeded
          - pipeline-error-eleven-labs-unauthorized-access
          - pipeline-error-eleven-labs-unauthorized-to-access-model
          - pipeline-error-eleven-labs-professional-voices-only-for-creator-plus
          - pipeline-error-eleven-labs-blocked-free-plan-and-requested-upgrade
          - pipeline-error-eleven-labs-blocked-concurrent-requests-and-requested-upgrade
          - pipeline-error-eleven-labs-blocked-using-instant-voice-clone-and-requested-upgrade
          - pipeline-error-eleven-labs-system-busy-and-requested-upgrade
          - pipeline-error-eleven-labs-voice-not-fine-tuned
          - pipeline-error-eleven-labs-invalid-api-key
          - pipeline-error-eleven-labs-invalid-voice-samples
          - pipeline-error-eleven-labs-voice-disabled-by-owner
          - pipeline-error-eleven-labs-blocked-account-in-probation
          - pipeline-error-eleven-labs-blocked-content-against-their-policy
          - pipeline-error-eleven-labs-missing-samples-for-voice-clone
          - pipeline-error-eleven-labs-voice-not-fine-tuned-and-cannot-be-used
          - pipeline-error-eleven-labs-voice-not-allowed-for-free-users
          - pipeline-error-eleven-labs-max-character-limit-exceeded
          - pipeline-error-eleven-labs-blocked-voice-potentially-against-terms-of-service-and-awaiting-verification
          - pipeline-error-eleven-labs-500-server-error
          - call.in-progress.error-vapifault-eleven-labs-voice-not-found
          - call.in-progress.error-vapifault-eleven-labs-quota-exceeded
          - call.in-progress.error-vapifault-eleven-labs-unauthorized-access
          - call.in-progress.error-vapifault-eleven-labs-unauthorized-to-access-model
          - call.in-progress.error-vapifault-eleven-labs-professional-voices-only-for-creator-plus
          - call.in-progress.error-vapifault-eleven-labs-blocked-free-plan-and-requested-upgrade
          - call.in-progress.error-vapifault-eleven-labs-blocked-concurrent-requests-and-requested-upgrade
          - call.in-progress.error-vapifault-eleven-labs-blocked-using-instant-voice-clone-and-requested-upgrade
          - call.in-progress.error-vapifault-eleven-labs-system-busy-and-requested-upgrade
          - call.in-progress.error-vapifault-eleven-labs-voice-not-fine-tuned
          - call.in-progress.error-vapifault-eleven-labs-invalid-api-key
          - call.in-progress.error-vapifault-eleven-labs-invalid-voice-samples
          - call.in-progress.error-vapifault-eleven-labs-voice-disabled-by-owner
          - call.in-progress.error-vapifault-eleven-labs-blocked-account-in-probation
          - call.in-progress.error-vapifault-eleven-labs-blocked-content-against-their-policy
          - call.in-progress.error-vapifault-eleven-labs-missing-samples-for-voice-clone
          - call.in-progress.error-vapifault-eleven-labs-voice-not-fine-tuned-and-cannot-be-used
          - call.in-progress.error-vapifault-eleven-labs-voice-not-allowed-for-free-users
          - call.in-progress.error-vapifault-eleven-labs-max-character-limit-exceeded
          - call.in-progress.error-vapifault-eleven-labs-blocked-voice-potentially-against-terms-of-service-and-awaiting-verification
          - call.in-progress.error-providerfault-eleven-labs-500-server-error
          - pipeline-error-playht-request-timed-out
          - pipeline-error-playht-invalid-voice
          - pipeline-error-playht-unexpected-error
          - pipeline-error-playht-out-of-credits
          - pipeline-error-playht-invalid-emotion
          - pipeline-error-playht-voice-must-be-a-valid-voice-manifest-uri
          - pipeline-error-playht-401-unauthorized
          - pipeline-error-playht-403-forbidden-out-of-characters
          - pipeline-error-playht-403-forbidden-api-access-not-available
          - pipeline-error-playht-429-exceeded-quota
          - pipeline-error-playht-502-gateway-error
          - pipeline-error-playht-504-gateway-error
          - call.in-progress.error-vapifault-playht-request-timed-out
          - call.in-progress.error-vapifault-playht-invalid-voice
          - call.in-progress.error-vapifault-playht-unexpected-error
          - call.in-progress.error-vapifault-playht-out-of-credits
          - call.in-progress.error-vapifault-playht-invalid-emotion
          - call.in-progress.error-vapifault-playht-voice-must-be-a-valid-voice-manifest-uri
          - call.in-progress.error-vapifault-playht-401-unauthorized
          - call.in-progress.error-vapifault-playht-403-forbidden-out-of-characters
          - call.in-progress.error-vapifault-playht-403-forbidden-api-access-not-available
          - call.in-progress.error-vapifault-playht-429-exceeded-quota
          - call.in-progress.error-providerfault-playht-502-gateway-error
          - call.in-progress.error-providerfault-playht-504-gateway-error
          - pipeline-error-custom-transcriber-failed
          - call.in-progress.error-vapifault-custom-transcriber-failed
          - pipeline-error-eleven-labs-transcriber-failed
          - call.in-progress.error-vapifault-eleven-labs-transcriber-failed
          - pipeline-error-deepgram-returning-400-no-such-model-language-tier-combination
          - pipeline-error-deepgram-returning-401-invalid-credentials
          - pipeline-error-deepgram-returning-403-model-access-denied
          - pipeline-error-deepgram-returning-404-not-found
          - pipeline-error-deepgram-returning-500-invalid-json
          - pipeline-error-deepgram-returning-502-network-error
          - pipeline-error-deepgram-returning-502-bad-gateway-ehostunreach
          - call.in-progress.error-vapifault-deepgram-returning-400-no-such-model-language-tier-combination
          - call.in-progress.error-vapifault-deepgram-returning-401-invalid-credentials
          - call.in-progress.error-vapifault-deepgram-returning-404-not-found
          - call.in-progress.error-vapifault-deepgram-returning-403-model-access-denied
          - call.in-progress.error-providerfault-deepgram-returning-500-invalid-json
          - call.in-progress.error-providerfault-deepgram-returning-502-network-error
          - call.in-progress.error-providerfault-deepgram-returning-502-bad-gateway-ehostunreach
          - pipeline-error-google-transcriber-failed
          - call.in-progress.error-vapifault-google-transcriber-failed
          - pipeline-error-openai-transcriber-failed
          - call.in-progress.error-vapifault-openai-transcriber-failed
          - assistant-ended-call
          - assistant-said-end-call-phrase
          - assistant-ended-call-with-hangup-task
          - assistant-ended-call-after-message-spoken
          - assistant-forwarded-call
          - assistant-join-timed-out
          - call.in-progress.error-assistant-did-not-receive-customer-audio
          - customer-busy
          - customer-ended-call
          - customer-did-not-answer
          - customer-did-not-give-microphone-permission
          - exceeded-max-duration
          - manually-canceled
          - phone-call-provider-closed-websocket
          - silence-timed-out
          - call.in-progress.error-sip-telephony-provider-failed-to-connect-call
          - call.ringing.hook-executed-say
          - call.ringing.hook-executed-transfer
          - twilio-failed-to-connect-call
          - twilio-reported-customer-misdialed
          - vonage-rejected
          - voicemail
        destination:
          description: "This is the destination where the call ended up being transferred to. If the call was not transferred, this will be empty."
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
        id:
          type: string
          description: This is the unique identifier for the call.
        orgId:
          type: string
          description: This is the unique identifier for the org that this call belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the call was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the call was last updated.
          format: date-time
        startedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the call was started.
          format: date-time
        endedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the call was ended.
          format: date-time
        cost:
          type: number
          description: This is the cost of the call in USD.
        costBreakdown:
          description: This is the cost of the call in USD.
          allOf:
          - $ref: '#/components/schemas/CostBreakdown'
        artifactPlan:
          description: This is a copy of assistant artifact plan. This isn't actually stored on the call but rather just returned in POST /call/web to enable artifact creation client side.
          allOf:
          - $ref: '#/components/schemas/ArtifactPlan'
        analysis:
          description: This is the analysis of the call. Configure in `assistant.analysisPlan`.
          allOf:
          - $ref: '#/components/schemas/Analysis'
        monitor:
          description: This is to real-time monitor the call. Configure in `assistant.monitorPlan`.
          allOf:
          - $ref: '#/components/schemas/Monitor'
        artifact:
          description: These are the artifacts created from the call. Configure in `assistant.artifactPlan`.
          allOf:
          - $ref: '#/components/schemas/Artifact'
        phoneCallProviderId:
          type: string
          description: |-
            The ID of the call as provided by the phone number service. callSid in Twilio. conversationUuid in Vonage. callControlId in Telnyx.

            Only relevant for `outboundPhoneCall` and `inboundPhoneCall` type.
        assistantId:
          type: string
          description: "This is the assistant that will be used for the call. To use a transient assistant, use `assistant` instead."
        assistant:
          description: "This is the assistant that will be used for the call. To use an existing assistant, use `assistantId` instead."
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        assistantOverrides:
          description: These are the overrides for the `assistant` or `assistantId`'s settings and template variables.
          allOf:
          - $ref: '#/components/schemas/AssistantOverrides'
        squadId:
          type: string
          description: "This is the squad that will be used for the call. To use a transient squad, use `squad` instead."
        squad:
          description: "This is a squad that will be used for the call. To use an existing squad, use `squadId` instead."
          allOf:
          - $ref: '#/components/schemas/CreateSquadDTO'
        phoneNumberId:
          type: string
          description: |-
            This is the phone number that will be used for the call. To use a transient number, use `phoneNumber` instead.

            Only relevant for `outboundPhoneCall` and `inboundPhoneCall` type.
        phoneNumber:
          description: |-
            This is the phone number that will be used for the call. To use an existing number, use `phoneNumberId` instead.

            Only relevant for `outboundPhoneCall` and `inboundPhoneCall` type.
          allOf:
          - $ref: '#/components/schemas/ImportTwilioPhoneNumberDTO'
        customerId:
          type: string
          description: |-
            This is the customer that will be called. To call a transient customer , use `customer` instead.

            Only relevant for `outboundPhoneCall` and `inboundPhoneCall` type.
        customer:
          description: |-
            This is the customer that will be called. To call an existing customer, use `customerId` instead.

            Only relevant for `outboundPhoneCall` and `inboundPhoneCall` type.
          allOf:
          - $ref: '#/components/schemas/CreateCustomerDTO'
        name:
          maxLength: 40
          type: string
          description: This is the name of the call. This is just for your own reference.
        schedulePlan:
          description: This is the schedule plan of the call.
          allOf:
          - $ref: '#/components/schemas/SchedulePlan'
        transport:
          type: object
          description: This is the transport of the call.
    CallBatchError:
      required:
      - customer
      - error
      type: object
      properties:
        customer:
          $ref: '#/components/schemas/CreateCustomerDTO'
        error:
          type: string
    CallBatchResponse:
      required:
      - errors
      - results
      type: object
      properties:
        results:
          type: array
          description: This is the list of calls that were created.
          items:
            $ref: '#/components/schemas/Call'
        errors:
          type: array
          description: This is the list of calls that failed to be created.
          items:
            $ref: '#/components/schemas/CallBatchError'
    CreateCallDTO:
      type: object
      properties:
        customers:
          type: array
          description: |-
            This is used to issue batch calls to multiple customers.

            Only relevant for `outboundPhoneCall`. To call a single customer, use `customer` instead.
          items:
            $ref: '#/components/schemas/CreateCustomerDTO'
        name:
          maxLength: 40
          type: string
          description: This is the name of the call. This is just for your own reference.
        schedulePlan:
          description: This is the schedule plan of the call.
          allOf:
          - $ref: '#/components/schemas/SchedulePlan'
        transport:
          type: object
          description: This is the transport of the call.
        assistantId:
          type: string
          description: "This is the assistant that will be used for the call. To use a transient assistant, use `assistant` instead."
        assistant:
          description: "This is the assistant that will be used for the call. To use an existing assistant, use `assistantId` instead."
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        assistantOverrides:
          description: These are the overrides for the `assistant` or `assistantId`'s settings and template variables.
          allOf:
          - $ref: '#/components/schemas/AssistantOverrides'
        squadId:
          type: string
          description: "This is the squad that will be used for the call. To use a transient squad, use `squad` instead."
        squad:
          description: "This is a squad that will be used for the call. To use an existing squad, use `squadId` instead."
          allOf:
          - $ref: '#/components/schemas/CreateSquadDTO'
        phoneNumberId:
          type: string
          description: |-
            This is the phone number that will be used for the call. To use a transient number, use `phoneNumber` instead.

            Only relevant for `outboundPhoneCall` and `inboundPhoneCall` type.
        phoneNumber:
          description: |-
            This is the phone number that will be used for the call. To use an existing number, use `phoneNumberId` instead.

            Only relevant for `outboundPhoneCall` and `inboundPhoneCall` type.
          allOf:
          - $ref: '#/components/schemas/ImportTwilioPhoneNumberDTO'
        customerId:
          type: string
          description: |-
            This is the customer that will be called. To call a transient customer , use `customer` instead.

            Only relevant for `outboundPhoneCall` and `inboundPhoneCall` type.
        customer:
          description: |-
            This is the customer that will be called. To call an existing customer, use `customerId` instead.

            Only relevant for `outboundPhoneCall` and `inboundPhoneCall` type.
          allOf:
          - $ref: '#/components/schemas/CreateCustomerDTO'
    PaginationMeta:
      required:
      - currentPage
      - itemsPerPage
      - totalItems
      type: object
      properties:
        itemsPerPage:
          type: number
        totalItems:
          type: number
        currentPage:
          type: number
    CallPaginatedResponse:
      required:
      - metadata
      - results
      type: object
      properties:
        results:
          type: array
          items:
            $ref: '#/components/schemas/Call'
        metadata:
          $ref: '#/components/schemas/PaginationMeta'
    CreateOutboundCallDTO:
      type: object
      properties:
        customers:
          type: array
          description: |-
            This is used to issue batch calls to multiple customers.

            Only relevant for `outboundPhoneCall`. To call a single customer, use `customer` instead.
          items:
            $ref: '#/components/schemas/CreateCustomerDTO'
        name:
          maxLength: 40
          type: string
          description: This is the name of the call. This is just for your own reference.
        schedulePlan:
          description: This is the schedule plan of the call.
          allOf:
          - $ref: '#/components/schemas/SchedulePlan'
        transport:
          type: object
          description: This is the transport of the call.
        assistantId:
          type: string
          description: "This is the assistant that will be used for the call. To use a transient assistant, use `assistant` instead."
        assistant:
          description: "This is the assistant that will be used for the call. To use an existing assistant, use `assistantId` instead."
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        assistantOverrides:
          description: These are the overrides for the `assistant` or `assistantId`'s settings and template variables.
          allOf:
          - $ref: '#/components/schemas/AssistantOverrides'
        squadId:
          type: string
          description: "This is the squad that will be used for the call. To use a transient squad, use `squad` instead."
        squad:
          description: "This is a squad that will be used for the call. To use an existing squad, use `squadId` instead."
          allOf:
          - $ref: '#/components/schemas/CreateSquadDTO'
        phoneNumberId:
          type: string
          description: |-
            This is the phone number that will be used for the call. To use a transient number, use `phoneNumber` instead.

            Only relevant for `outboundPhoneCall` and `inboundPhoneCall` type.
        phoneNumber:
          description: |-
            This is the phone number that will be used for the call. To use an existing number, use `phoneNumberId` instead.

            Only relevant for `outboundPhoneCall` and `inboundPhoneCall` type.
          allOf:
          - $ref: '#/components/schemas/ImportTwilioPhoneNumberDTO'
        customerId:
          type: string
          description: |-
            This is the customer that will be called. To call a transient customer , use `customer` instead.

            Only relevant for `outboundPhoneCall` and `inboundPhoneCall` type.
        customer:
          description: |-
            This is the customer that will be called. To call an existing customer, use `customerId` instead.

            Only relevant for `outboundPhoneCall` and `inboundPhoneCall` type.
          allOf:
          - $ref: '#/components/schemas/CreateCustomerDTO'
    CreateWebCallDTO:
      type: object
      properties:
        assistantId:
          type: string
          description: "This is the assistant that will be used for the call. To use a transient assistant, use `assistant` instead."
        assistant:
          description: "This is the assistant that will be used for the call. To use an existing assistant, use `assistantId` instead."
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        assistantOverrides:
          description: These are the overrides for the `assistant` or `assistantId`'s settings and template variables.
          allOf:
          - $ref: '#/components/schemas/AssistantOverrides'
        squadId:
          type: string
          description: "This is the squad that will be used for the call. To use a transient squad, use `squad` instead."
        squad:
          description: "This is a squad that will be used for the call. To use an existing squad, use `squadId` instead."
          allOf:
          - $ref: '#/components/schemas/CreateSquadDTO'
    UpdateCallDTO:
      type: object
      properties:
        name:
          maxLength: 40
          type: string
          description: This is the name of the call. This is just for your own reference.
    ChatServiceResponse:
      type: object
      properties: {}
    ChatCompletionMessageMetadata:
      required:
      - taskName
      - taskOutput
      - taskType
      type: object
      properties:
        taskName:
          type: string
        taskType:
          type: string
        taskOutput:
          type: string
        taskState:
          type: object
        nodeTrace:
          type: array
          items:
            type: string
    ChatCompletionMessageWorkflows:
      required:
      - content
      - role
      type: object
      properties:
        role:
          type: object
        content:
          type: string
          nullable: true
        metadata:
          $ref: '#/components/schemas/ChatCompletionMessageMetadata'
    Say:
      required:
      - name
      - type
      type: object
      properties:
        type:
          type: string
          enum:
          - say
        exact:
          maxLength: 1000
          type: string
        prompt:
          maxLength: 1000
          type: string
        name:
          maxLength: 80
          type: string
        metadata:
          type: object
          description: This is for metadata you want to store on the task.
    SayHook:
      required:
      - type
      type: object
      properties:
        type:
          type: string
          enum:
          - say
        metadata:
          type: object
          description: This is for metadata you want to store on the task.
        exact:
          maxLength: 1000
          type: string
        prompt:
          maxLength: 1000
          type: string
    Hook:
      required:
      - do
      - "on"
      type: object
      properties:
        "on":
          maxLength: 80
          type: string
          enum:
          - task.start
          - task.output.confirmation
          - task.delayed
        do:
          type: array
          items:
            $ref: '#/components/schemas/SayHook'
    Gather:
      required:
      - name
      - output
      - type
      type: object
      properties:
        type:
          type: string
          enum:
          - gather
        output:
          $ref: '#/components/schemas/JsonSchema'
        confirmContent:
          type: boolean
          description: "This is whether or not the workflow should read back the gathered data to the user, and ask about its correctness."
        hooks:
          type: array
          description: |-
            This is a list of hooks for a task.
            Each hook is a list of tasks to run on a trigger (such as on start, on failure, etc).
            Only Say is supported for now.
          items:
            $ref: '#/components/schemas/Hook'
        maxRetries:
          type: number
          description: "This is the number of times we should try to gather the information from the user before we failover to the fail path. An example of this would be a user refusing to give their phone number for privacy reasons, and then going down a different path on account of this"
        literalTemplate:
          type: string
          description: "This is a liquid templating string. On the first call to Gather, the template will be filled out with variables from the context, and will be spoken verbatim to the user. An example would be \"Base on your zipcode, it looks like you could be in one of these counties: {{ counties | join: \", \" }}. Which one do you live in?\""
        name:
          maxLength: 80
          type: string
        metadata:
          type: object
          description: This is for metadata you want to store on the task.
    ApiRequest:
      required:
      - method
      - mode
      - name
      - type
      - url
      type: object
      properties:
        type:
          type: string
          enum:
          - apiRequest
        method:
          type: string
          enum:
          - POST
          - GET
        url:
          type: string
          description: Api endpoint to send requests to.
        headers:
          description: |-
            These are the custom headers to include in the Api Request sent.

            Each key-value pair represents a header name and its value.
          allOf:
          - $ref: '#/components/schemas/JsonSchema'
        body:
          description: |-
            This defined the JSON body of your Api Request. For example, if `body_schema`
            included "my_field": "my_gather_statement.user_age", then the json body sent to the server would have that particular value assign to it.
            Right now, only data from gather statements are supported.
          allOf:
          - $ref: '#/components/schemas/JsonSchema'
        mode:
          type: string
          description: |-
            This is the mode of the Api Request.
            We only support BLOCKING and BACKGROUND for now.
          enum:
          - blocking
          - background
        hooks:
          type: array
          description: |-
            This is a list of hooks for a task.
            Each hook is a list of tasks to run on a trigger (such as on start, on failure, etc).
            Only Say is supported for now.
          items:
            $ref: '#/components/schemas/Hook'
        output:
          description: This is the schema for the outputs of the Api Request.
          allOf:
          - $ref: '#/components/schemas/JsonSchema'
        name:
          maxLength: 80
          type: string
        metadata:
          type: object
          description: This is for metadata you want to store on the task.
    Hangup:
      required:
      - name
      - type
      type: object
      properties:
        type:
          type: string
          enum:
          - hangup
        name:
          maxLength: 80
          type: string
        metadata:
          type: object
          description: This is for metadata you want to store on the task.
    Transfer:
      required:
      - destination
      - name
      - type
      type: object
      properties:
        type:
          type: string
          enum:
          - transfer
        destination:
          type: object
        name:
          maxLength: 80
          type: string
        metadata:
          type: object
          description: This is for metadata you want to store on the task.
    CreateWorkflowDTO:
      required:
      - edges
      - name
      - nodes
      type: object
      properties:
        nodes:
          type: array
          items:
            oneOf:
            - $ref: '#/components/schemas/Say'
            - $ref: '#/components/schemas/Gather'
            - $ref: '#/components/schemas/ApiRequest'
            - $ref: '#/components/schemas/Hangup'
            - $ref: '#/components/schemas/Transfer'
        model:
          description: These are the options for the workflow's LLM.
          oneOf:
          - $ref: '#/components/schemas/AnthropicModel'
          - $ref: '#/components/schemas/AnyscaleModel'
          - $ref: '#/components/schemas/CerebrasModel'
          - $ref: '#/components/schemas/CustomLLMModel'
          - $ref: '#/components/schemas/DeepInfraModel'
          - $ref: '#/components/schemas/DeepSeekModel'
          - $ref: '#/components/schemas/GoogleModel'
          - $ref: '#/components/schemas/GroqModel'
          - $ref: '#/components/schemas/InflectionAIModel'
          - $ref: '#/components/schemas/OpenAIModel'
          - $ref: '#/components/schemas/OpenRouterModel'
          - $ref: '#/components/schemas/PerplexityAIModel'
          - $ref: '#/components/schemas/TogetherAIModel'
          - $ref: '#/components/schemas/XaiModel'
        name:
          maxLength: 80
          type: string
        edges:
          type: array
          items:
            $ref: '#/components/schemas/Edge'
    ChatCompletionsDTO:
      required:
      - messages
      type: object
      properties:
        messages:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionMessageWorkflows'
        workflowId:
          type: string
        workflow:
          $ref: '#/components/schemas/CreateWorkflowDTO'
    Assistant:
      required:
      - createdAt
      - id
      - orgId
      - updatedAt
      type: object
      properties:
        transcriber:
          description: These are the options for the assistant's transcriber.
          oneOf:
          - $ref: '#/components/schemas/AssemblyAITranscriber'
          - $ref: '#/components/schemas/AzureSpeechTranscriber'
          - $ref: '#/components/schemas/CustomTranscriber'
          - $ref: '#/components/schemas/DeepgramTranscriber'
          - $ref: '#/components/schemas/ElevenLabsTranscriber'
          - $ref: '#/components/schemas/GladiaTranscriber'
          - $ref: '#/components/schemas/SpeechmaticsTranscriber'
          - $ref: '#/components/schemas/TalkscriberTranscriber'
          - $ref: '#/components/schemas/GoogleTranscriber'
          - $ref: '#/components/schemas/OpenAITranscriber'
        model:
          description: These are the options for the assistant's LLM.
          oneOf:
          - $ref: '#/components/schemas/AnyscaleModel'
          - $ref: '#/components/schemas/AnthropicModel'
          - $ref: '#/components/schemas/CerebrasModel'
          - $ref: '#/components/schemas/CustomLLMModel'
          - $ref: '#/components/schemas/DeepInfraModel'
          - $ref: '#/components/schemas/DeepSeekModel'
          - $ref: '#/components/schemas/GoogleModel'
          - $ref: '#/components/schemas/GroqModel'
          - $ref: '#/components/schemas/InflectionAIModel'
          - $ref: '#/components/schemas/OpenAIModel'
          - $ref: '#/components/schemas/OpenRouterModel'
          - $ref: '#/components/schemas/PerplexityAIModel'
          - $ref: '#/components/schemas/TogetherAIModel'
          - $ref: '#/components/schemas/VapiModel'
          - $ref: '#/components/schemas/XaiModel'
        voice:
          description: These are the options for the assistant's voice.
          oneOf:
          - $ref: '#/components/schemas/AzureVoice'
          - $ref: '#/components/schemas/CartesiaVoice'
          - $ref: '#/components/schemas/CustomVoice'
          - $ref: '#/components/schemas/DeepgramVoice'
          - $ref: '#/components/schemas/ElevenLabsVoice'
          - $ref: '#/components/schemas/HumeVoice'
          - $ref: '#/components/schemas/LMNTVoice'
          - $ref: '#/components/schemas/NeuphonicVoice'
          - $ref: '#/components/schemas/OpenAIVoice'
          - $ref: '#/components/schemas/PlayHTVoice'
          - $ref: '#/components/schemas/RimeAIVoice'
          - $ref: '#/components/schemas/SmallestAIVoice'
          - $ref: '#/components/schemas/TavusVoice'
          - $ref: '#/components/schemas/VapiVoice'
          default:
            provider: playht
            voiceId: jennifer
        firstMessage:
          type: string
          description: |-
            This is the first message that the assistant will say. This can also be a URL to a containerized audio file (mp3, wav, etc.).

            If unspecified, assistant will wait for user to speak and use the model to respond once they speak.
          example: Hello! How can I help you today?
        firstMessageInterruptionsEnabled:
          type: boolean
          default: false
        firstMessageMode:
          type: string
          description: |-
            This is the mode for the first message. Default is 'assistant-speaks-first'.

            Use:
            - 'assistant-speaks-first' to have the assistant speak first.
            - 'assistant-waits-for-user' to have the assistant wait for the user to speak first.
            - 'assistant-speaks-first-with-model-generated-message' to have the assistant speak first with a message generated by the model based on the conversation state. (`assistant.model.messages` at call start, `call.messages` at squad transfer points).

            @default 'assistant-speaks-first'
          example: assistant-speaks-first
          enum:
          - assistant-speaks-first
          - assistant-speaks-first-with-model-generated-message
          - assistant-waits-for-user
        voicemailDetection:
          description: |-
            These are the settings to configure or disable voicemail detection. Alternatively, voicemail detection can be configured using the model.tools=[VoicemailTool].
            This uses Twilio's built-in detection while the VoicemailTool relies on the model to detect if a voicemail was reached.
            You can use neither of them, one of them, or both of them. By default, Twilio built-in detection is enabled while VoicemailTool is not.
          oneOf:
          - $ref: '#/components/schemas/GoogleVoicemailDetectionPlan'
          - $ref: '#/components/schemas/OpenAIVoicemailDetectionPlan'
          - $ref: '#/components/schemas/TwilioVoicemailDetectionPlan'
        clientMessages:
          type: array
          description: "These are the messages that will be sent to your Client SDKs. Default is conversation-update,function-call,hang,model-output,speech-update,status-update,transfer-update,transcript,tool-calls,user-interrupted,voice-input,workflow.node.started. You can check the shape of the messages in ClientMessage schema."
          example:
          - conversation-update
          - function-call
          - hang
          - model-output
          - speech-update
          - status-update
          - transfer-update
          - transcript
          - tool-calls
          - user-interrupted
          - voice-input
          - workflow.node.started
          items:
            type: string
            enum:
            - conversation-update
            - function-call
            - function-call-result
            - hang
            - language-changed
            - metadata
            - model-output
            - speech-update
            - status-update
            - transcript
            - tool-calls
            - tool-calls-result
            - transfer-update
            - user-interrupted
            - voice-input
            - workflow.node.started
          enum:
          - conversation-update
          - function-call
          - function-call-result
          - hang
          - language-changed
          - metadata
          - model-output
          - speech-update
          - status-update
          - transcript
          - tool-calls
          - tool-calls-result
          - transfer-update
          - user-interrupted
          - voice-input
          - workflow.node.started
        serverMessages:
          type: array
          description: "These are the messages that will be sent to your Server URL. Default is conversation-update,end-of-call-report,function-call,hang,speech-update,status-update,tool-calls,transfer-destination-request,user-interrupted. You can check the shape of the messages in ServerMessage schema."
          example:
          - conversation-update
          - end-of-call-report
          - function-call
          - hang
          - speech-update
          - status-update
          - tool-calls
          - transfer-destination-request
          - user-interrupted
          items:
            type: string
            enum:
            - conversation-update
            - end-of-call-report
            - function-call
            - hang
            - language-changed
            - language-change-detected
            - model-output
            - phone-call-control
            - speech-update
            - status-update
            - transcript
            - "transcript[transcriptType=\"final\"]"
            - tool-calls
            - transfer-destination-request
            - transfer-update
            - user-interrupted
            - voice-input
          enum:
          - conversation-update
          - end-of-call-report
          - function-call
          - hang
          - language-changed
          - language-change-detected
          - model-output
          - phone-call-control
          - speech-update
          - status-update
          - transcript
          - "transcript[transcriptType=\"final\"]"
          - tool-calls
          - transfer-destination-request
          - transfer-update
          - user-interrupted
          - voice-input
        silenceTimeoutSeconds:
          maximum: 3600
          minimum: 10
          type: number
          description: |-
            How many seconds of silence to wait before ending the call. Defaults to 30.

            @default 30
          example: 30
        maxDurationSeconds:
          maximum: 43200
          minimum: 10
          type: number
          description: |-
            This is the maximum number of seconds that the call will last. When the call reaches this duration, it will be ended.

            @default 600 (10 minutes)
          example: 600
        backgroundSound:
          maxLength: 1000
          description: |-
            This is the background sound in the call. Default for phone calls is 'office' and default for web calls is 'off'.
            You can also provide a custom sound by providing a URL to an audio file.
          oneOf:
          - type: string
            example: office
            enum:
            - "false"
            - office
          - type: string
            format: uri
            example: https://www.soundjay.com/ambient/sounds/people-in-lounge-1.mp3
        backgroundDenoisingEnabled:
          type: boolean
          description: |-
            This enables filtering of noise and background speech while the user is talking.

            Default `false` while in beta.

            @default false
          example: false
        modelOutputInMessagesEnabled:
          type: boolean
          description: |-
            This determines whether the model's output is used in conversation history rather than the transcription of assistant's speech.

            Default `false` while in beta.

            @default false
          example: false
        transportConfigurations:
          type: array
          description: "These are the configurations to be passed to the transport providers of assistant's calls, like Twilio. You can store multiple configurations for different transport providers. For a call, only the configuration matching the call transport provider is used."
          items:
            oneOf:
            - $ref: '#/components/schemas/TransportConfigurationTwilio'
        observabilityPlan:
          description: |-
            This is the plan for observability configuration of assistant's calls.
            Currently supports Langfuse for tracing and monitoring.
          allOf:
          - $ref: '#/components/schemas/LangfuseObservabilityPlan'
          oneOf:
          - $ref: '#/components/schemas/LangfuseObservabilityPlan'
        credentials:
          type: array
          description: "These are dynamic credentials that will be used for the assistant calls. By default, all the credentials are available for use in the call but you can supplement an additional credentials using this. Dynamic credentials override existing credentials."
          items:
            discriminator:
              propertyName: provider
              mapping:
                "11labs": '#/components/schemas/CreateElevenLabsCredentialDTO'
                anthropic: '#/components/schemas/CreateAnthropicCredentialDTO'
                anyscale: '#/components/schemas/CreateAnyscaleCredentialDTO'
                assembly-ai: '#/components/schemas/CreateAssemblyAICredentialDTO'
                azure-openai: '#/components/schemas/CreateAzureOpenAICredentialDTO'
                azure: '#/components/schemas/CreateAzureCredentialDTO'
                byo-sip-trunk: '#/components/schemas/CreateByoSipTrunkCredentialDTO'
                cartesia: '#/components/schemas/CreateCartesiaCredentialDTO'
                cerebras: '#/components/schemas/CreateCerebrasCredentialDTO'
                cloudflare: '#/components/schemas/CreateCloudflareCredentialDTO'
                custom-llm: '#/components/schemas/CreateCustomLLMCredentialDTO'
                deepgram: '#/components/schemas/CreateDeepgramCredentialDTO'
                deepinfra: '#/components/schemas/CreateDeepInfraCredentialDTO'
                deep-seek: '#/components/schemas/CreateDeepSeekCredentialDTO'
                gcp: '#/components/schemas/CreateGcpCredentialDTO'
                gladia: '#/components/schemas/CreateGladiaCredentialDTO'
                gohighlevel: '#/components/schemas/CreateGoHighLevelCredentialDTO'
                google: '#/components/schemas/CreateGoogleCredentialDTO'
                groq: '#/components/schemas/CreateGroqCredentialDTO'
                inflection-ai: '#/components/schemas/CreateInflectionAICredentialDTO'
                langfuse: '#/components/schemas/CreateLangfuseCredentialDTO'
                lmnt: '#/components/schemas/CreateLmntCredentialDTO'
                make: '#/components/schemas/CreateMakeCredentialDTO'
                openai: '#/components/schemas/CreateOpenAICredentialDTO'
                openrouter: '#/components/schemas/CreateOpenRouterCredentialDTO'
                perplexity-ai: '#/components/schemas/CreatePerplexityAICredentialDTO'
                playht: '#/components/schemas/CreatePlayHTCredentialDTO'
                rime-ai: '#/components/schemas/CreateRimeAICredentialDTO'
                runpod: '#/components/schemas/CreateRunpodCredentialDTO'
                s3: '#/components/schemas/CreateS3CredentialDTO'
                supabase: '#/components/schemas/CreateSupabaseCredentialDTO'
                smallest-ai: '#/components/schemas/CreateSmallestAICredentialDTO'
                tavus: '#/components/schemas/CreateTavusCredentialDTO'
                together-ai: '#/components/schemas/CreateTogetherAICredentialDTO'
                twilio: '#/components/schemas/CreateTwilioCredentialDTO'
                vonage: '#/components/schemas/CreateVonageCredentialDTO'
                webhook: '#/components/schemas/CreateWebhookCredentialDTO'
                xai: '#/components/schemas/CreateXAiCredentialDTO'
                neuphonic: '#/components/schemas/CreateNeuphonicCredentialDTO'
                hume: '#/components/schemas/CreateHumeCredentialDTO'
                mistral: '#/components/schemas/CreateMistralCredentialDTO'
                speechmatics: '#/components/schemas/CreateSpeechmaticsCredentialDTO'
                trieve: '#/components/schemas/CreateTrieveCredentialDTO'
                google.calendar.oauth2-client: '#/components/schemas/CreateGoogleCalendarOAuth2ClientCredentialDTO'
                google.calendar.oauth2-authorization: '#/components/schemas/CreateGoogleCalendarOAuth2AuthorizationCredentialDTO'
                google.sheets.oauth2-authorization: '#/components/schemas/CreateGoogleSheetsOAuth2AuthorizationCredentialDTO'
                slack.oauth2-authorization: '#/components/schemas/CreateSlackOAuth2AuthorizationCredentialDTO'
            oneOf:
            - $ref: '#/components/schemas/CreateAnthropicCredentialDTO'
            - $ref: '#/components/schemas/CreateAnyscaleCredentialDTO'
            - $ref: '#/components/schemas/CreateAssemblyAICredentialDTO'
            - $ref: '#/components/schemas/CreateAzureCredentialDTO'
            - $ref: '#/components/schemas/CreateAzureOpenAICredentialDTO'
            - $ref: '#/components/schemas/CreateByoSipTrunkCredentialDTO'
            - $ref: '#/components/schemas/CreateCartesiaCredentialDTO'
            - $ref: '#/components/schemas/CreateCerebrasCredentialDTO'
            - $ref: '#/components/schemas/CreateCloudflareCredentialDTO'
            - $ref: '#/components/schemas/CreateCustomLLMCredentialDTO'
            - $ref: '#/components/schemas/CreateDeepgramCredentialDTO'
            - $ref: '#/components/schemas/CreateDeepInfraCredentialDTO'
            - $ref: '#/components/schemas/CreateDeepSeekCredentialDTO'
            - $ref: '#/components/schemas/CreateElevenLabsCredentialDTO'
            - $ref: '#/components/schemas/CreateGcpCredentialDTO'
            - $ref: '#/components/schemas/CreateGladiaCredentialDTO'
            - $ref: '#/components/schemas/CreateGoHighLevelCredentialDTO'
            - $ref: '#/components/schemas/CreateGoogleCredentialDTO'
            - $ref: '#/components/schemas/CreateGroqCredentialDTO'
            - $ref: '#/components/schemas/CreateHumeCredentialDTO'
            - $ref: '#/components/schemas/CreateInflectionAICredentialDTO'
            - $ref: '#/components/schemas/CreateLangfuseCredentialDTO'
            - $ref: '#/components/schemas/CreateLmntCredentialDTO'
            - $ref: '#/components/schemas/CreateMakeCredentialDTO'
            - $ref: '#/components/schemas/CreateMistralCredentialDTO'
            - $ref: '#/components/schemas/CreateNeuphonicCredentialDTO'
            - $ref: '#/components/schemas/CreateOpenAICredentialDTO'
            - $ref: '#/components/schemas/CreateOpenRouterCredentialDTO'
            - $ref: '#/components/schemas/CreatePerplexityAICredentialDTO'
            - $ref: '#/components/schemas/CreatePlayHTCredentialDTO'
            - $ref: '#/components/schemas/CreateRimeAICredentialDTO'
            - $ref: '#/components/schemas/CreateRunpodCredentialDTO'
            - $ref: '#/components/schemas/CreateS3CredentialDTO'
            - $ref: '#/components/schemas/CreateSmallestAICredentialDTO'
            - $ref: '#/components/schemas/CreateSpeechmaticsCredentialDTO'
            - $ref: '#/components/schemas/CreateSupabaseCredentialDTO'
            - $ref: '#/components/schemas/CreateTavusCredentialDTO'
            - $ref: '#/components/schemas/CreateTogetherAICredentialDTO'
            - $ref: '#/components/schemas/CreateTrieveCredentialDTO'
            - $ref: '#/components/schemas/CreateTwilioCredentialDTO'
            - $ref: '#/components/schemas/CreateVonageCredentialDTO'
            - $ref: '#/components/schemas/CreateWebhookCredentialDTO'
            - $ref: '#/components/schemas/CreateXAiCredentialDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarOAuth2ClientCredentialDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarOAuth2AuthorizationCredentialDTO'
            - $ref: '#/components/schemas/CreateGoogleSheetsOAuth2AuthorizationCredentialDTO'
            - $ref: '#/components/schemas/CreateSlackOAuth2AuthorizationCredentialDTO'
        name:
          maxLength: 40
          type: string
          description: |-
            This is the name of the assistant.

            This is required when you want to transfer between assistants in a call.
        voicemailMessage:
          maxLength: 1000
          type: string
          description: |-
            This is the message that the assistant will say if the call is forwarded to voicemail.

            If unspecified, it will hang up.
        endCallMessage:
          maxLength: 1000
          type: string
          description: |-
            This is the message that the assistant will say if it ends the call.

            If unspecified, it will hang up without saying anything.
        endCallPhrases:
          type: array
          description: "This list contains phrases that, if spoken by the assistant, will trigger the call to be hung up. Case insensitive."
          items:
            maxLength: 140
            minLength: 2
            type: string
        compliancePlan:
          $ref: '#/components/schemas/CompliancePlan'
        metadata:
          type: object
          description: This is for metadata you want to store on the assistant.
        analysisPlan:
          description: This is the plan for analysis of assistant's calls. Stored in `call.analysis`.
          allOf:
          - $ref: '#/components/schemas/AnalysisPlan'
        artifactPlan:
          description: |-
            This is the plan for artifacts generated during assistant's calls. Stored in `call.artifact`.

            Note: `recordingEnabled` is currently at the root level. It will be moved to `artifactPlan` in the future, but will remain backwards compatible.
          allOf:
          - $ref: '#/components/schemas/ArtifactPlan'
        messagePlan:
          description: |-
            This is the plan for static predefined messages that can be spoken by the assistant during the call, like `idleMessages`.

            Note: `firstMessage`, `voicemailMessage`, and `endCallMessage` are currently at the root level. They will be moved to `messagePlan` in the future, but will remain backwards compatible.
          allOf:
          - $ref: '#/components/schemas/MessagePlan'
        startSpeakingPlan:
          description: |-
            This is the plan for when the assistant should start talking.

            You should configure this if you're running into these issues:
            - The assistant is too slow to start talking after the customer is done speaking.
            - The assistant is too fast to start talking after the customer is done speaking.
            - The assistant is so fast that it's actually interrupting the customer.
          allOf:
          - $ref: '#/components/schemas/StartSpeakingPlan'
        stopSpeakingPlan:
          description: |-
            This is the plan for when assistant should stop talking on customer interruption.

            You should configure this if you're running into these issues:
            - The assistant is too slow to recognize customer's interruption.
            - The assistant is too fast to recognize customer's interruption.
            - The assistant is getting interrupted by phrases that are just acknowledgments.
            - The assistant is getting interrupted by background noises.
            - The assistant is not properly stopping -- it starts talking right after getting interrupted.
          allOf:
          - $ref: '#/components/schemas/StopSpeakingPlan'
        monitorPlan:
          description: |-
            This is the plan for real-time monitoring of the assistant's calls.

            Usage:
            - To enable live listening of the assistant's calls, set `monitorPlan.listenEnabled` to `true`.
            - To enable live control of the assistant's calls, set `monitorPlan.controlEnabled` to `true`.

            Note, `serverMessages`, `clientMessages`, `serverUrl` and `serverUrlSecret` are currently at the root level but will be moved to `monitorPlan` in the future. Will remain backwards compatible
          allOf:
          - $ref: '#/components/schemas/MonitorPlan'
        credentialIds:
          type: array
          description: "These are the credentials that will be used for the assistant calls. By default, all the credentials are available for use in the call but you can provide a subset using this."
          items:
            type: string
        server:
          description: |-
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. assistant.server.url
            2. phoneNumber.serverUrl
            3. org.serverUrl
          allOf:
          - $ref: '#/components/schemas/Server'
        hooks:
          type: array
          description: This is a set of actions that will be performed on certain events.
          items:
            $ref: '#/components/schemas/AssistantHooks'
        keypadInputPlan:
          $ref: '#/components/schemas/KeypadInputPlan'
        id:
          type: string
          description: This is the unique identifier for the assistant.
        orgId:
          type: string
          description: This is the unique identifier for the org that this assistant belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
    AssistantPaginatedResponse:
      required:
      - metadata
      - results
      type: object
      properties:
        results:
          type: array
          items:
            $ref: '#/components/schemas/Assistant'
        metadata:
          $ref: '#/components/schemas/PaginationMeta'
    UpdateAssistantDTO:
      type: object
      properties:
        transcriber:
          description: These are the options for the assistant's transcriber.
          oneOf:
          - $ref: '#/components/schemas/AssemblyAITranscriber'
          - $ref: '#/components/schemas/AzureSpeechTranscriber'
          - $ref: '#/components/schemas/CustomTranscriber'
          - $ref: '#/components/schemas/DeepgramTranscriber'
          - $ref: '#/components/schemas/ElevenLabsTranscriber'
          - $ref: '#/components/schemas/GladiaTranscriber'
          - $ref: '#/components/schemas/SpeechmaticsTranscriber'
          - $ref: '#/components/schemas/TalkscriberTranscriber'
          - $ref: '#/components/schemas/GoogleTranscriber'
          - $ref: '#/components/schemas/OpenAITranscriber'
        model:
          description: These are the options for the assistant's LLM.
          oneOf:
          - $ref: '#/components/schemas/AnyscaleModel'
          - $ref: '#/components/schemas/AnthropicModel'
          - $ref: '#/components/schemas/CerebrasModel'
          - $ref: '#/components/schemas/CustomLLMModel'
          - $ref: '#/components/schemas/DeepInfraModel'
          - $ref: '#/components/schemas/DeepSeekModel'
          - $ref: '#/components/schemas/GoogleModel'
          - $ref: '#/components/schemas/GroqModel'
          - $ref: '#/components/schemas/InflectionAIModel'
          - $ref: '#/components/schemas/OpenAIModel'
          - $ref: '#/components/schemas/OpenRouterModel'
          - $ref: '#/components/schemas/PerplexityAIModel'
          - $ref: '#/components/schemas/TogetherAIModel'
          - $ref: '#/components/schemas/VapiModel'
          - $ref: '#/components/schemas/XaiModel'
        voice:
          description: These are the options for the assistant's voice.
          oneOf:
          - $ref: '#/components/schemas/AzureVoice'
          - $ref: '#/components/schemas/CartesiaVoice'
          - $ref: '#/components/schemas/CustomVoice'
          - $ref: '#/components/schemas/DeepgramVoice'
          - $ref: '#/components/schemas/ElevenLabsVoice'
          - $ref: '#/components/schemas/HumeVoice'
          - $ref: '#/components/schemas/LMNTVoice'
          - $ref: '#/components/schemas/NeuphonicVoice'
          - $ref: '#/components/schemas/OpenAIVoice'
          - $ref: '#/components/schemas/PlayHTVoice'
          - $ref: '#/components/schemas/RimeAIVoice'
          - $ref: '#/components/schemas/SmallestAIVoice'
          - $ref: '#/components/schemas/TavusVoice'
          - $ref: '#/components/schemas/VapiVoice'
          default:
            provider: playht
            voiceId: jennifer
        firstMessage:
          type: string
          description: |-
            This is the first message that the assistant will say. This can also be a URL to a containerized audio file (mp3, wav, etc.).

            If unspecified, assistant will wait for user to speak and use the model to respond once they speak.
          example: Hello! How can I help you today?
        firstMessageInterruptionsEnabled:
          type: boolean
          default: false
        firstMessageMode:
          type: string
          description: |-
            This is the mode for the first message. Default is 'assistant-speaks-first'.

            Use:
            - 'assistant-speaks-first' to have the assistant speak first.
            - 'assistant-waits-for-user' to have the assistant wait for the user to speak first.
            - 'assistant-speaks-first-with-model-generated-message' to have the assistant speak first with a message generated by the model based on the conversation state. (`assistant.model.messages` at call start, `call.messages` at squad transfer points).

            @default 'assistant-speaks-first'
          example: assistant-speaks-first
          enum:
          - assistant-speaks-first
          - assistant-speaks-first-with-model-generated-message
          - assistant-waits-for-user
        voicemailDetection:
          description: |-
            These are the settings to configure or disable voicemail detection. Alternatively, voicemail detection can be configured using the model.tools=[VoicemailTool].
            This uses Twilio's built-in detection while the VoicemailTool relies on the model to detect if a voicemail was reached.
            You can use neither of them, one of them, or both of them. By default, Twilio built-in detection is enabled while VoicemailTool is not.
          oneOf:
          - $ref: '#/components/schemas/GoogleVoicemailDetectionPlan'
          - $ref: '#/components/schemas/OpenAIVoicemailDetectionPlan'
          - $ref: '#/components/schemas/TwilioVoicemailDetectionPlan'
        clientMessages:
          type: array
          description: "These are the messages that will be sent to your Client SDKs. Default is conversation-update,function-call,hang,model-output,speech-update,status-update,transfer-update,transcript,tool-calls,user-interrupted,voice-input,workflow.node.started. You can check the shape of the messages in ClientMessage schema."
          example:
          - conversation-update
          - function-call
          - hang
          - model-output
          - speech-update
          - status-update
          - transfer-update
          - transcript
          - tool-calls
          - user-interrupted
          - voice-input
          - workflow.node.started
          items:
            type: string
            enum:
            - conversation-update
            - function-call
            - function-call-result
            - hang
            - language-changed
            - metadata
            - model-output
            - speech-update
            - status-update
            - transcript
            - tool-calls
            - tool-calls-result
            - transfer-update
            - user-interrupted
            - voice-input
            - workflow.node.started
          enum:
          - conversation-update
          - function-call
          - function-call-result
          - hang
          - language-changed
          - metadata
          - model-output
          - speech-update
          - status-update
          - transcript
          - tool-calls
          - tool-calls-result
          - transfer-update
          - user-interrupted
          - voice-input
          - workflow.node.started
        serverMessages:
          type: array
          description: "These are the messages that will be sent to your Server URL. Default is conversation-update,end-of-call-report,function-call,hang,speech-update,status-update,tool-calls,transfer-destination-request,user-interrupted. You can check the shape of the messages in ServerMessage schema."
          example:
          - conversation-update
          - end-of-call-report
          - function-call
          - hang
          - speech-update
          - status-update
          - tool-calls
          - transfer-destination-request
          - user-interrupted
          items:
            type: string
            enum:
            - conversation-update
            - end-of-call-report
            - function-call
            - hang
            - language-changed
            - language-change-detected
            - model-output
            - phone-call-control
            - speech-update
            - status-update
            - transcript
            - "transcript[transcriptType=\"final\"]"
            - tool-calls
            - transfer-destination-request
            - transfer-update
            - user-interrupted
            - voice-input
          enum:
          - conversation-update
          - end-of-call-report
          - function-call
          - hang
          - language-changed
          - language-change-detected
          - model-output
          - phone-call-control
          - speech-update
          - status-update
          - transcript
          - "transcript[transcriptType=\"final\"]"
          - tool-calls
          - transfer-destination-request
          - transfer-update
          - user-interrupted
          - voice-input
        silenceTimeoutSeconds:
          maximum: 3600
          minimum: 10
          type: number
          description: |-
            How many seconds of silence to wait before ending the call. Defaults to 30.

            @default 30
          example: 30
        maxDurationSeconds:
          maximum: 43200
          minimum: 10
          type: number
          description: |-
            This is the maximum number of seconds that the call will last. When the call reaches this duration, it will be ended.

            @default 600 (10 minutes)
          example: 600
        backgroundSound:
          maxLength: 1000
          description: |-
            This is the background sound in the call. Default for phone calls is 'office' and default for web calls is 'off'.
            You can also provide a custom sound by providing a URL to an audio file.
          oneOf:
          - type: string
            example: office
            enum:
            - "false"
            - office
          - type: string
            format: uri
            example: https://www.soundjay.com/ambient/sounds/people-in-lounge-1.mp3
        backgroundDenoisingEnabled:
          type: boolean
          description: |-
            This enables filtering of noise and background speech while the user is talking.

            Default `false` while in beta.

            @default false
          example: false
        modelOutputInMessagesEnabled:
          type: boolean
          description: |-
            This determines whether the model's output is used in conversation history rather than the transcription of assistant's speech.

            Default `false` while in beta.

            @default false
          example: false
        transportConfigurations:
          type: array
          description: "These are the configurations to be passed to the transport providers of assistant's calls, like Twilio. You can store multiple configurations for different transport providers. For a call, only the configuration matching the call transport provider is used."
          items:
            oneOf:
            - $ref: '#/components/schemas/TransportConfigurationTwilio'
        observabilityPlan:
          description: |-
            This is the plan for observability configuration of assistant's calls.
            Currently supports Langfuse for tracing and monitoring.
          allOf:
          - $ref: '#/components/schemas/LangfuseObservabilityPlan'
          oneOf:
          - $ref: '#/components/schemas/LangfuseObservabilityPlan'
        credentials:
          type: array
          description: "These are dynamic credentials that will be used for the assistant calls. By default, all the credentials are available for use in the call but you can supplement an additional credentials using this. Dynamic credentials override existing credentials."
          items:
            discriminator:
              propertyName: provider
              mapping:
                "11labs": '#/components/schemas/CreateElevenLabsCredentialDTO'
                anthropic: '#/components/schemas/CreateAnthropicCredentialDTO'
                anyscale: '#/components/schemas/CreateAnyscaleCredentialDTO'
                assembly-ai: '#/components/schemas/CreateAssemblyAICredentialDTO'
                azure-openai: '#/components/schemas/CreateAzureOpenAICredentialDTO'
                azure: '#/components/schemas/CreateAzureCredentialDTO'
                byo-sip-trunk: '#/components/schemas/CreateByoSipTrunkCredentialDTO'
                cartesia: '#/components/schemas/CreateCartesiaCredentialDTO'
                cerebras: '#/components/schemas/CreateCerebrasCredentialDTO'
                cloudflare: '#/components/schemas/CreateCloudflareCredentialDTO'
                custom-llm: '#/components/schemas/CreateCustomLLMCredentialDTO'
                deepgram: '#/components/schemas/CreateDeepgramCredentialDTO'
                deepinfra: '#/components/schemas/CreateDeepInfraCredentialDTO'
                deep-seek: '#/components/schemas/CreateDeepSeekCredentialDTO'
                gcp: '#/components/schemas/CreateGcpCredentialDTO'
                gladia: '#/components/schemas/CreateGladiaCredentialDTO'
                gohighlevel: '#/components/schemas/CreateGoHighLevelCredentialDTO'
                google: '#/components/schemas/CreateGoogleCredentialDTO'
                groq: '#/components/schemas/CreateGroqCredentialDTO'
                inflection-ai: '#/components/schemas/CreateInflectionAICredentialDTO'
                langfuse: '#/components/schemas/CreateLangfuseCredentialDTO'
                lmnt: '#/components/schemas/CreateLmntCredentialDTO'
                make: '#/components/schemas/CreateMakeCredentialDTO'
                openai: '#/components/schemas/CreateOpenAICredentialDTO'
                openrouter: '#/components/schemas/CreateOpenRouterCredentialDTO'
                perplexity-ai: '#/components/schemas/CreatePerplexityAICredentialDTO'
                playht: '#/components/schemas/CreatePlayHTCredentialDTO'
                rime-ai: '#/components/schemas/CreateRimeAICredentialDTO'
                runpod: '#/components/schemas/CreateRunpodCredentialDTO'
                s3: '#/components/schemas/CreateS3CredentialDTO'
                supabase: '#/components/schemas/CreateSupabaseCredentialDTO'
                smallest-ai: '#/components/schemas/CreateSmallestAICredentialDTO'
                tavus: '#/components/schemas/CreateTavusCredentialDTO'
                together-ai: '#/components/schemas/CreateTogetherAICredentialDTO'
                twilio: '#/components/schemas/CreateTwilioCredentialDTO'
                vonage: '#/components/schemas/CreateVonageCredentialDTO'
                webhook: '#/components/schemas/CreateWebhookCredentialDTO'
                xai: '#/components/schemas/CreateXAiCredentialDTO'
                neuphonic: '#/components/schemas/CreateNeuphonicCredentialDTO'
                hume: '#/components/schemas/CreateHumeCredentialDTO'
                mistral: '#/components/schemas/CreateMistralCredentialDTO'
                speechmatics: '#/components/schemas/CreateSpeechmaticsCredentialDTO'
                trieve: '#/components/schemas/CreateTrieveCredentialDTO'
                google.calendar.oauth2-client: '#/components/schemas/CreateGoogleCalendarOAuth2ClientCredentialDTO'
                google.calendar.oauth2-authorization: '#/components/schemas/CreateGoogleCalendarOAuth2AuthorizationCredentialDTO'
                google.sheets.oauth2-authorization: '#/components/schemas/CreateGoogleSheetsOAuth2AuthorizationCredentialDTO'
                slack.oauth2-authorization: '#/components/schemas/CreateSlackOAuth2AuthorizationCredentialDTO'
            oneOf:
            - $ref: '#/components/schemas/CreateAnthropicCredentialDTO'
            - $ref: '#/components/schemas/CreateAnyscaleCredentialDTO'
            - $ref: '#/components/schemas/CreateAssemblyAICredentialDTO'
            - $ref: '#/components/schemas/CreateAzureCredentialDTO'
            - $ref: '#/components/schemas/CreateAzureOpenAICredentialDTO'
            - $ref: '#/components/schemas/CreateByoSipTrunkCredentialDTO'
            - $ref: '#/components/schemas/CreateCartesiaCredentialDTO'
            - $ref: '#/components/schemas/CreateCerebrasCredentialDTO'
            - $ref: '#/components/schemas/CreateCloudflareCredentialDTO'
            - $ref: '#/components/schemas/CreateCustomLLMCredentialDTO'
            - $ref: '#/components/schemas/CreateDeepgramCredentialDTO'
            - $ref: '#/components/schemas/CreateDeepInfraCredentialDTO'
            - $ref: '#/components/schemas/CreateDeepSeekCredentialDTO'
            - $ref: '#/components/schemas/CreateElevenLabsCredentialDTO'
            - $ref: '#/components/schemas/CreateGcpCredentialDTO'
            - $ref: '#/components/schemas/CreateGladiaCredentialDTO'
            - $ref: '#/components/schemas/CreateGoHighLevelCredentialDTO'
            - $ref: '#/components/schemas/CreateGoogleCredentialDTO'
            - $ref: '#/components/schemas/CreateGroqCredentialDTO'
            - $ref: '#/components/schemas/CreateHumeCredentialDTO'
            - $ref: '#/components/schemas/CreateInflectionAICredentialDTO'
            - $ref: '#/components/schemas/CreateLangfuseCredentialDTO'
            - $ref: '#/components/schemas/CreateLmntCredentialDTO'
            - $ref: '#/components/schemas/CreateMakeCredentialDTO'
            - $ref: '#/components/schemas/CreateMistralCredentialDTO'
            - $ref: '#/components/schemas/CreateNeuphonicCredentialDTO'
            - $ref: '#/components/schemas/CreateOpenAICredentialDTO'
            - $ref: '#/components/schemas/CreateOpenRouterCredentialDTO'
            - $ref: '#/components/schemas/CreatePerplexityAICredentialDTO'
            - $ref: '#/components/schemas/CreatePlayHTCredentialDTO'
            - $ref: '#/components/schemas/CreateRimeAICredentialDTO'
            - $ref: '#/components/schemas/CreateRunpodCredentialDTO'
            - $ref: '#/components/schemas/CreateS3CredentialDTO'
            - $ref: '#/components/schemas/CreateSmallestAICredentialDTO'
            - $ref: '#/components/schemas/CreateSpeechmaticsCredentialDTO'
            - $ref: '#/components/schemas/CreateSupabaseCredentialDTO'
            - $ref: '#/components/schemas/CreateTavusCredentialDTO'
            - $ref: '#/components/schemas/CreateTogetherAICredentialDTO'
            - $ref: '#/components/schemas/CreateTrieveCredentialDTO'
            - $ref: '#/components/schemas/CreateTwilioCredentialDTO'
            - $ref: '#/components/schemas/CreateVonageCredentialDTO'
            - $ref: '#/components/schemas/CreateWebhookCredentialDTO'
            - $ref: '#/components/schemas/CreateXAiCredentialDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarOAuth2ClientCredentialDTO'
            - $ref: '#/components/schemas/CreateGoogleCalendarOAuth2AuthorizationCredentialDTO'
            - $ref: '#/components/schemas/CreateGoogleSheetsOAuth2AuthorizationCredentialDTO'
            - $ref: '#/components/schemas/CreateSlackOAuth2AuthorizationCredentialDTO'
        name:
          maxLength: 40
          type: string
          description: |-
            This is the name of the assistant.

            This is required when you want to transfer between assistants in a call.
        voicemailMessage:
          maxLength: 1000
          type: string
          description: |-
            This is the message that the assistant will say if the call is forwarded to voicemail.

            If unspecified, it will hang up.
        endCallMessage:
          maxLength: 1000
          type: string
          description: |-
            This is the message that the assistant will say if it ends the call.

            If unspecified, it will hang up without saying anything.
        endCallPhrases:
          type: array
          description: "This list contains phrases that, if spoken by the assistant, will trigger the call to be hung up. Case insensitive."
          items:
            maxLength: 140
            minLength: 2
            type: string
        compliancePlan:
          $ref: '#/components/schemas/CompliancePlan'
        metadata:
          type: object
          description: This is for metadata you want to store on the assistant.
        analysisPlan:
          description: This is the plan for analysis of assistant's calls. Stored in `call.analysis`.
          allOf:
          - $ref: '#/components/schemas/AnalysisPlan'
        artifactPlan:
          description: |-
            This is the plan for artifacts generated during assistant's calls. Stored in `call.artifact`.

            Note: `recordingEnabled` is currently at the root level. It will be moved to `artifactPlan` in the future, but will remain backwards compatible.
          allOf:
          - $ref: '#/components/schemas/ArtifactPlan'
        messagePlan:
          description: |-
            This is the plan for static predefined messages that can be spoken by the assistant during the call, like `idleMessages`.

            Note: `firstMessage`, `voicemailMessage`, and `endCallMessage` are currently at the root level. They will be moved to `messagePlan` in the future, but will remain backwards compatible.
          allOf:
          - $ref: '#/components/schemas/MessagePlan'
        startSpeakingPlan:
          description: |-
            This is the plan for when the assistant should start talking.

            You should configure this if you're running into these issues:
            - The assistant is too slow to start talking after the customer is done speaking.
            - The assistant is too fast to start talking after the customer is done speaking.
            - The assistant is so fast that it's actually interrupting the customer.
          allOf:
          - $ref: '#/components/schemas/StartSpeakingPlan'
        stopSpeakingPlan:
          description: |-
            This is the plan for when assistant should stop talking on customer interruption.

            You should configure this if you're running into these issues:
            - The assistant is too slow to recognize customer's interruption.
            - The assistant is too fast to recognize customer's interruption.
            - The assistant is getting interrupted by phrases that are just acknowledgments.
            - The assistant is getting interrupted by background noises.
            - The assistant is not properly stopping -- it starts talking right after getting interrupted.
          allOf:
          - $ref: '#/components/schemas/StopSpeakingPlan'
        monitorPlan:
          description: |-
            This is the plan for real-time monitoring of the assistant's calls.

            Usage:
            - To enable live listening of the assistant's calls, set `monitorPlan.listenEnabled` to `true`.
            - To enable live control of the assistant's calls, set `monitorPlan.controlEnabled` to `true`.

            Note, `serverMessages`, `clientMessages`, `serverUrl` and `serverUrlSecret` are currently at the root level but will be moved to `monitorPlan` in the future. Will remain backwards compatible
          allOf:
          - $ref: '#/components/schemas/MonitorPlan'
        credentialIds:
          type: array
          description: "These are the credentials that will be used for the assistant calls. By default, all the credentials are available for use in the call but you can provide a subset using this."
          items:
            type: string
        server:
          description: |-
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. assistant.server.url
            2. phoneNumber.serverUrl
            3. org.serverUrl
          allOf:
          - $ref: '#/components/schemas/Server'
        hooks:
          type: array
          description: This is a set of actions that will be performed on certain events.
          items:
            $ref: '#/components/schemas/AssistantHooks'
        keypadInputPlan:
          $ref: '#/components/schemas/KeypadInputPlan'
    ByoPhoneNumber:
      required:
      - createdAt
      - credentialId
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        fallbackDestination:
          description: |-
            This is the fallback destination an inbound call will be transferred to if:
            1. `assistantId` is not set
            2. `squadId` is not set
            3. and, `assistant-request` message to the `serverUrl` fails

            If this is not set and above conditions are met, the inbound call is hung up with an error message.
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
        hooks:
          type: array
          description: This is the hooks that will be used for incoming calls to this phone number.
          items: {}
        provider:
          type: string
          description: This is to bring your own phone numbers from your own SIP trunks or Carriers.
          enum:
          - byo-phone-number
        numberE164CheckEnabled:
          type: boolean
          description: |-
            This is the flag to toggle the E164 check for the `number` field. This is an advanced property which should be used if you know your use case requires it.

            Use cases:
            - `false`: To allow non-E164 numbers like `+001234567890`, `1234`, or `abc`. This is useful for dialing out to non-E164 numbers on your SIP trunks.
            - `true` (default): To allow only E164 numbers like `+14155551234`. This is standard for PSTN calls.

            If `false`, the `number` is still required to only contain alphanumeric characters (regex: `/^\+?[a-zA-Z0-9]+$/`).

            @default true (E164 check is enabled)
          default: true
        id:
          type: string
          description: This is the unique identifier for the phone number.
        orgId:
          type: string
          description: This is the unique identifier for the org that this phone number belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the phone number was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the phone number was last updated.
          format: date-time
        status:
          type: string
          description: This is the status of the phone number.
          enum:
          - active
          - activating
          - blocked
        name:
          maxLength: 40
          type: string
          description: This is the name of the phone number. This is just for your own reference.
        assistantId:
          type: string
          description: |-
            This is the assistant that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        squadId:
          type: string
          description: |-
            This is the squad that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        server:
          description: |-
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. assistant.server
            2. phoneNumber.server
            3. org.server
          allOf:
          - $ref: '#/components/schemas/Server'
        number:
          maxLength: 40
          minLength: 3
          type: string
          description: This is the number of the customer.
        credentialId:
          type: string
          description: |-
            This is the credential of your own SIP trunk or Carrier (type `byo-sip-trunk`) which can be used to make calls to this phone number.

            You can add the SIP trunk or Carrier credential in the Provider Credentials page on the Dashboard to get the credentialId.
    TwilioPhoneNumber:
      required:
      - createdAt
      - id
      - number
      - orgId
      - provider
      - twilioAccountSid
      - twilioAuthToken
      - updatedAt
      type: object
      properties:
        fallbackDestination:
          description: |-
            This is the fallback destination an inbound call will be transferred to if:
            1. `assistantId` is not set
            2. `squadId` is not set
            3. and, `assistant-request` message to the `serverUrl` fails

            If this is not set and above conditions are met, the inbound call is hung up with an error message.
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
        hooks:
          type: array
          description: This is the hooks that will be used for incoming calls to this phone number.
          items: {}
        provider:
          type: string
          description: This is to use numbers bought on Twilio.
          enum:
          - twilio
        id:
          type: string
          description: This is the unique identifier for the phone number.
        orgId:
          type: string
          description: This is the unique identifier for the org that this phone number belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the phone number was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the phone number was last updated.
          format: date-time
        status:
          type: string
          description: This is the status of the phone number.
          enum:
          - active
          - activating
          - blocked
        name:
          maxLength: 40
          type: string
          description: This is the name of the phone number. This is just for your own reference.
        assistantId:
          type: string
          description: |-
            This is the assistant that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        squadId:
          type: string
          description: |-
            This is the squad that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        server:
          description: |-
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. assistant.server
            2. phoneNumber.server
            3. org.server
          allOf:
          - $ref: '#/components/schemas/Server'
        number:
          type: string
          description: These are the digits of the phone number you own on your Twilio.
        twilioAccountSid:
          type: string
          description: This is the Twilio Account SID for the phone number.
        twilioAuthToken:
          type: string
          description: This is the Twilio Auth Token for the phone number.
    VonagePhoneNumber:
      required:
      - createdAt
      - credentialId
      - id
      - number
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        fallbackDestination:
          description: |-
            This is the fallback destination an inbound call will be transferred to if:
            1. `assistantId` is not set
            2. `squadId` is not set
            3. and, `assistant-request` message to the `serverUrl` fails

            If this is not set and above conditions are met, the inbound call is hung up with an error message.
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
        hooks:
          type: array
          description: This is the hooks that will be used for incoming calls to this phone number.
          items: {}
        provider:
          type: string
          description: This is to use numbers bought on Vonage.
          enum:
          - vonage
        id:
          type: string
          description: This is the unique identifier for the phone number.
        orgId:
          type: string
          description: This is the unique identifier for the org that this phone number belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the phone number was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the phone number was last updated.
          format: date-time
        status:
          type: string
          description: This is the status of the phone number.
          enum:
          - active
          - activating
          - blocked
        name:
          maxLength: 40
          type: string
          description: This is the name of the phone number. This is just for your own reference.
        assistantId:
          type: string
          description: |-
            This is the assistant that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        squadId:
          type: string
          description: |-
            This is the squad that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        server:
          description: |-
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. assistant.server
            2. phoneNumber.server
            3. org.server
          allOf:
          - $ref: '#/components/schemas/Server'
        number:
          type: string
          description: These are the digits of the phone number you own on your Vonage.
        credentialId:
          type: string
          description: "This is the credential you added in dashboard.vapi.ai/keys. This is used to configure the number to send inbound calls to Vapi, make outbound calls and do live call updates like transfers and hangups."
    SipAuthentication:
      required:
      - password
      - username
      type: object
      properties:
        realm:
          type: string
          description: This will be expected in the `realm` field of the `authorization` header of the SIP INVITE. Defaults to sip.vapi.ai.
        username:
          maxLength: 40
          minLength: 20
          type: string
          description: This will be expected in the `username` field of the `authorization` header of the SIP INVITE.
        password:
          maxLength: 40
          minLength: 20
          type: string
          description: "This will be expected to generate the `response` field of the `authorization` header of the SIP INVITE, through digest authentication."
    VapiPhoneNumber:
      required:
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        fallbackDestination:
          description: |-
            This is the fallback destination an inbound call will be transferred to if:
            1. `assistantId` is not set
            2. `squadId` is not set
            3. and, `assistant-request` message to the `serverUrl` fails

            If this is not set and above conditions are met, the inbound call is hung up with an error message.
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
        hooks:
          type: array
          description: This is the hooks that will be used for incoming calls to this phone number.
          items: {}
        provider:
          type: string
          description: This is to create free SIP phone numbers on Vapi.
          enum:
          - vapi
        id:
          type: string
          description: This is the unique identifier for the phone number.
        orgId:
          type: string
          description: This is the unique identifier for the org that this phone number belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the phone number was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the phone number was last updated.
          format: date-time
        status:
          type: string
          description: This is the status of the phone number.
          enum:
          - active
          - activating
          - blocked
        number:
          type: string
          description: These are the digits of the phone number you purchased from Vapi.
        name:
          maxLength: 40
          type: string
          description: This is the name of the phone number. This is just for your own reference.
        assistantId:
          type: string
          description: |-
            This is the assistant that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        squadId:
          type: string
          description: |-
            This is the squad that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        server:
          description: |-
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. assistant.server
            2. phoneNumber.server
            3. org.server
          allOf:
          - $ref: '#/components/schemas/Server'
        numberDesiredAreaCode:
          maxLength: 3
          minLength: 3
          type: string
          description: This is the area code of the phone number to purchase.
        sipUri:
          type: string
          description: |-
            This is the SIP URI of the phone number. You can SIP INVITE this. The assistant attached to this number will answer.

            This is case-insensitive.
        authentication:
          description: |-
            This enables authentication for incoming SIP INVITE requests to the `sipUri`.

            If not set, any username/password to the 401 challenge of the SIP INVITE will be accepted.
          allOf:
          - $ref: '#/components/schemas/SipAuthentication'
    TelnyxPhoneNumber:
      required:
      - createdAt
      - credentialId
      - id
      - number
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        fallbackDestination:
          description: |-
            This is the fallback destination an inbound call will be transferred to if:
            1. `assistantId` is not set
            2. `squadId` is not set
            3. and, `assistant-request` message to the `serverUrl` fails

            If this is not set and above conditions are met, the inbound call is hung up with an error message.
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
        hooks:
          type: array
          description: This is the hooks that will be used for incoming calls to this phone number.
          items: {}
        provider:
          type: string
          description: This is to use numbers bought on Telnyx.
          enum:
          - telnyx
        id:
          type: string
          description: This is the unique identifier for the phone number.
        orgId:
          type: string
          description: This is the unique identifier for the org that this phone number belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the phone number was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the phone number was last updated.
          format: date-time
        status:
          type: string
          description: This is the status of the phone number.
          enum:
          - active
          - activating
          - blocked
        name:
          maxLength: 40
          type: string
          description: This is the name of the phone number. This is just for your own reference.
        assistantId:
          type: string
          description: |-
            This is the assistant that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        squadId:
          type: string
          description: |-
            This is the squad that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        server:
          description: |-
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. assistant.server
            2. phoneNumber.server
            3. org.server
          allOf:
          - $ref: '#/components/schemas/Server'
        number:
          type: string
          description: These are the digits of the phone number you own on your Telnyx.
        credentialId:
          type: string
          description: "This is the credential you added in dashboard.vapi.ai/keys. This is used to configure the number to send inbound calls to Vapi, make outbound calls and do live call updates like transfers and hangups."
    CreateByoPhoneNumberDTO:
      required:
      - credentialId
      - provider
      type: object
      properties:
        fallbackDestination:
          description: |-
            This is the fallback destination an inbound call will be transferred to if:
            1. `assistantId` is not set
            2. `squadId` is not set
            3. and, `assistant-request` message to the `serverUrl` fails

            If this is not set and above conditions are met, the inbound call is hung up with an error message.
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
        hooks:
          type: array
          description: This is the hooks that will be used for incoming calls to this phone number.
          items: {}
        provider:
          type: string
          description: This is to bring your own phone numbers from your own SIP trunks or Carriers.
          enum:
          - byo-phone-number
        numberE164CheckEnabled:
          type: boolean
          description: |-
            This is the flag to toggle the E164 check for the `number` field. This is an advanced property which should be used if you know your use case requires it.

            Use cases:
            - `false`: To allow non-E164 numbers like `+001234567890`, `1234`, or `abc`. This is useful for dialing out to non-E164 numbers on your SIP trunks.
            - `true` (default): To allow only E164 numbers like `+14155551234`. This is standard for PSTN calls.

            If `false`, the `number` is still required to only contain alphanumeric characters (regex: `/^\+?[a-zA-Z0-9]+$/`).

            @default true (E164 check is enabled)
          default: true
        number:
          maxLength: 40
          minLength: 3
          type: string
          description: This is the number of the customer.
        credentialId:
          type: string
          description: |-
            This is the credential of your own SIP trunk or Carrier (type `byo-sip-trunk`) which can be used to make calls to this phone number.

            You can add the SIP trunk or Carrier credential in the Provider Credentials page on the Dashboard to get the credentialId.
        name:
          maxLength: 40
          type: string
          description: This is the name of the phone number. This is just for your own reference.
        assistantId:
          type: string
          description: |-
            This is the assistant that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        squadId:
          type: string
          description: |-
            This is the squad that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        server:
          description: |-
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. assistant.server
            2. phoneNumber.server
            3. org.server
          allOf:
          - $ref: '#/components/schemas/Server'
    CreateTwilioPhoneNumberDTO:
      required:
      - number
      - provider
      - twilioAccountSid
      - twilioAuthToken
      type: object
      properties:
        fallbackDestination:
          description: |-
            This is the fallback destination an inbound call will be transferred to if:
            1. `assistantId` is not set
            2. `squadId` is not set
            3. and, `assistant-request` message to the `serverUrl` fails

            If this is not set and above conditions are met, the inbound call is hung up with an error message.
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
        hooks:
          type: array
          description: This is the hooks that will be used for incoming calls to this phone number.
          items: {}
        provider:
          type: string
          description: This is to use numbers bought on Twilio.
          enum:
          - twilio
        number:
          type: string
          description: These are the digits of the phone number you own on your Twilio.
        twilioAccountSid:
          type: string
          description: This is the Twilio Account SID for the phone number.
        twilioAuthToken:
          type: string
          description: This is the Twilio Auth Token for the phone number.
        name:
          maxLength: 40
          type: string
          description: This is the name of the phone number. This is just for your own reference.
        assistantId:
          type: string
          description: |-
            This is the assistant that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        squadId:
          type: string
          description: |-
            This is the squad that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        server:
          description: |-
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. assistant.server
            2. phoneNumber.server
            3. org.server
          allOf:
          - $ref: '#/components/schemas/Server'
    CreateVonagePhoneNumberDTO:
      required:
      - credentialId
      - number
      - provider
      type: object
      properties:
        fallbackDestination:
          description: |-
            This is the fallback destination an inbound call will be transferred to if:
            1. `assistantId` is not set
            2. `squadId` is not set
            3. and, `assistant-request` message to the `serverUrl` fails

            If this is not set and above conditions are met, the inbound call is hung up with an error message.
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
        hooks:
          type: array
          description: This is the hooks that will be used for incoming calls to this phone number.
          items: {}
        provider:
          type: string
          description: This is to use numbers bought on Vonage.
          enum:
          - vonage
        number:
          type: string
          description: These are the digits of the phone number you own on your Vonage.
        credentialId:
          type: string
          description: "This is the credential you added in dashboard.vapi.ai/keys. This is used to configure the number to send inbound calls to Vapi, make outbound calls and do live call updates like transfers and hangups."
        name:
          maxLength: 40
          type: string
          description: This is the name of the phone number. This is just for your own reference.
        assistantId:
          type: string
          description: |-
            This is the assistant that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        squadId:
          type: string
          description: |-
            This is the squad that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        server:
          description: |-
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. assistant.server
            2. phoneNumber.server
            3. org.server
          allOf:
          - $ref: '#/components/schemas/Server'
    CreateVapiPhoneNumberDTO:
      required:
      - provider
      type: object
      properties:
        fallbackDestination:
          description: |-
            This is the fallback destination an inbound call will be transferred to if:
            1. `assistantId` is not set
            2. `squadId` is not set
            3. and, `assistant-request` message to the `serverUrl` fails

            If this is not set and above conditions are met, the inbound call is hung up with an error message.
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
        hooks:
          type: array
          description: This is the hooks that will be used for incoming calls to this phone number.
          items: {}
        provider:
          type: string
          description: This is to create free SIP phone numbers on Vapi.
          enum:
          - vapi
        numberDesiredAreaCode:
          maxLength: 3
          minLength: 3
          type: string
          description: This is the area code of the phone number to purchase.
        sipUri:
          type: string
          description: |-
            This is the SIP URI of the phone number. You can SIP INVITE this. The assistant attached to this number will answer.

            This is case-insensitive.
        authentication:
          description: |-
            This enables authentication for incoming SIP INVITE requests to the `sipUri`.

            If not set, any username/password to the 401 challenge of the SIP INVITE will be accepted.
          allOf:
          - $ref: '#/components/schemas/SipAuthentication'
        name:
          maxLength: 40
          type: string
          description: This is the name of the phone number. This is just for your own reference.
        assistantId:
          type: string
          description: |-
            This is the assistant that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        squadId:
          type: string
          description: |-
            This is the squad that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        server:
          description: |-
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. assistant.server
            2. phoneNumber.server
            3. org.server
          allOf:
          - $ref: '#/components/schemas/Server'
    CreateTelnyxPhoneNumberDTO:
      required:
      - credentialId
      - number
      - provider
      type: object
      properties:
        fallbackDestination:
          description: |-
            This is the fallback destination an inbound call will be transferred to if:
            1. `assistantId` is not set
            2. `squadId` is not set
            3. and, `assistant-request` message to the `serverUrl` fails

            If this is not set and above conditions are met, the inbound call is hung up with an error message.
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
        hooks:
          type: array
          description: This is the hooks that will be used for incoming calls to this phone number.
          items: {}
        provider:
          type: string
          description: This is to use numbers bought on Telnyx.
          enum:
          - telnyx
        number:
          type: string
          description: These are the digits of the phone number you own on your Telnyx.
        credentialId:
          type: string
          description: "This is the credential you added in dashboard.vapi.ai/keys. This is used to configure the number to send inbound calls to Vapi, make outbound calls and do live call updates like transfers and hangups."
        name:
          maxLength: 40
          type: string
          description: This is the name of the phone number. This is just for your own reference.
        assistantId:
          type: string
          description: |-
            This is the assistant that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        squadId:
          type: string
          description: |-
            This is the squad that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        server:
          description: |-
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. assistant.server
            2. phoneNumber.server
            3. org.server
          allOf:
          - $ref: '#/components/schemas/Server'
    UpdateByoPhoneNumberDTO:
      type: object
      properties:
        fallbackDestination:
          description: |-
            This is the fallback destination an inbound call will be transferred to if:
            1. `assistantId` is not set
            2. `squadId` is not set
            3. and, `assistant-request` message to the `serverUrl` fails

            If this is not set and above conditions are met, the inbound call is hung up with an error message.
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
        hooks:
          type: array
          description: This is the hooks that will be used for incoming calls to this phone number.
          items: {}
        numberE164CheckEnabled:
          type: boolean
          description: |-
            This is the flag to toggle the E164 check for the `number` field. This is an advanced property which should be used if you know your use case requires it.

            Use cases:
            - `false`: To allow non-E164 numbers like `+001234567890`, `1234`, or `abc`. This is useful for dialing out to non-E164 numbers on your SIP trunks.
            - `true` (default): To allow only E164 numbers like `+14155551234`. This is standard for PSTN calls.

            If `false`, the `number` is still required to only contain alphanumeric characters (regex: `/^\+?[a-zA-Z0-9]+$/`).

            @default true (E164 check is enabled)
          default: true
        name:
          maxLength: 40
          type: string
          description: This is the name of the phone number. This is just for your own reference.
        assistantId:
          type: string
          description: |-
            This is the assistant that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        squadId:
          type: string
          description: |-
            This is the squad that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        server:
          description: |-
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. assistant.server
            2. phoneNumber.server
            3. org.server
          allOf:
          - $ref: '#/components/schemas/Server'
        number:
          maxLength: 40
          minLength: 3
          type: string
          description: This is the number of the customer.
        credentialId:
          type: string
          description: |-
            This is the credential of your own SIP trunk or Carrier (type `byo-sip-trunk`) which can be used to make calls to this phone number.

            You can add the SIP trunk or Carrier credential in the Provider Credentials page on the Dashboard to get the credentialId.
    UpdateTwilioPhoneNumberDTO:
      type: object
      properties:
        fallbackDestination:
          description: |-
            This is the fallback destination an inbound call will be transferred to if:
            1. `assistantId` is not set
            2. `squadId` is not set
            3. and, `assistant-request` message to the `serverUrl` fails

            If this is not set and above conditions are met, the inbound call is hung up with an error message.
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
        hooks:
          type: array
          description: This is the hooks that will be used for incoming calls to this phone number.
          items: {}
        name:
          maxLength: 40
          type: string
          description: This is the name of the phone number. This is just for your own reference.
        assistantId:
          type: string
          description: |-
            This is the assistant that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        squadId:
          type: string
          description: |-
            This is the squad that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        server:
          description: |-
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. assistant.server
            2. phoneNumber.server
            3. org.server
          allOf:
          - $ref: '#/components/schemas/Server'
        number:
          type: string
          description: These are the digits of the phone number you own on your Twilio.
        twilioAccountSid:
          type: string
          description: This is the Twilio Account SID for the phone number.
        twilioAuthToken:
          type: string
          description: This is the Twilio Auth Token for the phone number.
    UpdateVonagePhoneNumberDTO:
      type: object
      properties:
        fallbackDestination:
          description: |-
            This is the fallback destination an inbound call will be transferred to if:
            1. `assistantId` is not set
            2. `squadId` is not set
            3. and, `assistant-request` message to the `serverUrl` fails

            If this is not set and above conditions are met, the inbound call is hung up with an error message.
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
        hooks:
          type: array
          description: This is the hooks that will be used for incoming calls to this phone number.
          items: {}
        name:
          maxLength: 40
          type: string
          description: This is the name of the phone number. This is just for your own reference.
        assistantId:
          type: string
          description: |-
            This is the assistant that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        squadId:
          type: string
          description: |-
            This is the squad that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        server:
          description: |-
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. assistant.server
            2. phoneNumber.server
            3. org.server
          allOf:
          - $ref: '#/components/schemas/Server'
        number:
          type: string
          description: These are the digits of the phone number you own on your Vonage.
        credentialId:
          type: string
          description: "This is the credential you added in dashboard.vapi.ai/keys. This is used to configure the number to send inbound calls to Vapi, make outbound calls and do live call updates like transfers and hangups."
    UpdateVapiPhoneNumberDTO:
      type: object
      properties:
        fallbackDestination:
          description: |-
            This is the fallback destination an inbound call will be transferred to if:
            1. `assistantId` is not set
            2. `squadId` is not set
            3. and, `assistant-request` message to the `serverUrl` fails

            If this is not set and above conditions are met, the inbound call is hung up with an error message.
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
        hooks:
          type: array
          description: This is the hooks that will be used for incoming calls to this phone number.
          items: {}
        name:
          maxLength: 40
          type: string
          description: This is the name of the phone number. This is just for your own reference.
        assistantId:
          type: string
          description: |-
            This is the assistant that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        squadId:
          type: string
          description: |-
            This is the squad that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        server:
          description: |-
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. assistant.server
            2. phoneNumber.server
            3. org.server
          allOf:
          - $ref: '#/components/schemas/Server'
        sipUri:
          type: string
          description: |-
            This is the SIP URI of the phone number. You can SIP INVITE this. The assistant attached to this number will answer.

            This is case-insensitive.
        authentication:
          description: |-
            This enables authentication for incoming SIP INVITE requests to the `sipUri`.

            If not set, any username/password to the 401 challenge of the SIP INVITE will be accepted.
          allOf:
          - $ref: '#/components/schemas/SipAuthentication'
    UpdateTelnyxPhoneNumberDTO:
      type: object
      properties:
        fallbackDestination:
          description: |-
            This is the fallback destination an inbound call will be transferred to if:
            1. `assistantId` is not set
            2. `squadId` is not set
            3. and, `assistant-request` message to the `serverUrl` fails

            If this is not set and above conditions are met, the inbound call is hung up with an error message.
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
        hooks:
          type: array
          description: This is the hooks that will be used for incoming calls to this phone number.
          items: {}
        name:
          maxLength: 40
          type: string
          description: This is the name of the phone number. This is just for your own reference.
        assistantId:
          type: string
          description: |-
            This is the assistant that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        squadId:
          type: string
          description: |-
            This is the squad that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        server:
          description: |-
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. assistant.server
            2. phoneNumber.server
            3. org.server
          allOf:
          - $ref: '#/components/schemas/Server'
        number:
          type: string
          description: These are the digits of the phone number you own on your Telnyx.
        credentialId:
          type: string
          description: "This is the credential you added in dashboard.vapi.ai/keys. This is used to configure the number to send inbound calls to Vapi, make outbound calls and do live call updates like transfers and hangups."
    ImportVonagePhoneNumberDTO:
      required:
      - credentialId
      - vonagePhoneNumber
      type: object
      properties:
        fallbackDestination:
          description: |-
            This is the fallback destination an inbound call will be transferred to if:
            1. `assistantId` is not set
            2. `squadId` is not set
            3. and, `assistant-request` message to the `serverUrl` fails

            If this is not set and above conditions are met, the inbound call is hung up with an error message.
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
        hooks:
          type: array
          description: This is the hooks that will be used for incoming calls to this phone number.
          items: {}
        vonagePhoneNumber:
          type: string
          description: These are the digits of the phone number you own on your Vonage.
          deprecated: true
        credentialId:
          type: string
          description: "This is the credential you added in dashboard.vapi.ai/keys. This is used to configure the number to send inbound calls to Vapi, make outbound calls and do live call updates like transfers and hangups."
        name:
          maxLength: 40
          type: string
          description: This is the name of the phone number. This is just for your own reference.
        assistantId:
          type: string
          description: |-
            This is the assistant that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        squadId:
          type: string
          description: |-
            This is the squad that will be used for incoming calls to this phone number.

            If neither `assistantId` nor `squadId` is set, `assistant-request` will be sent to your Server URL. Check `ServerMessage` and `ServerMessageResponse` for the shape of the message and response that is expected.
        server:
          description: |-
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. assistant.server
            2. phoneNumber.server
            3. org.server
          allOf:
          - $ref: '#/components/schemas/Server'
    PhoneNumberPaginatedResponse:
      required:
      - metadata
      - results
      type: object
      properties:
        results:
          type: array
          description: "A list of phone numbers, which can be of any provider type."
          items:
            oneOf:
            - $ref: '#/components/schemas/ByoPhoneNumber'
            - $ref: '#/components/schemas/TwilioPhoneNumber'
            - $ref: '#/components/schemas/VonagePhoneNumber'
            - $ref: '#/components/schemas/VapiPhoneNumber'
            - $ref: '#/components/schemas/TelnyxPhoneNumber'
        metadata:
          description: Metadata about the pagination.
          allOf:
          - $ref: '#/components/schemas/PaginationMeta'
    DtmfTool:
      required:
      - createdAt
      - id
      - orgId
      - type
      - updatedAt
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "dtmf" for DTMF tool.
          enum:
          - dtmf
        id:
          type: string
          description: This is the unique identifier for the tool.
        orgId:
          type: string
          description: This is the unique identifier for the organization that this tool belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was last updated.
          format: date-time
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    EndCallTool:
      required:
      - createdAt
      - id
      - orgId
      - type
      - updatedAt
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "endCall" for End Call tool.
          enum:
          - endCall
        id:
          type: string
          description: This is the unique identifier for the tool.
        orgId:
          type: string
          description: This is the unique identifier for the organization that this tool belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was last updated.
          format: date-time
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    FunctionTool:
      required:
      - createdAt
      - id
      - orgId
      - type
      - updatedAt
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "function" for Function tool.
          enum:
          - function
        id:
          type: string
          description: This is the unique identifier for the tool.
        orgId:
          type: string
          description: This is the unique identifier for the organization that this tool belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was last updated.
          format: date-time
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    GhlTool:
      required:
      - createdAt
      - id
      - metadata
      - orgId
      - type
      - updatedAt
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "ghl" for GHL tool.
          enum:
          - ghl
        id:
          type: string
          description: This is the unique identifier for the tool.
        orgId:
          type: string
          description: This is the unique identifier for the organization that this tool belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was last updated.
          format: date-time
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
        metadata:
          $ref: '#/components/schemas/GhlToolMetadata'
    MakeTool:
      required:
      - createdAt
      - id
      - metadata
      - orgId
      - type
      - updatedAt
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "make" for Make tool.
          enum:
          - make
        id:
          type: string
          description: This is the unique identifier for the tool.
        orgId:
          type: string
          description: This is the unique identifier for the organization that this tool belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was last updated.
          format: date-time
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
        metadata:
          $ref: '#/components/schemas/MakeToolMetadata'
    TransferCallTool:
      required:
      - createdAt
      - id
      - orgId
      - type
      - updatedAt
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          enum:
          - transferCall
        destinations:
          type: array
          description: "These are the destinations that the call can be transferred to. If no destinations are provided, server.url will be used to get the transfer destination once the tool is called."
          items:
            oneOf:
            - $ref: '#/components/schemas/TransferDestinationAssistant'
            - $ref: '#/components/schemas/TransferDestinationStep'
            - $ref: '#/components/schemas/TransferDestinationNumber'
            - $ref: '#/components/schemas/TransferDestinationSip'
        id:
          type: string
          description: This is the unique identifier for the tool.
        orgId:
          type: string
          description: This is the unique identifier for the organization that this tool belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was last updated.
          format: date-time
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    OutputTool:
      required:
      - createdAt
      - id
      - orgId
      - type
      - updatedAt
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "output" for Output tool.
          enum:
          - output
        id:
          type: string
          description: This is the unique identifier for the tool.
        orgId:
          type: string
          description: This is the unique identifier for the organization that this tool belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was last updated.
          format: date-time
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    BashTool:
      required:
      - createdAt
      - id
      - name
      - orgId
      - subType
      - type
      - updatedAt
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "bash" for Bash tool.
          enum:
          - bash
        subType:
          type: string
          description: The sub type of tool.
          enum:
          - bash_20241022
        id:
          type: string
          description: This is the unique identifier for the tool.
        orgId:
          type: string
          description: This is the unique identifier for the organization that this tool belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was last updated.
          format: date-time
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
        name:
          type: string
          description: "The name of the tool, fixed to 'bash'"
          default: bash
          enum:
          - bash
    ComputerTool:
      required:
      - createdAt
      - displayHeightPx
      - displayWidthPx
      - id
      - name
      - orgId
      - subType
      - type
      - updatedAt
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "computer" for Computer tool.
          enum:
          - computer
        subType:
          type: string
          description: The sub type of tool.
          enum:
          - computer_20241022
        id:
          type: string
          description: This is the unique identifier for the tool.
        orgId:
          type: string
          description: This is the unique identifier for the organization that this tool belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was last updated.
          format: date-time
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
        name:
          type: string
          description: "The name of the tool, fixed to 'computer'"
          default: computer
          enum:
          - computer
        displayWidthPx:
          type: number
          description: The display width in pixels
        displayHeightPx:
          type: number
          description: The display height in pixels
        displayNumber:
          type: number
          description: Optional display number
    TextEditorTool:
      required:
      - createdAt
      - id
      - name
      - orgId
      - subType
      - type
      - updatedAt
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "textEditor" for Text Editor tool.
          enum:
          - textEditor
        subType:
          type: string
          description: The sub type of tool.
          enum:
          - text_editor_20241022
        id:
          type: string
          description: This is the unique identifier for the tool.
        orgId:
          type: string
          description: This is the unique identifier for the organization that this tool belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was last updated.
          format: date-time
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
        name:
          type: string
          description: "The name of the tool, fixed to 'str_replace_editor'"
          default: str_replace_editor
          enum:
          - str_replace_editor
    QueryTool:
      required:
      - createdAt
      - id
      - orgId
      - type
      - updatedAt
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "query" for Query tool.
          enum:
          - query
        knowledgeBases:
          type: array
          description: The knowledge bases to query
          items:
            $ref: '#/components/schemas/KnowledgeBase'
        id:
          type: string
          description: This is the unique identifier for the tool.
        orgId:
          type: string
          description: This is the unique identifier for the organization that this tool belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was last updated.
          format: date-time
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    GoogleCalendarCreateEventTool:
      required:
      - createdAt
      - id
      - orgId
      - type
      - updatedAt
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "google.calendar.event.create" for Google Calendar tool.
          enum:
          - google.calendar.event.create
        id:
          type: string
          description: This is the unique identifier for the tool.
        orgId:
          type: string
          description: This is the unique identifier for the organization that this tool belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was last updated.
          format: date-time
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    GoogleSheetsRowAppendTool:
      required:
      - createdAt
      - id
      - orgId
      - type
      - updatedAt
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "google.sheets.row.append" for Google Sheets tool.
          enum:
          - google.sheets.row.append
        id:
          type: string
          description: This is the unique identifier for the tool.
        orgId:
          type: string
          description: This is the unique identifier for the organization that this tool belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was last updated.
          format: date-time
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    GoogleCalendarCheckAvailabilityTool:
      required:
      - createdAt
      - id
      - orgId
      - type
      - updatedAt
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "google.calendar.availability.check" for Google Calendar availability check tool.
          enum:
          - google.calendar.availability.check
        id:
          type: string
          description: This is the unique identifier for the tool.
        orgId:
          type: string
          description: This is the unique identifier for the organization that this tool belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was last updated.
          format: date-time
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    SlackSendMessageTool:
      required:
      - createdAt
      - id
      - orgId
      - type
      - updatedAt
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "slack.message.send" for Slack send message tool.
          enum:
          - slack.message.send
        id:
          type: string
          description: This is the unique identifier for the tool.
        orgId:
          type: string
          description: This is the unique identifier for the organization that this tool belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was last updated.
          format: date-time
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    SmsSendTool:
      required:
      - createdAt
      - id
      - orgId
      - type
      - updatedAt
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "sms" for Twilio SMS sending tool.
          enum:
          - sms
        id:
          type: string
          description: This is the unique identifier for the tool.
        orgId:
          type: string
          description: This is the unique identifier for the organization that this tool belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was last updated.
          format: date-time
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    McpTool:
      required:
      - createdAt
      - id
      - orgId
      - type
      - updatedAt
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "mcp" for MCP tool.
          enum:
          - mcp
        id:
          type: string
          description: This is the unique identifier for the tool.
        orgId:
          type: string
          description: This is the unique identifier for the organization that this tool belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the tool was last updated.
          format: date-time
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    CreateOutputToolDTO:
      required:
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "output" for Output tool.
          enum:
          - output
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    CreateBashToolDTO:
      required:
      - name
      - subType
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "bash" for Bash tool.
          enum:
          - bash
        subType:
          type: string
          description: The sub type of tool.
          enum:
          - bash_20241022
        name:
          type: string
          description: "The name of the tool, fixed to 'bash'"
          default: bash
          enum:
          - bash
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    CreateComputerToolDTO:
      required:
      - displayHeightPx
      - displayWidthPx
      - name
      - subType
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "computer" for Computer tool.
          enum:
          - computer
        subType:
          type: string
          description: The sub type of tool.
          enum:
          - computer_20241022
        name:
          type: string
          description: "The name of the tool, fixed to 'computer'"
          default: computer
          enum:
          - computer
        displayWidthPx:
          type: number
          description: The display width in pixels
        displayHeightPx:
          type: number
          description: The display height in pixels
        displayNumber:
          type: number
          description: Optional display number
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    CreateTextEditorToolDTO:
      required:
      - name
      - subType
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "textEditor" for Text Editor tool.
          enum:
          - textEditor
        subType:
          type: string
          description: The sub type of tool.
          enum:
          - text_editor_20241022
        name:
          type: string
          description: "The name of the tool, fixed to 'str_replace_editor'"
          default: str_replace_editor
          enum:
          - str_replace_editor
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    CreateSmsSendToolDTO:
      required:
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "sms" for Twilio SMS sending tool.
          enum:
          - sms
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    CreateMcpToolDTO:
      required:
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "mcp" for MCP tool.
          enum:
          - mcp
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    UpdateDtmfToolDTO:
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    UpdateEndCallToolDTO:
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    UpdateFunctionToolDTO:
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    UpdateGhlToolDTO:
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
        metadata:
          $ref: '#/components/schemas/GhlToolMetadata'
    UpdateMakeToolDTO:
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
        metadata:
          $ref: '#/components/schemas/MakeToolMetadata'
    UpdateTransferCallToolDTO:
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        destinations:
          type: array
          description: "These are the destinations that the call can be transferred to. If no destinations are provided, server.url will be used to get the transfer destination once the tool is called."
          items:
            oneOf:
            - $ref: '#/components/schemas/TransferDestinationAssistant'
            - $ref: '#/components/schemas/TransferDestinationStep'
            - $ref: '#/components/schemas/TransferDestinationNumber'
            - $ref: '#/components/schemas/TransferDestinationSip'
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    UpdateOutputToolDTO:
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    UpdateBashToolDTO:
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        subType:
          type: string
          description: The sub type of tool.
          enum:
          - bash_20241022
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
        name:
          type: string
          description: "The name of the tool, fixed to 'bash'"
          default: bash
          enum:
          - bash
    UpdateComputerToolDTO:
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        subType:
          type: string
          description: The sub type of tool.
          enum:
          - computer_20241022
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
        name:
          type: string
          description: "The name of the tool, fixed to 'computer'"
          default: computer
          enum:
          - computer
        displayWidthPx:
          type: number
          description: The display width in pixels
        displayHeightPx:
          type: number
          description: The display height in pixels
        displayNumber:
          type: number
          description: Optional display number
    UpdateTextEditorToolDTO:
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        subType:
          type: string
          description: The sub type of tool.
          enum:
          - text_editor_20241022
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
        name:
          type: string
          description: "The name of the tool, fixed to 'str_replace_editor'"
          default: str_replace_editor
          enum:
          - str_replace_editor
    UpdateQueryToolDTO:
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        knowledgeBases:
          type: array
          description: The knowledge bases to query
          items:
            $ref: '#/components/schemas/KnowledgeBase'
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    UpdateGoogleCalendarCreateEventToolDTO:
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    UpdateGoogleSheetsRowAppendToolDTO:
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    UpdateGoogleCalendarCheckAvailabilityToolDTO:
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    UpdateSlackSendMessageToolDTO:
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    UpdateSmsSendToolDTO:
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    UpdateMcpToolDTO:
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    CreateFileDTO:
      required:
      - file
      type: object
      properties:
        file:
          type: string
          description: This is the File you want to upload for use with the Knowledge Base.
          format: binary
    File:
      required:
      - createdAt
      - id
      - orgId
      - updatedAt
      type: object
      properties:
        object:
          type: string
          enum:
          - file
        status:
          type: string
          enum:
          - processing
          - done
          - failed
        name:
          maxLength: 40
          type: string
          description: This is the name of the file. This is just for your own reference.
        originalName:
          type: string
        bytes:
          type: number
        purpose:
          type: string
        mimetype:
          type: string
        key:
          type: string
        path:
          type: string
        bucket:
          type: string
        url:
          type: string
        parsedTextUrl:
          type: string
        parsedTextBytes:
          type: number
        metadata:
          type: object
        id:
          type: string
          description: This is the unique identifier for the file.
        orgId:
          type: string
          description: This is the unique identifier for the org that this file belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the file was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the file was last updated.
          format: date-time
    UpdateFileDTO:
      type: object
      properties:
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of the file. This is just for your own reference.
    TrieveKnowledgeBaseSearchPlan:
      required:
      - searchType
      type: object
      properties:
        topK:
          type: number
          description: Specifies the number of top chunks to return. This corresponds to the `page_size` parameter in Trieve.
        removeStopWords:
          type: boolean
          description: "If true, stop words (specified in server/src/stop-words.txt in the git repo) will be removed. This will preserve queries that are entirely stop words."
        scoreThreshold:
          type: number
          description: "This is the score threshold to filter out chunks with a score below the threshold for cosine distance metric. For Manhattan Distance, Euclidean Distance, and Dot Product, it will filter out scores above the threshold distance. This threshold applies before weight and bias modifications. If not specified, this defaults to no threshold. A threshold of 0 will default to no threshold."
        searchType:
          type: string
          description: This is the search method used when searching for relevant chunks from the vector store.
          enum:
          - fulltext
          - semantic
          - hybrid
          - bm25
    TrieveKnowledgeBase:
      required:
      - id
      - orgId
      - provider
      type: object
      properties:
        provider:
          type: string
          description: |-
            This knowledge base is provided by Trieve.

            To learn more about Trieve, visit https://trieve.ai.
          enum:
          - trieve
        name:
          type: string
          description: This is the name of the knowledge base.
        searchPlan:
          description: |-
            This is the searching plan used when searching for relevant chunks from the vector store.

            You should configure this if you're running into these issues:
            - Too much unnecessary context is being fed as knowledge base context.
            - Not enough relevant context is being fed as knowledge base context.
          allOf:
          - $ref: '#/components/schemas/TrieveKnowledgeBaseSearchPlan'
        createPlan:
          description: This is the plan if you want us to create/import a new vector store using Trieve.
          oneOf:
          - $ref: '#/components/schemas/TrieveKnowledgeBaseImport'
        id:
          type: string
          description: This is the id of the knowledge base.
        orgId:
          type: string
          description: This is the org id of the knowledge base.
    CustomKnowledgeBase:
      required:
      - id
      - orgId
      - provider
      - server
      type: object
      properties:
        provider:
          type: string
          description: This knowledge base is bring your own knowledge base implementation.
          enum:
          - custom-knowledge-base
        server:
          description: |-
            This is where the knowledge base request will be sent.

            Request Example:

            POST https://{server.url}
            Content-Type: application/json

            {
              "messsage": {
                "type": "knowledge-base-request",
                "messages": [
                  {
                    "role": "user",
                    "content": "Why is ocean blue?"
                  }
                ],
                ...other metadata about the call...
              }
            }

            Response Expected:
            ```
            {
              "message": {
                 "role": "assistant",
                 "content": "The ocean is blue because water absorbs everything but blue.",
              }, // YOU CAN RETURN THE EXACT RESPONSE TO SPEAK
              "documents": [
                {
                  "content": "The ocean is blue primarily because water absorbs colors in the red part of the light spectrum and scatters the blue light, making it more visible to our eyes.",
                  "similarity": 1
                },
                {
                  "content": "Blue light is scattered more by the water molecules than other colors, enhancing the blue appearance of the ocean.",
                  "similarity": .5
                }
              ] // OR, YOU CAN RETURN AN ARRAY OF DOCUMENTS THAT WILL BE SENT TO THE MODEL
            }
            ```
          allOf:
          - $ref: '#/components/schemas/Server'
        id:
          type: string
          description: This is the id of the knowledge base.
        orgId:
          type: string
          description: This is the org id of the knowledge base.
    CreateTrieveKnowledgeBaseDTO:
      required:
      - provider
      type: object
      properties:
        provider:
          type: string
          description: |-
            This knowledge base is provided by Trieve.

            To learn more about Trieve, visit https://trieve.ai.
          enum:
          - trieve
        name:
          type: string
          description: This is the name of the knowledge base.
        searchPlan:
          description: |-
            This is the searching plan used when searching for relevant chunks from the vector store.

            You should configure this if you're running into these issues:
            - Too much unnecessary context is being fed as knowledge base context.
            - Not enough relevant context is being fed as knowledge base context.
          allOf:
          - $ref: '#/components/schemas/TrieveKnowledgeBaseSearchPlan'
        createPlan:
          description: This is the plan if you want us to create/import a new vector store using Trieve.
          oneOf:
          - $ref: '#/components/schemas/TrieveKnowledgeBaseImport'
    UpdateTrieveKnowledgeBaseDTO:
      type: object
      properties:
        name:
          type: string
          description: This is the name of the knowledge base.
        searchPlan:
          description: |-
            This is the searching plan used when searching for relevant chunks from the vector store.

            You should configure this if you're running into these issues:
            - Too much unnecessary context is being fed as knowledge base context.
            - Not enough relevant context is being fed as knowledge base context.
          allOf:
          - $ref: '#/components/schemas/TrieveKnowledgeBaseSearchPlan'
        createPlan:
          description: This is the plan if you want us to create/import a new vector store using Trieve.
          oneOf:
          - $ref: '#/components/schemas/TrieveKnowledgeBaseImport'
    UpdateCustomKnowledgeBaseDTO:
      type: object
      properties:
        server:
          description: |-
            This is where the knowledge base request will be sent.

            Request Example:

            POST https://{server.url}
            Content-Type: application/json

            {
              "messsage": {
                "type": "knowledge-base-request",
                "messages": [
                  {
                    "role": "user",
                    "content": "Why is ocean blue?"
                  }
                ],
                ...other metadata about the call...
              }
            }

            Response Expected:
            ```
            {
              "message": {
                 "role": "assistant",
                 "content": "The ocean is blue because water absorbs everything but blue.",
              }, // YOU CAN RETURN THE EXACT RESPONSE TO SPEAK
              "documents": [
                {
                  "content": "The ocean is blue primarily because water absorbs colors in the red part of the light spectrum and scatters the blue light, making it more visible to our eyes.",
                  "similarity": 1
                },
                {
                  "content": "Blue light is scattered more by the water molecules than other colors, enhancing the blue appearance of the ocean.",
                  "similarity": .5
                }
              ] // OR, YOU CAN RETURN AN ARRAY OF DOCUMENTS THAT WILL BE SENT TO THE MODEL
            }
            ```
          allOf:
          - $ref: '#/components/schemas/Server'
    TrieveKnowledgeBaseChunkPlan:
      type: object
      properties:
        fileIds:
          type: array
          description: "These are the file ids that will be used to create the vector store. To upload files, use the `POST /files` endpoint."
          items:
            type: string
        websites:
          type: array
          description: These are the websites that will be used to create the vector store.
          items:
            type: string
        targetSplitsPerChunk:
          type: number
          description: "This is an optional field which allows you to specify the number of splits you want per chunk. If not specified, the default 20 is used. However, you may want to use a different number."
        splitDelimiters:
          type: array
          description: "This is an optional field which allows you to specify the delimiters to use when splitting the file before chunking the text. If not specified, the default [.!?\\n] are used to split into sentences. However, you may want to use spaces or other delimiters."
          items:
            type: string
        rebalanceChunks:
          type: boolean
          description: "This is an optional field which allows you to specify whether or not to rebalance the chunks created from the file. If not specified, the default true is used. If true, Trieve will evenly distribute remainder splits across chunks such that 66 splits with a target_splits_per_chunk of 20 will result in 3 chunks with 22 splits each."
    TrieveKnowledgeBaseCreate:
      required:
      - chunkPlans
      - type
      type: object
      properties:
        type:
          type: string
          description: This is to create a new dataset on Trieve.
          enum:
          - create
        chunkPlans:
          type: array
          description: These are the chunk plans used to create the dataset.
          items:
            $ref: '#/components/schemas/TrieveKnowledgeBaseChunkPlan'
    TrieveKnowledgeBaseImport:
      required:
      - providerId
      - type
      type: object
      properties:
        type:
          type: string
          description: This is to import an existing dataset from Trieve.
          enum:
          - import
        providerId:
          type: string
          description: This is the `datasetId` of the dataset on your Trieve account.
    UpdateWorkflowDTO:
      type: object
      properties:
        nodes:
          type: array
          items:
            oneOf:
            - $ref: '#/components/schemas/Say'
            - $ref: '#/components/schemas/Gather'
            - $ref: '#/components/schemas/ApiRequest'
            - $ref: '#/components/schemas/Hangup'
            - $ref: '#/components/schemas/Transfer'
        model:
          description: These are the options for the workflow's LLM.
          oneOf:
          - $ref: '#/components/schemas/AnthropicModel'
          - $ref: '#/components/schemas/AnyscaleModel'
          - $ref: '#/components/schemas/CerebrasModel'
          - $ref: '#/components/schemas/CustomLLMModel'
          - $ref: '#/components/schemas/DeepInfraModel'
          - $ref: '#/components/schemas/DeepSeekModel'
          - $ref: '#/components/schemas/GoogleModel'
          - $ref: '#/components/schemas/GroqModel'
          - $ref: '#/components/schemas/InflectionAIModel'
          - $ref: '#/components/schemas/OpenAIModel'
          - $ref: '#/components/schemas/OpenRouterModel'
          - $ref: '#/components/schemas/PerplexityAIModel'
          - $ref: '#/components/schemas/TogetherAIModel'
          - $ref: '#/components/schemas/XaiModel'
        name:
          maxLength: 80
          type: string
        edges:
          type: array
          items:
            $ref: '#/components/schemas/Edge'
    Squad:
      required:
      - createdAt
      - id
      - members
      - orgId
      - updatedAt
      type: object
      properties:
        name:
          type: string
          description: This is the name of the squad.
        members:
          type: array
          description: |-
            This is the list of assistants that make up the squad.

            The call will start with the first assistant in the list.
          items:
            $ref: '#/components/schemas/SquadMemberDTO'
        membersOverrides:
          description: |-
            This can be used to override all the assistants' settings and provide values for their template variables.

            Both `membersOverrides` and `members[n].assistantOverrides` can be used together. First, `members[n].assistantOverrides` is applied. Then, `membersOverrides` is applied as a global override.
          allOf:
          - $ref: '#/components/schemas/AssistantOverrides'
        id:
          type: string
          description: This is the unique identifier for the squad.
        orgId:
          type: string
          description: This is the unique identifier for the org that this squad belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the squad was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the squad was last updated.
          format: date-time
    UpdateSquadDTO:
      required:
      - members
      type: object
      properties:
        name:
          type: string
          description: This is the name of the squad.
        members:
          type: array
          description: |-
            This is the list of assistants that make up the squad.

            The call will start with the first assistant in the list.
          items:
            $ref: '#/components/schemas/SquadMemberDTO'
        membersOverrides:
          description: |-
            This can be used to override all the assistants' settings and provide values for their template variables.

            Both `membersOverrides` and `members[n].assistantOverrides` can be used together. First, `members[n].assistantOverrides` is applied. Then, `membersOverrides` is applied as a global override.
          allOf:
          - $ref: '#/components/schemas/AssistantOverrides'
    TesterPlan:
      type: object
      properties:
        assistant:
          description: |-
            Pass a transient assistant to use for the test assistant.

            Make sure to write a detailed system prompt for a test assistant, and use the {{test.script}} variable to access the test script.
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        assistantId:
          type: string
          description: |-
            Pass an assistant id that can be access

            Make sure to write a detailed system prompt for the test assistant, and use the {{test.script}} variable to access the test script.
        assistantOverrides:
          description: |-
            Add any assistant overrides to the test assistant.

            One use case is if you want to pass custom variables into the test using variableValues, that you can then access in the script
            and rubric using {{varName}}.
          allOf:
          - $ref: '#/components/schemas/AssistantOverrides'
    TestSuitePhoneNumber:
      required:
      - number
      - provider
      type: object
      properties:
        provider:
          type: string
          description: This is the provider of the phone number.
          enum:
          - test-suite
        number:
          maxLength: 50
          type: string
          description: This is the phone number that is being tested.
    TargetPlan:
      type: object
      properties:
        phoneNumberId:
          type: string
          description: |-
            This is the phone number that is being tested.
            During the actual test, it'll be called and the assistant attached to it will pick up and be tested.
            To test an assistant directly, send assistantId instead.
        phoneNumber:
          description: |-
            This can be any phone number (even not on Vapi).
            During the actual test, it'll be called.
            To test a Vapi number, send phoneNumberId. To test an assistant directly, send assistantId instead.
          allOf:
          - $ref: '#/components/schemas/TestSuitePhoneNumber'
        assistantId:
          type: string
          description: |-
            This is the assistant being tested.
            During the actual test, it'll invoked directly.
            To test the assistant over phone number, send phoneNumberId instead.
        assistantOverrides:
          description: This is the assistant overrides applied to assistantId before it is tested.
          allOf:
          - $ref: '#/components/schemas/AssistantOverrides'
    TestSuite:
      required:
      - createdAt
      - id
      - orgId
      - updatedAt
      type: object
      properties:
        id:
          type: string
          description: This is the unique identifier for the test suite.
        orgId:
          type: string
          description: This is the unique identifier for the org that this test suite belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the test suite was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the test suite was last updated.
          format: date-time
        name:
          maxLength: 80
          type: string
          description: This is the name of the test suite.
        phoneNumberId:
          type: string
          description: This is the phone number ID associated with this test suite.
          deprecated: true
        testerPlan:
          description: |-
            Override the default tester plan by providing custom assistant configuration for the test agent.

            We recommend only using this if you are confident, as we have already set sensible defaults on the tester plan.
          allOf:
          - $ref: '#/components/schemas/TesterPlan'
        targetPlan:
          description: These are the configuration for the assistant / phone number that is being tested.
          allOf:
          - $ref: '#/components/schemas/TargetPlan'
    TestSuitesPaginatedResponse:
      required:
      - metadata
      - results
      type: object
      properties:
        results:
          type: array
          items:
            $ref: '#/components/schemas/TestSuite'
        metadata:
          $ref: '#/components/schemas/PaginationMeta'
    CreateTestSuiteDto:
      type: object
      properties:
        name:
          maxLength: 80
          type: string
          description: This is the name of the test suite.
        phoneNumberId:
          type: string
          description: This is the phone number ID associated with this test suite.
          deprecated: true
        testerPlan:
          description: |-
            Override the default tester plan by providing custom assistant configuration for the test agent.

            We recommend only using this if you are confident, as we have already set sensible defaults on the tester plan.
          allOf:
          - $ref: '#/components/schemas/TesterPlan'
        targetPlan:
          description: These are the configuration for the assistant / phone number that is being tested.
          allOf:
          - $ref: '#/components/schemas/TargetPlan'
    UpdateTestSuiteDto:
      type: object
      properties:
        name:
          maxLength: 80
          type: string
          description: This is the name of the test suite.
        phoneNumberId:
          type: string
          description: This is the phone number ID associated with this test suite.
          deprecated: true
        testerPlan:
          description: |-
            Override the default tester plan by providing custom assistant configuration for the test agent.

            We recommend only using this if you are confident, as we have already set sensible defaults on the tester plan.
          allOf:
          - $ref: '#/components/schemas/TesterPlan'
        targetPlan:
          description: These are the configuration for the assistant / phone number that is being tested.
          allOf:
          - $ref: '#/components/schemas/TargetPlan'
    TestSuiteTestVoice:
      required:
      - createdAt
      - id
      - orgId
      - scorers
      - script
      - testSuiteId
      - type
      - updatedAt
      type: object
      properties:
        scorers:
          type: array
          description: These are the scorers used to evaluate the test.
          items:
            oneOf:
            - $ref: '#/components/schemas/TestSuiteTestScorerAI'
        type:
          maxLength: 100
          type: string
          description: "This is the type of the test, which must be voice."
          enum:
          - voice
        id:
          type: string
          description: This is the unique identifier for the test.
        testSuiteId:
          type: string
          description: This is the unique identifier for the test suite this test belongs to.
        orgId:
          type: string
          description: This is the unique identifier for the organization this test belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the test was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the test was last updated.
          format: date-time
        name:
          maxLength: 80
          type: string
          description: This is the name of the test.
        script:
          maxLength: 10000
          type: string
          description: This is the script to be used for the voice test.
        numAttempts:
          maximum: 10
          minimum: 1
          type: number
          description: This is the number of attempts allowed for the test.
    TestSuiteTestChat:
      required:
      - createdAt
      - id
      - orgId
      - scorers
      - script
      - testSuiteId
      - type
      - updatedAt
      type: object
      properties:
        scorers:
          type: array
          description: These are the scorers used to evaluate the test.
          items:
            oneOf:
            - $ref: '#/components/schemas/TestSuiteTestScorerAI'
        type:
          maxLength: 100
          type: string
          description: "This is the type of the test, which must be chat."
          enum:
          - chat
        id:
          type: string
          description: This is the unique identifier for the test.
        testSuiteId:
          type: string
          description: This is the unique identifier for the test suite this test belongs to.
        orgId:
          type: string
          description: This is the unique identifier for the organization this test belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the test was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the test was last updated.
          format: date-time
        name:
          maxLength: 80
          type: string
          description: This is the name of the test.
        script:
          maxLength: 10000
          type: string
          description: This is the script to be used for the chat test.
        numAttempts:
          maximum: 10
          minimum: 1
          type: number
          description: This is the number of attempts allowed for the test.
    CreateTestSuiteTestVoiceDto:
      required:
      - scorers
      - script
      - type
      type: object
      properties:
        scorers:
          type: array
          description: These are the scorers used to evaluate the test.
          items:
            oneOf:
            - $ref: '#/components/schemas/TestSuiteTestScorerAI'
        type:
          maxLength: 100
          type: string
          description: "This is the type of the test, which must be voice."
          enum:
          - voice
        script:
          maxLength: 10000
          type: string
          description: This is the script to be used for the voice test.
        numAttempts:
          maximum: 10
          minimum: 1
          type: number
          description: This is the number of attempts allowed for the test.
        name:
          maxLength: 80
          type: string
          description: This is the name of the test.
    CreateTestSuiteTestChatDto:
      required:
      - scorers
      - script
      - type
      type: object
      properties:
        scorers:
          type: array
          description: These are the scorers used to evaluate the test.
          items:
            oneOf:
            - $ref: '#/components/schemas/TestSuiteTestScorerAI'
        type:
          maxLength: 100
          type: string
          description: "This is the type of the test, which must be chat."
          enum:
          - chat
        script:
          maxLength: 10000
          type: string
          description: This is the script to be used for the chat test.
        numAttempts:
          maximum: 10
          minimum: 1
          type: number
          description: This is the number of attempts allowed for the test.
        name:
          maxLength: 80
          type: string
          description: This is the name of the test.
    UpdateTestSuiteTestVoiceDto:
      type: object
      properties:
        scorers:
          type: array
          description: These are the scorers used to evaluate the test.
          items:
            oneOf:
            - $ref: '#/components/schemas/TestSuiteTestScorerAI'
        type:
          maxLength: 100
          type: string
          description: "This is the type of the test, which must be voice."
          enum:
          - voice
        name:
          maxLength: 80
          type: string
          description: This is the name of the test.
        script:
          maxLength: 10000
          type: string
          description: This is the script to be used for the voice test.
        numAttempts:
          maximum: 10
          minimum: 1
          type: number
          description: This is the number of attempts allowed for the test.
    UpdateTestSuiteTestChatDto:
      type: object
      properties:
        scorers:
          type: array
          description: These are the scorers used to evaluate the test.
          items:
            oneOf:
            - $ref: '#/components/schemas/TestSuiteTestScorerAI'
        type:
          maxLength: 100
          type: string
          description: "This is the type of the test, which must be chat."
          enum:
          - chat
        name:
          maxLength: 80
          type: string
          description: This is the name of the test.
        script:
          maxLength: 10000
          type: string
          description: This is the script to be used for the chat test.
        numAttempts:
          maximum: 10
          minimum: 1
          type: number
          description: This is the number of attempts allowed for the test.
    TestSuiteTestScorerAI:
      required:
      - rubric
      - type
      type: object
      properties:
        type:
          maxLength: 100
          type: string
          description: "This is the type of the scorer, which must be AI."
          enum:
          - ai
        rubric:
          maxLength: 1000
          type: string
          description: This is the rubric used by the AI scorer.
    TestSuiteTestsPaginatedResponse:
      required:
      - metadata
      - results
      type: object
      properties:
        results:
          type: array
          description: A list of test suite tests.
          items:
            oneOf:
            - $ref: '#/components/schemas/TestSuiteTestVoice'
            - $ref: '#/components/schemas/TestSuiteTestChat'
        metadata:
          description: Metadata about the pagination.
          allOf:
          - $ref: '#/components/schemas/PaginationMeta'
    TestSuiteRunScorerAI:
      required:
      - reasoning
      - result
      - rubric
      - type
      type: object
      properties:
        type:
          maxLength: 100
          type: string
          description: "This is the type of the scorer, which must be AI."
          enum:
          - ai
        result:
          maxLength: 100
          type: string
          description: This is the result of the test suite.
          enum:
          - pass
          - fail
        reasoning:
          maxLength: 10000
          type: string
          description: This is the reasoning provided by the AI scorer.
        rubric:
          maxLength: 1000
          type: string
          description: This is the rubric used by the AI scorer.
    TestSuiteRunTestAttemptCall:
      required:
      - artifact
      type: object
      properties:
        artifact:
          description: This is the artifact of the call.
          allOf:
          - $ref: '#/components/schemas/Artifact'
    TestSuiteRunTestAttemptMetadata:
      required:
      - sessionId
      type: object
      properties:
        sessionId:
          type: string
          description: This is the session ID for the test attempt.
    TestSuiteRunTestAttempt:
      required:
      - scorerResults
      type: object
      properties:
        scorerResults:
          type: array
          description: These are the results of the scorers used to evaluate the test attempt.
          items:
            oneOf:
            - $ref: '#/components/schemas/TestSuiteRunScorerAI'
        call:
          description: This is the call made during the test attempt.
          allOf:
          - $ref: '#/components/schemas/TestSuiteRunTestAttemptCall'
        callId:
          type: string
          description: This is the call ID for the test attempt.
        metadata:
          description: This is the metadata for the test attempt.
          allOf:
          - $ref: '#/components/schemas/TestSuiteRunTestAttemptMetadata'
    TestSuiteRunTestResult:
      required:
      - attempts
      - test
      type: object
      properties:
        test:
          description: This is the test that was run.
          oneOf:
          - $ref: '#/components/schemas/TestSuiteTestVoice'
        attempts:
          type: array
          description: These are the attempts made for this test.
          items:
            $ref: '#/components/schemas/TestSuiteRunTestAttempt'
    TestSuiteRun:
      required:
      - createdAt
      - id
      - orgId
      - status
      - testResults
      - testSuiteId
      - updatedAt
      type: object
      properties:
        status:
          type: string
          description: This is the current status of the test suite run.
          enum:
          - queued
          - in-progress
          - completed
          - failed
        id:
          type: string
          description: This is the unique identifier for the test suite run.
        orgId:
          type: string
          description: This is the unique identifier for the organization this run belongs to.
        testSuiteId:
          type: string
          description: This is the unique identifier for the test suite this run belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the test suite run was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the test suite run was last updated.
          format: date-time
        testResults:
          type: array
          description: These are the results of the tests in this test suite run.
          items:
            $ref: '#/components/schemas/TestSuiteRunTestResult'
        name:
          maxLength: 80
          type: string
          description: This is the name of the test suite run.
    TestSuiteRunsPaginatedResponse:
      required:
      - metadata
      - results
      type: object
      properties:
        results:
          type: array
          items:
            $ref: '#/components/schemas/TestSuiteRun'
        metadata:
          $ref: '#/components/schemas/PaginationMeta'
    CreateTestSuiteRunDto:
      type: object
      properties:
        name:
          maxLength: 80
          type: string
          description: This is the name of the test suite run.
    UpdateTestSuiteRunDto:
      type: object
      properties:
        name:
          maxLength: 80
          type: string
          description: This is the name of the test suite run.
    Metrics:
      required:
      - bill
      - billDailyBreakdown
      - billWithinBillingLimit
      - callActive
      - callActiveWithinConcurrencyLimit
      - callCount
      - callCountDailyBreakdown
      - callMinutes
      - callMinutesAverage
      - callMinutesAverageDailyBreakdown
      - callMinutesDailyBreakdown
      - orgId
      - rangeEnd
      - rangeStart
      type: object
      properties:
        orgId:
          type: string
        rangeStart:
          type: string
        rangeEnd:
          type: string
        bill:
          type: number
        billWithinBillingLimit:
          type: boolean
        billDailyBreakdown:
          type: object
        callActive:
          type: number
        callActiveWithinConcurrencyLimit:
          type: boolean
        callMinutes:
          type: number
        callMinutesDailyBreakdown:
          type: object
        callMinutesAverage:
          type: number
        callMinutesAverageDailyBreakdown:
          type: object
        callCount:
          type: number
        callCountDailyBreakdown:
          type: object
    TimeRange:
      type: object
      properties:
        step:
          type: string
          description: |-
            This is the time step for aggregations.

            If not provided, defaults to returning for the entire time range.
          enum:
          - second
          - minute
          - hour
          - day
          - week
          - month
          - quarter
          - year
          - decade
          - century
          - millennium
        start:
          type: string
          description: |-
            This is the start date for the time range.

            If not provided, defaults to the 7 days ago.
          format: date-time
        end:
          type: string
          description: |-
            This is the end date for the time range.

            If not provided, defaults to now.
          format: date-time
        timezone:
          type: string
          description: |-
            This is the timezone you want to set for the query.

            If not provided, defaults to UTC.
    AnalyticsOperation:
      required:
      - column
      - operation
      type: object
      properties:
        operation:
          type: string
          description: This is the aggregation operation you want to perform.
          enum:
          - sum
          - avg
          - count
          - min
          - max
          - history
        column:
          type: string
          description: This is the columns you want to perform the aggregation operation on.
          enum:
          - id
          - cost
          - costBreakdown.llm
          - costBreakdown.stt
          - costBreakdown.tts
          - costBreakdown.vapi
          - costBreakdown.ttsCharacters
          - costBreakdown.llmPromptTokens
          - costBreakdown.llmCompletionTokens
          - duration
          - concurrency
          - minutesUsed
        alias:
          maxLength: 40
          type: string
          description: "This is the alias for column name returned. Defaults to `${operation}${column}`."
    AnalyticsQuery:
      required:
      - name
      - operations
      - table
      type: object
      properties:
        table:
          type: string
          description: This is the table you want to query.
          enum:
          - call
          - subscription
        groupBy:
          type: array
          description: This is the list of columns you want to group by.
          items:
            type: string
            enum:
            - type
            - assistantId
            - endedReason
            - analysis.successEvaluation
            - status
          enum:
          - type
          - assistantId
          - endedReason
          - analysis.successEvaluation
          - status
        name:
          maxLength: 40
          type: string
          description: This is the name of the query. This will be used to identify the query in the response.
        timeRange:
          description: This is the time range for the query.
          allOf:
          - $ref: '#/components/schemas/TimeRange'
        operations:
          type: array
          description: This is the list of operations you want to perform.
          items:
            $ref: '#/components/schemas/AnalyticsOperation'
    AnalyticsQueryDTO:
      required:
      - queries
      type: object
      properties:
        queries:
          type: array
          description: This is the list of metric queries you want to perform.
          items:
            $ref: '#/components/schemas/AnalyticsQuery'
    AnalyticsQueryResult:
      required:
      - name
      - result
      - timeRange
      type: object
      properties:
        name:
          type: string
          description: This is the unique key for the query.
        timeRange:
          description: This is the time range for the query.
          allOf:
          - $ref: '#/components/schemas/TimeRange'
        result:
          type: array
          description: |-
            This is the result of the query, a list of unique groups with result of their aggregations.

            Example:
            "result": [
              { "date": "2023-01-01", "assistantId": "123", "endedReason": "customer-ended-call", "sumDuration": 120, "avgCost": 10.5 },
              { "date": "2023-01-02", "assistantId": "123", "endedReason": "customer-did-not-give-microphone-permission", "sumDuration": 0, "avgCost": 0 },
              // Additional results
            ]
          items:
            type: object
    CallLogPrivileged:
      required:
      - callId
      - level
      - log
      - orgId
      - time
      type: object
      properties:
        callId:
          type: string
          description: This is the unique identifier for the call.
        orgId:
          type: string
          description: This is the unique identifier for the org that this call log belongs to.
        log:
          type: string
          description: This is the log message associated with the call.
        level:
          type: string
          description: This is the level of the log message.
          enum:
          - INFO
          - LOG
          - WARN
          - ERROR
          - CHECKPOINT
        time:
          type: string
          description: This is the ISO 8601 date-time string of when the log was created.
          format: date-time
    CallLogsPaginatedResponse:
      required:
      - metadata
      - results
      type: object
      properties:
        results:
          type: array
          items:
            $ref: '#/components/schemas/CallLogPrivileged'
        metadata:
          $ref: '#/components/schemas/PaginationMeta'
    Error:
      required:
      - message
      type: object
      properties:
        message:
          type: string
    Log:
      required:
      - orgId
      - time
      - type
      type: object
      properties:
        time:
          type: string
          description: This is the timestamp at which the log was written.
        orgId:
          type: string
          description: This is the unique identifier for the org that this log belongs to.
        type:
          type: string
          description: This is the type of the log.
          enum:
          - API
          - Webhook
          - Call
          - Provider
        webhookType:
          type: string
          description: "This is the type of the webhook, given the log is from a webhook."
        resource:
          type: string
          description: "This is the specific resource, relevant only to API logs."
          enum:
          - org
          - assistant
          - analytics
          - credential
          - phone-number
          - block
          - voice-library
          - provider
          - tool
          - token
          - template
          - squad
          - call
          - file
          - metric
          - log
        requestDurationSeconds:
          minimum: 0
          type: number
          description: '''This is how long the request took.'
        requestStartedAt:
          type: string
          description: This is the timestamp at which the request began.
        requestFinishedAt:
          type: string
          description: This is the timestamp at which the request finished.
        requestBody:
          type: object
          description: This is the body of the request.
        requestHttpMethod:
          type: string
          description: This is the request method.
          enum:
          - POST
          - GET
          - PUT
          - PATCH
          - DELETE
        requestUrl:
          type: string
          description: This is the request URL.
        requestPath:
          type: string
          description: This is the request path.
        requestQuery:
          type: string
          description: This is the request query.
        responseHttpCode:
          type: number
          description: This the HTTP status code of the response.
        requestIpAddress:
          type: string
          description: This is the request IP address.
        requestOrigin:
          type: string
          description: This is the origin of the request
        responseBody:
          type: object
          description: This is the body of the response.
        requestHeaders:
          type: object
          description: These are the headers of the request.
        error:
          description: "This is the error, if one occurred."
          allOf:
          - $ref: '#/components/schemas/Error'
        assistantId:
          type: string
          description: This is the ID of the assistant.
        phoneNumberId:
          type: string
          description: This is the ID of the phone number.
        customerId:
          type: string
          description: This is the ID of the customer.
        squadId:
          type: string
          description: This is the ID of the squad.
        callId:
          type: string
          description: This is the ID of the call.
    LogsPaginatedResponse:
      required:
      - metadata
      - results
      type: object
      properties:
        results:
          type: array
          items:
            $ref: '#/components/schemas/Log'
        metadata:
          $ref: '#/components/schemas/PaginationMeta'
    CreateOrgDTO:
      type: object
      properties:
        hipaaEnabled:
          type: boolean
          description: |-
            When this is enabled, no logs, recordings, or transcriptions will be stored. At the end of the call, you will still receive an end-of-call-report message to store on your server. Defaults to false.
            When HIPAA is enabled, only OpenAI/Custom LLM or Azure Providers will be available for LLM and Voice respectively.
            This is due to the compliance requirements of HIPAA. Other providers may not meet these requirements.
          example: false
        subscriptionId:
          type: string
          description: This is the ID of the subscription the org belongs to.
        name:
          maxLength: 40
          type: string
          description: This is the name of the org. This is just for your own reference.
        channel:
          type: string
          description: This is the channel of the org. There is the cluster the API traffic for the org will be directed.
          enum:
          - default
          - weekly
        billingLimit:
          maximum: 1000
          minimum: 0
          type: number
          description: "This is the monthly billing limit for the org. To go beyond $1000/mo, please contact us at support@vapi.ai."
        server:
          description: |-
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. assistant.server
            2. phoneNumber.server
            3. org.server
          allOf:
          - $ref: '#/components/schemas/Server'
        concurrencyLimit:
          maximum: 10
          minimum: 1
          type: number
          description: "This is the concurrency limit for the org. This is the maximum number of calls that can be active at any given time. To go beyond 10, please contact us at support@vapi.ai."
        compliancePlan:
          description: |-
            Stores the information about the compliance plan enforced at the organization level. Currently pciEnabled is supported through this field.
            When this is enabled, any logs, recordings, or transcriptions will be shipped to the customer endpoints if provided else lost.
            At the end of the call, you will receive an end-of-call-report message to store on your server, if webhook is provided.
            Defaults to false.
            When PCI is enabled, only PCI-compliant Providers will be available for LLM, Voice and transcribers.
            This is due to the compliance requirements of PCI. Other providers may not meet these requirements.
          allOf:
          - $ref: '#/components/schemas/CompliancePlan'
    AutoReloadPlan:
      required:
      - credits
      - threshold
      type: object
      properties:
        credits:
          type: number
          description: This the amount of credits to reload.
        threshold:
          type: number
          description: This is the limit at which the reload is triggered.
    InvoicePlan:
      type: object
      properties:
        companyName:
          type: string
          description: This is the name of the company.
        companyAddress:
          type: string
          description: This is the address of the company.
        companyTaxId:
          type: string
          description: This is the tax ID of the company.
        companyEmail:
          type: string
          description: "This is the preferred invoicing email of the company. If not specified, defaults to the subscription's email."
    Subscription:
      required:
      - concurrencyCounter
      - concurrencyLimitIncluded
      - concurrencyLimitPurchased
      - createdAt
      - credits
      - id
      - status
      - type
      - updatedAt
      type: object
      properties:
        id:
          type: string
          description: This is the unique identifier for the subscription.
        createdAt:
          type: string
          description: This is the timestamp when the subscription was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the timestamp when the subscription was last updated.
          format: date-time
        type:
          type: string
          description: This is the type / tier of the subscription.
          enum:
          - trial
          - pay-as-you-go
          - enterprise
        status:
          type: string
          description: |-
            This is the status of the subscription. Past due subscriptions are subscriptions
            with past due payments.
          enum:
          - active
          - frozen
        credits:
          type: string
          description: |-
            This is the number of credits the subscription currently has.

            Note: This is a string to avoid floating point precision issues.
        concurrencyCounter:
          minimum: 1
          type: number
          description: This is the total number of active calls (concurrency) across all orgs under this subscription.
        concurrencyLimitIncluded:
          minimum: 1
          type: number
          description: This is the default concurrency limit for the subscription.
        phoneNumbersCounter:
          minimum: 1
          type: number
          description: This is the number of free phone numbers the subscription has
        phoneNumbersIncluded:
          minimum: 1
          type: number
          description: This is the maximum number of free phone numbers the subscription can have
        concurrencyLimitPurchased:
          minimum: 1
          type: number
          description: This is the purchased add-on concurrency limit for the subscription.
        monthlyChargeScheduleId:
          type: number
          description: This is the ID of the monthly job that charges for subscription add ons and phone numbers.
        monthlyCreditCheckScheduleId:
          type: number
          description: |-
            This is the ID of the monthly job that checks whether the credit balance of the subscription
            is sufficient for the monthly charge.
        stripeCustomerId:
          type: string
          description: This is the Stripe customer ID.
        stripePaymentMethodId:
          type: string
          description: This is the Stripe payment ID.
        slackSupportEnabled:
          type: boolean
          description: "If this flag is true, then the user has purchased slack support."
        slackChannelId:
          type: string
          description: "If this subscription has a slack support subscription, the slack channel's ID will be stored here."
        hipaaEnabled:
          type: boolean
          description: |-
            This is the HIPAA enabled flag for the subscription. It determines whether orgs under this
            subscription have the option to enable HIPAA compliance.
        hipaaCommonPaperAgreementId:
          type: string
          description: This is the ID for the Common Paper agreement outlining the HIPAA contract.
        stripePaymentMethodFingerprint:
          type: string
          description: |-
            This is the Stripe fingerprint of the payment method (card). It allows us
            to detect users who try to abuse our system through multiple sign-ups.
        stripeCustomerEmail:
          type: string
          description: This is the customer's email on Stripe.
        referredByEmail:
          type: string
          description: This is the email of the referrer for the subscription.
        autoReloadPlan:
          description: This is the auto reload plan configured for the subscription.
          allOf:
          - $ref: '#/components/schemas/AutoReloadPlan'
        minutesIncluded:
          minimum: 0
          type: number
          description: The number of minutes included in the subscription.
        minutesUsed:
          minimum: 0
          type: number
          description: The number of minutes used in the subscription.
        minutesUsedNextResetAt:
          type: string
          description: This is the timestamp at which the number of monthly free minutes is scheduled to reset at.
          format: date-time
        minutesOverageCost:
          type: number
          description: The per minute charge on minutes that exceed the included minutes. Enterprise only.
        providersIncluded:
          type: array
          description: The list of providers included in the subscription. Enterprise only.
          items:
            type: string
        outboundCallsDailyLimit:
          minimum: 1
          type: number
          description: The maximum number of outbound calls this subscription may make in a day. Resets every night.
        outboundCallsCounter:
          minimum: 1
          type: number
          description: The current number of outbound calls the subscription has made in the current day.
        outboundCallsCounterNextResetAt:
          type: string
          description: This is the timestamp at which the outbound calls counter is scheduled to reset at.
          format: date-time
        couponIds:
          type: array
          description: This is the IDs of the coupons applicable to this subscription.
          items:
            type: string
        couponUsageLeft:
          type: string
          description: This is the number of credits left obtained from a coupon.
        invoicePlan:
          description: This is the invoice plan for the subscription.
          allOf:
          - $ref: '#/components/schemas/InvoicePlan'
        pciEnabled:
          type: boolean
          description: |-
            This is the PCI enabled flag for the subscription. It determines whether orgs under this
            subscription have the option to enable PCI compliance.
        pciCommonPaperAgreementId:
          type: string
          description: This is the ID for the Common Paper agreement outlining the PCI contract.
    OrgPlan:
      type: object
      properties:
        includedProviders:
          type: array
          items:
            type: object
        includedMinutes:
          type: number
        costPerOverageMinute:
          type: number
    Org:
      required:
      - createdAt
      - id
      - updatedAt
      type: object
      properties:
        hipaaEnabled:
          type: boolean
          description: |-
            When this is enabled, no logs, recordings, or transcriptions will be stored. At the end of the call, you will still receive an end-of-call-report message to store on your server. Defaults to false.
            When HIPAA is enabled, only OpenAI/Custom LLM or Azure Providers will be available for LLM and Voice respectively.
            This is due to the compliance requirements of HIPAA. Other providers may not meet these requirements.
          example: false
        subscription:
          $ref: '#/components/schemas/Subscription'
        subscriptionId:
          type: string
          description: This is the ID of the subscription the org belongs to.
        id:
          type: string
          description: This is the unique identifier for the org.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the org was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the org was last updated.
          format: date-time
        stripeCustomerId:
          type: string
          description: This is the Stripe customer for the org.
        stripeSubscriptionId:
          type: string
          description: This is the subscription for the org.
        stripeSubscriptionItemId:
          type: string
          description: This is the subscription's subscription item.
        stripeSubscriptionCurrentPeriodStart:
          type: string
          description: This is the subscription's current period start.
          format: date-time
        stripeSubscriptionStatus:
          type: string
          description: This is the subscription's status.
        plan:
          description: This is the plan for the org.
          allOf:
          - $ref: '#/components/schemas/OrgPlan'
        name:
          maxLength: 40
          type: string
          description: This is the name of the org. This is just for your own reference.
        channel:
          type: string
          description: This is the channel of the org. There is the cluster the API traffic for the org will be directed.
          enum:
          - default
          - weekly
        billingLimit:
          maximum: 1000
          minimum: 0
          type: number
          description: "This is the monthly billing limit for the org. To go beyond $1000/mo, please contact us at support@vapi.ai."
        server:
          description: |-
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. assistant.server
            2. phoneNumber.server
            3. org.server
          allOf:
          - $ref: '#/components/schemas/Server'
        concurrencyLimit:
          maximum: 10
          minimum: 1
          type: number
          description: "This is the concurrency limit for the org. This is the maximum number of calls that can be active at any given time. To go beyond 10, please contact us at support@vapi.ai."
        compliancePlan:
          description: |-
            Stores the information about the compliance plan enforced at the organization level. Currently pciEnabled is supported through this field.
            When this is enabled, any logs, recordings, or transcriptions will be shipped to the customer endpoints if provided else lost.
            At the end of the call, you will receive an end-of-call-report message to store on your server, if webhook is provided.
            Defaults to false.
            When PCI is enabled, only PCI-compliant Providers will be available for LLM, Voice and transcribers.
            This is due to the compliance requirements of PCI. Other providers may not meet these requirements.
          allOf:
          - $ref: '#/components/schemas/CompliancePlan'
    UpdateOrgDTO:
      type: object
      properties:
        hipaaEnabled:
          type: boolean
          description: |-
            When this is enabled, no logs, recordings, or transcriptions will be stored. At the end of the call, you will still receive an end-of-call-report message to store on your server. Defaults to false.
            When HIPAA is enabled, only OpenAI/Custom LLM or Azure Providers will be available for LLM and Voice respectively.
            This is due to the compliance requirements of HIPAA. Other providers may not meet these requirements.
          example: false
        subscriptionId:
          type: string
          description: This is the ID of the subscription the org belongs to.
        name:
          maxLength: 40
          type: string
          description: This is the name of the org. This is just for your own reference.
        channel:
          type: string
          description: This is the channel of the org. There is the cluster the API traffic for the org will be directed.
          enum:
          - default
          - weekly
        billingLimit:
          maximum: 1000
          minimum: 0
          type: number
          description: "This is the monthly billing limit for the org. To go beyond $1000/mo, please contact us at support@vapi.ai."
        server:
          description: |-
            This is where Vapi will send webhooks. You can find all webhooks available along with their shape in ServerMessage schema.

            The order of precedence is:

            1. assistant.server
            2. phoneNumber.server
            3. org.server
          allOf:
          - $ref: '#/components/schemas/Server'
        concurrencyLimit:
          maximum: 10
          minimum: 1
          type: number
          description: "This is the concurrency limit for the org. This is the maximum number of calls that can be active at any given time. To go beyond 10, please contact us at support@vapi.ai."
        compliancePlan:
          description: |-
            Stores the information about the compliance plan enforced at the organization level. Currently pciEnabled is supported through this field.
            When this is enabled, any logs, recordings, or transcriptions will be shipped to the customer endpoints if provided else lost.
            At the end of the call, you will receive an end-of-call-report message to store on your server, if webhook is provided.
            Defaults to false.
            When PCI is enabled, only PCI-compliant Providers will be available for LLM, Voice and transcribers.
            This is due to the compliance requirements of PCI. Other providers may not meet these requirements.
          allOf:
          - $ref: '#/components/schemas/CompliancePlan'
    User:
      required:
      - createdAt
      - email
      - id
      - updatedAt
      type: object
      properties:
        id:
          type: string
          description: This is the unique identifier for the profile or user.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the profile was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the profile was last updated.
          format: date-time
        email:
          type: string
          description: This is the email of the user that is associated with the profile.
        fullName:
          type: string
          description: This is the full name of the user that is associated with the profile.
    InviteUserDTO:
      required:
      - emails
      - role
      type: object
      properties:
        emails:
          maxItems: 100
          type: array
          items:
            type: string
        role:
          type: string
          enum:
          - admin
          - editor
          - viewer
        redirectTo:
          type: string
    UpdateUserRoleDTO:
      required:
      - role
      - userId
      type: object
      properties:
        userId:
          type: string
        role:
          type: string
          enum:
          - admin
          - editor
          - viewer
    TokenRestrictions:
      type: object
      properties:
        enabled:
          type: boolean
          description: "This determines whether the token is enabled or disabled. Default is true, it's enabled."
        allowedOrigins:
          type: array
          description: |-
            This determines the allowed origins for this token. Validates the `Origin` header. Default is any origin.

            Only relevant for `public` tokens.
          items:
            type: string
        allowedAssistantIds:
          type: array
          description: |-
            This determines which assistantIds can be used when creating a call. Default is any assistantId.

            Only relevant for `public` tokens.
          items:
            type: string
        allowTransientAssistant:
          type: boolean
          description: |-
            This determines whether transient assistants can be used when creating a call. Default is true.

            If `allowedAssistantIds` is provided, this is automatically false.

            Only relevant for `public` tokens.
    CreateTokenDTO:
      type: object
      properties:
        tag:
          type: string
          description: This is the tag for the token. It represents its scope.
          enum:
          - private
          - public
        name:
          maxLength: 40
          type: string
          description: This is the name of the token. This is just for your own reference.
        restrictions:
          description: This are the restrictions for the token.
          allOf:
          - $ref: '#/components/schemas/TokenRestrictions'
    Token:
      required:
      - createdAt
      - id
      - orgId
      - updatedAt
      - value
      type: object
      properties:
        tag:
          type: string
          description: This is the tag for the token. It represents its scope.
          enum:
          - private
          - public
        id:
          type: string
          description: This is the unique identifier for the token.
        orgId:
          type: string
          description: This is unique identifier for the org that this token belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the token was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the token was last updated.
          format: date-time
        value:
          type: string
          description: This is the token key.
        name:
          maxLength: 40
          type: string
          description: This is the name of the token. This is just for your own reference.
        restrictions:
          description: This are the restrictions for the token.
          allOf:
          - $ref: '#/components/schemas/TokenRestrictions'
    UpdateTokenDTO:
      type: object
      properties:
        tag:
          type: string
          description: This is the tag for the token. It represents its scope.
          enum:
          - private
          - public
        name:
          maxLength: 40
          type: string
          description: This is the name of the token. This is just for your own reference.
        restrictions:
          description: This are the restrictions for the token.
          allOf:
          - $ref: '#/components/schemas/TokenRestrictions'
    AnthropicCredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - anthropic
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    AnyscaleCredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - anyscale
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    AssemblyAICredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - assembly-ai
        apiKey:
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    AzureCredential:
      required:
      - createdAt
      - id
      - orgId
      - provider
      - service
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - azure
        service:
          type: string
          description: This is the service being used in Azure.
          default: speech
          enum:
          - speech
          - blob_storage
        region:
          type: string
          description: This is the region of the Azure resource.
          enum:
          - australia
          - canadaeast
          - canadacentral
          - eastus2
          - eastus
          - france
          - india
          - japaneast
          - japanwest
          - uaenorth
          - northcentralus
          - norway
          - southcentralus
          - swedencentral
          - switzerland
          - uk
          - westus
          - westus3
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
        bucketPlan:
          description: This is the bucket plan that can be provided to store call artifacts in Azure Blob Storage.
          allOf:
          - $ref: '#/components/schemas/AzureBlobStorageBucketPlan'
    AzureOpenAICredential:
      required:
      - createdAt
      - id
      - models
      - openAIEndpoint
      - openAIKey
      - orgId
      - provider
      - region
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - azure-openai
        region:
          type: string
          enum:
          - australia
          - canadaeast
          - canadacentral
          - eastus2
          - eastus
          - france
          - india
          - japaneast
          - japanwest
          - uaenorth
          - northcentralus
          - norway
          - southcentralus
          - swedencentral
          - switzerland
          - uk
          - westus
          - westus3
        models:
          type: array
          example:
          - gpt-4-0125-preview
          - gpt-4-0613
          items:
            type: string
            enum:
            - gpt-4o-2024-11-20
            - gpt-4o-2024-08-06
            - gpt-4o-mini-2024-07-18
            - gpt-4o-2024-05-13
            - gpt-4-turbo-2024-04-09
            - gpt-4-0125-preview
            - gpt-4-1106-preview
            - gpt-4-0613
            - gpt-35-turbo-0125
            - gpt-35-turbo-1106
          enum:
          - gpt-4o-2024-11-20
          - gpt-4o-2024-08-06
          - gpt-4o-mini-2024-07-18
          - gpt-4o-2024-05-13
          - gpt-4-turbo-2024-04-09
          - gpt-4-0125-preview
          - gpt-4-1106-preview
          - gpt-4-0613
          - gpt-35-turbo-0125
          - gpt-35-turbo-1106
        openAIKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        ocpApimSubscriptionKey:
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
        openAIEndpoint:
          maxLength: 10000
          type: string
    ByoSipTrunkCredential:
      required:
      - createdAt
      - gateways
      - id
      - orgId
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          description: This can be used to bring your own SIP trunks or to connect to a Carrier.
          enum:
          - byo-sip-trunk
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
        gateways:
          type: array
          description: This is the list of SIP trunk's gateways.
          items:
            $ref: '#/components/schemas/SipTrunkGateway'
        outboundAuthenticationPlan:
          description: This can be used to configure the outbound authentication if required by the SIP trunk.
          allOf:
          - $ref: '#/components/schemas/SipTrunkOutboundAuthenticationPlan'
        outboundLeadingPlusEnabled:
          type: boolean
          description: |-
            This ensures the outbound origination attempts have a leading plus. Defaults to false to match conventional telecom behavior.

            Usage:
            - Vonage/Twilio requires leading plus for all outbound calls. Set this to true.

            @default false
        techPrefix:
          maxLength: 10000
          type: string
          description: This can be used to configure the tech prefix on outbound calls. This is an advanced property.
        sipDiversionHeader:
          maxLength: 10000
          type: string
          description: This can be used to enable the SIP diversion header for authenticating the calling number if the SIP trunk supports it. This is an advanced property.
        sbcConfiguration:
          description: "This is an advanced configuration for enterprise deployments. This uses the onprem SBC to trunk into the SIP trunk's `gateways`, rather than the managed SBC provided by Vapi."
          allOf:
          - $ref: '#/components/schemas/SbcConfiguration'
    CartesiaCredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - cartesia
        apiKey:
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CerebrasCredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - cerebras
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CloudflareCredential:
      required:
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          description: Credential provider. Only allowed value is cloudflare
          enum:
          - cloudflare
        accountId:
          type: string
          description: Cloudflare Account Id.
        apiKey:
          type: string
          description: Cloudflare API Key / Token.
        accountEmail:
          type: string
          description: Cloudflare Account Email.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
        bucketPlan:
          description: This is the bucket plan that can be provided to store call artifacts in R2
          allOf:
          - $ref: '#/components/schemas/CloudflareR2BucketPlan'
    Oauth2AuthenticationSession:
      type: object
      properties:
        accessToken:
          type: string
          description: This is the OAuth2 access token.
        expiresAt:
          type: string
          description: This is the OAuth2 access token expiration.
          format: date-time
    CustomLLMCredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - custom-llm
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        authenticationPlan:
          description: "This is the authentication plan. Currently supports OAuth2 RFC 6749. To use Bearer authentication, use apiKey"
          allOf:
          - $ref: '#/components/schemas/OAuth2AuthenticationPlan'
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        authenticationSession:
          description: This is the authentication session for the credential. Available for credentials that have an authentication plan.
          allOf:
          - $ref: '#/components/schemas/Oauth2AuthenticationSession'
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    DeepgramCredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - deepgram
        apiKey:
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
        apiUrl:
          type: string
          description: This can be used to point to an onprem Deepgram instance. Defaults to api.deepgram.com.
    DeepInfraCredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - deepinfra
        apiKey:
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    DeepSeekCredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - deep-seek
        apiKey:
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    ElevenLabsCredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - 11labs
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    GcpCredential:
      required:
      - createdAt
      - gcpKey
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - gcp
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
        gcpKey:
          description: |-
            This is the GCP key. This is the JSON that can be generated in the Google Cloud Console at https://console.cloud.google.com/iam-admin/serviceaccounts/details/<service-account-id>/keys.

            The schema is identical to the JSON that GCP outputs.
          allOf:
          - $ref: '#/components/schemas/GcpKey'
        bucketPlan:
          description: This is the bucket plan that can be provided to store call artifacts in GCP.
          allOf:
          - $ref: '#/components/schemas/BucketPlan'
    GladiaCredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - gladia
        apiKey:
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    GoHighLevelCredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - gohighlevel
        apiKey:
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    GoogleCredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          description: "This is the key for Gemini in Google AI Studio. Get it from here: https://aistudio.google.com/app/apikey"
          enum:
          - google
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    GroqCredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - groq
        apiKey:
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    HumeCredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - hume
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    InflectionAICredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          description: "This is the api key for Pi in InflectionAI's console. Get it from here: https://developers.inflection.ai/keys, billing will need to be setup"
          enum:
          - inflection-ai
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    LangfuseCredential:
      required:
      - apiKey
      - apiUrl
      - createdAt
      - id
      - orgId
      - provider
      - publicKey
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - langfuse
        publicKey:
          type: string
          description: "The public key for Langfuse project. Eg: pk-lf-..."
        apiKey:
          type: string
          description: "The secret key for Langfuse project. Eg: sk-lf-... .This is not returned in the API."
        apiUrl:
          type: string
          description: "The host URL for Langfuse project. Eg: https://cloud.langfuse.com"
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    LmntCredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - lmnt
        apiKey:
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    MakeCredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - region
      - teamId
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - make
        teamId:
          type: string
          description: Team ID
        region:
          type: string
          description: "Region of your application. For example: eu1, eu2, us1, us2"
        apiKey:
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    MistralCredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - mistral
        apiKey:
          maxLength: 100
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    NeuphonicCredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - neuphonic
        apiKey:
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    OpenAICredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - openai
        apiKey:
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    OpenRouterCredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - openrouter
        apiKey:
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    PerplexityAICredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - perplexity-ai
        apiKey:
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    PlayHTCredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      - userId
      type: object
      properties:
        provider:
          type: string
          enum:
          - playht
        apiKey:
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
        userId:
          type: string
    RimeAICredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - rime-ai
        apiKey:
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    RunpodCredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - runpod
        apiKey:
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    S3Credential:
      required:
      - awsAccessKeyId
      - awsSecretAccessKey
      - createdAt
      - id
      - orgId
      - provider
      - region
      - s3BucketName
      - s3PathPrefix
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          description: Credential provider. Only allowed value is s3
          enum:
          - s3
        awsAccessKeyId:
          type: string
          description: AWS access key ID.
        awsSecretAccessKey:
          type: string
          description: AWS access key secret. This is not returned in the API.
        region:
          type: string
          description: AWS region in which the S3 bucket is located.
        s3BucketName:
          type: string
          description: AWS S3 bucket name.
        s3PathPrefix:
          type: string
          description: The path prefix for the uploaded recording. Ex. "recordings/"
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    SmallestAICredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - smallest-ai
        apiKey:
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    SpeechmaticsCredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - speechmatics
        apiKey:
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    SupabaseCredential:
      required:
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          description: This is for supabase storage.
          enum:
          - supabase
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
        bucketPlan:
          $ref: '#/components/schemas/SupabaseBucketPlan'
    TavusCredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - tavus
        apiKey:
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    TogetherAICredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - together-ai
        apiKey:
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    TrieveCredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - trieve
        apiKey:
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    TwilioCredential:
      required:
      - accountSid
      - authToken
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - twilio
        authToken:
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
        accountSid:
          type: string
    VonageCredential:
      required:
      - apiKey
      - apiSecret
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      - vonageApplicationId
      - vonageApplicationPrivateKey
      type: object
      properties:
        vonageApplicationPrivateKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        provider:
          type: string
          enum:
          - vonage
        apiSecret:
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        vonageApplicationId:
          maxLength: 10000
          type: string
          description: |-
            This is the Vonage Application ID for the credential.

            Only relevant for Vonage credentials.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
        apiKey:
          type: string
    WebhookCredential:
      required:
      - authenticationPlan
      - authenticationSession
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - webhook
        authenticationPlan:
          description: This is the authentication plan. Currently supports OAuth2 RFC 6749.
          allOf:
          - $ref: '#/components/schemas/OAuth2AuthenticationPlan'
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        authenticationSession:
          description: This is the authentication session for the credential. Available for credentials that have an authentication plan.
          allOf:
          - $ref: '#/components/schemas/Oauth2AuthenticationSession'
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    XAiCredential:
      required:
      - apiKey
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          description: "This is the api key for Grok in XAi's console. Get it from here: https://console.x.ai"
          enum:
          - xai
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    GoogleCalendarOAuth2ClientCredential:
      required:
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - google.calendar.oauth2-client
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    GoogleCalendarOAuth2AuthorizationCredential:
      required:
      - authorizationId
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - google.calendar.oauth2-authorization
        authorizationId:
          type: string
          description: The authorization ID for the OAuth2 authorization
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    GoogleSheetsOAuth2AuthorizationCredential:
      required:
      - authorizationId
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - google.sheets.oauth2-authorization
        authorizationId:
          type: string
          description: The authorization ID for the OAuth2 authorization
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    SlackOAuth2AuthorizationCredential:
      required:
      - authorizationId
      - createdAt
      - id
      - orgId
      - provider
      - updatedAt
      type: object
      properties:
        provider:
          type: string
          enum:
          - slack.oauth2-authorization
        authorizationId:
          type: string
          description: The authorization ID for the OAuth2 authorization
        id:
          type: string
          description: This is the unique identifier for the credential.
        orgId:
          type: string
          description: This is the unique identifier for the org that this credential belongs to.
        createdAt:
          type: string
          description: This is the ISO 8601 date-time string of when the credential was created.
          format: date-time
        updatedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the assistant was last updated.
          format: date-time
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateCerebrasCredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - cerebras
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateGoogleCredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          description: "This is the key for Gemini in Google AI Studio. Get it from here: https://aistudio.google.com/app/apikey"
          enum:
          - google
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateHumeCredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - hume
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateInflectionAICredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          description: "This is the api key for Pi in InflectionAI's console. Get it from here: https://developers.inflection.ai/keys, billing will need to be setup"
          enum:
          - inflection-ai
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateMistralCredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - mistral
        apiKey:
          maxLength: 100
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateNeuphonicCredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - neuphonic
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateSpeechmaticsCredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - speechmatics
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CreateTrieveCredentialDTO:
      required:
      - apiKey
      - provider
      type: object
      properties:
        provider:
          type: string
          enum:
          - trieve
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateAnthropicCredentialDTO:
      type: object
      properties:
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateAnyscaleCredentialDTO:
      type: object
      properties:
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateAssemblyAICredentialDTO:
      type: object
      properties:
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateAzureCredentialDTO:
      type: object
      properties:
        service:
          type: string
          description: This is the service being used in Azure.
          default: speech
          enum:
          - speech
          - blob_storage
        region:
          type: string
          description: This is the region of the Azure resource.
          enum:
          - australia
          - canadaeast
          - canadacentral
          - eastus2
          - eastus
          - france
          - india
          - japaneast
          - japanwest
          - uaenorth
          - northcentralus
          - norway
          - southcentralus
          - swedencentral
          - switzerland
          - uk
          - westus
          - westus3
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
        bucketPlan:
          description: This is the bucket plan that can be provided to store call artifacts in Azure Blob Storage.
          allOf:
          - $ref: '#/components/schemas/AzureBlobStorageBucketPlan'
    UpdateAzureOpenAICredentialDTO:
      type: object
      properties:
        region:
          type: string
          enum:
          - australia
          - canadaeast
          - canadacentral
          - eastus2
          - eastus
          - france
          - india
          - japaneast
          - japanwest
          - uaenorth
          - northcentralus
          - norway
          - southcentralus
          - swedencentral
          - switzerland
          - uk
          - westus
          - westus3
        models:
          type: array
          example:
          - gpt-4-0125-preview
          - gpt-4-0613
          items:
            type: string
            enum:
            - gpt-4o-2024-11-20
            - gpt-4o-2024-08-06
            - gpt-4o-mini-2024-07-18
            - gpt-4o-2024-05-13
            - gpt-4-turbo-2024-04-09
            - gpt-4-0125-preview
            - gpt-4-1106-preview
            - gpt-4-0613
            - gpt-35-turbo-0125
            - gpt-35-turbo-1106
          enum:
          - gpt-4o-2024-11-20
          - gpt-4o-2024-08-06
          - gpt-4o-mini-2024-07-18
          - gpt-4o-2024-05-13
          - gpt-4-turbo-2024-04-09
          - gpt-4-0125-preview
          - gpt-4-1106-preview
          - gpt-4-0613
          - gpt-35-turbo-0125
          - gpt-35-turbo-1106
        openAIKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        ocpApimSubscriptionKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
        openAIEndpoint:
          maxLength: 10000
          type: string
    UpdateByoSipTrunkCredentialDTO:
      type: object
      properties:
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
        gateways:
          type: array
          description: This is the list of SIP trunk's gateways.
          items:
            $ref: '#/components/schemas/SipTrunkGateway'
        outboundAuthenticationPlan:
          description: This can be used to configure the outbound authentication if required by the SIP trunk.
          allOf:
          - $ref: '#/components/schemas/SipTrunkOutboundAuthenticationPlan'
        outboundLeadingPlusEnabled:
          type: boolean
          description: |-
            This ensures the outbound origination attempts have a leading plus. Defaults to false to match conventional telecom behavior.

            Usage:
            - Vonage/Twilio requires leading plus for all outbound calls. Set this to true.

            @default false
        techPrefix:
          maxLength: 10000
          type: string
          description: This can be used to configure the tech prefix on outbound calls. This is an advanced property.
        sipDiversionHeader:
          maxLength: 10000
          type: string
          description: This can be used to enable the SIP diversion header for authenticating the calling number if the SIP trunk supports it. This is an advanced property.
        sbcConfiguration:
          description: "This is an advanced configuration for enterprise deployments. This uses the onprem SBC to trunk into the SIP trunk's `gateways`, rather than the managed SBC provided by Vapi."
          allOf:
          - $ref: '#/components/schemas/SbcConfiguration'
    UpdateCartesiaCredentialDTO:
      type: object
      properties:
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateCerebrasCredentialDTO:
      type: object
      properties:
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateCloudflareCredentialDTO:
      type: object
      properties:
        accountId:
          type: string
          description: Cloudflare Account Id.
        apiKey:
          type: string
          description: Cloudflare API Key / Token.
        accountEmail:
          type: string
          description: Cloudflare Account Email.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
        bucketPlan:
          description: This is the bucket plan that can be provided to store call artifacts in R2
          allOf:
          - $ref: '#/components/schemas/CloudflareR2BucketPlan'
    UpdateCustomLLMCredentialDTO:
      type: object
      properties:
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        authenticationPlan:
          description: "This is the authentication plan. Currently supports OAuth2 RFC 6749. To use Bearer authentication, use apiKey"
          allOf:
          - $ref: '#/components/schemas/OAuth2AuthenticationPlan'
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateDeepgramCredentialDTO:
      type: object
      properties:
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
        apiUrl:
          type: string
          description: This can be used to point to an onprem Deepgram instance. Defaults to api.deepgram.com.
    UpdateDeepInfraCredentialDTO:
      type: object
      properties:
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateDeepSeekCredentialDTO:
      type: object
      properties:
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateElevenLabsCredentialDTO:
      type: object
      properties:
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateGcpCredentialDTO:
      type: object
      properties:
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
        gcpKey:
          description: |-
            This is the GCP key. This is the JSON that can be generated in the Google Cloud Console at https://console.cloud.google.com/iam-admin/serviceaccounts/details/<service-account-id>/keys.

            The schema is identical to the JSON that GCP outputs.
          allOf:
          - $ref: '#/components/schemas/GcpKey'
        bucketPlan:
          description: This is the bucket plan that can be provided to store call artifacts in GCP.
          allOf:
          - $ref: '#/components/schemas/BucketPlan'
    UpdateGladiaCredentialDTO:
      type: object
      properties:
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateGoHighLevelCredentialDTO:
      type: object
      properties:
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateGoogleCredentialDTO:
      type: object
      properties:
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateGroqCredentialDTO:
      type: object
      properties:
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateHumeCredentialDTO:
      type: object
      properties:
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateInflectionAICredentialDTO:
      type: object
      properties:
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateLangfuseCredentialDTO:
      type: object
      properties:
        publicKey:
          type: string
          description: "The public key for Langfuse project. Eg: pk-lf-..."
        apiKey:
          type: string
          description: "The secret key for Langfuse project. Eg: sk-lf-... .This is not returned in the API."
        apiUrl:
          type: string
          description: "The host URL for Langfuse project. Eg: https://cloud.langfuse.com"
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateLmntCredentialDTO:
      type: object
      properties:
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateMakeCredentialDTO:
      type: object
      properties:
        teamId:
          type: string
          description: Team ID
        region:
          type: string
          description: "Region of your application. For example: eu1, eu2, us1, us2"
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateMistralCredentialDTO:
      type: object
      properties:
        apiKey:
          maxLength: 100
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateNeuphonicCredentialDTO:
      type: object
      properties:
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateOpenAICredentialDTO:
      type: object
      properties:
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateOpenRouterCredentialDTO:
      type: object
      properties:
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdatePerplexityAICredentialDTO:
      type: object
      properties:
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdatePlayHTCredentialDTO:
      type: object
      properties:
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
        userId:
          type: string
    UpdateRimeAICredentialDTO:
      type: object
      properties:
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateRunpodCredentialDTO:
      type: object
      properties:
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateS3CredentialDTO:
      type: object
      properties:
        awsAccessKeyId:
          type: string
          description: AWS access key ID.
        awsSecretAccessKey:
          type: string
          description: AWS access key secret. This is not returned in the API.
        region:
          type: string
          description: AWS region in which the S3 bucket is located.
        s3BucketName:
          type: string
          description: AWS S3 bucket name.
        s3PathPrefix:
          type: string
          description: The path prefix for the uploaded recording. Ex. "recordings/"
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateSmallestAICredentialDTO:
      type: object
      properties:
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateSpeechmaticsCredentialDTO:
      type: object
      properties:
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateSupabaseCredentialDTO:
      type: object
      properties:
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
        bucketPlan:
          $ref: '#/components/schemas/SupabaseBucketPlan'
    UpdateTavusCredentialDTO:
      type: object
      properties:
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateTogetherAICredentialDTO:
      type: object
      properties:
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateTrieveCredentialDTO:
      type: object
      properties:
        apiKey:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateTwilioCredentialDTO:
      type: object
      properties:
        authToken:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
        accountSid:
          type: string
    UpdateVonageCredentialDTO:
      type: object
      properties:
        apiSecret:
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
        apiKey:
          type: string
    UpdateWebhookCredentialDTO:
      type: object
      properties:
        authenticationPlan:
          description: This is the authentication plan. Currently supports OAuth2 RFC 6749.
          allOf:
          - $ref: '#/components/schemas/OAuth2AuthenticationPlan'
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateXAiCredentialDTO:
      type: object
      properties:
        apiKey:
          maxLength: 10000
          type: string
          description: This is not returned in the API.
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateGoogleCalendarOAuth2ClientCredentialDTO:
      type: object
      properties:
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateGoogleCalendarOAuth2AuthorizationCredentialDTO:
      type: object
      properties:
        authorizationId:
          type: string
          description: The authorization ID for the OAuth2 authorization
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateGoogleSheetsOAuth2AuthorizationCredentialDTO:
      type: object
      properties:
        authorizationId:
          type: string
          description: The authorization ID for the OAuth2 authorization
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    UpdateSlackOAuth2AuthorizationCredentialDTO:
      type: object
      properties:
        authorizationId:
          type: string
          description: The authorization ID for the OAuth2 authorization
        name:
          maxLength: 40
          minLength: 1
          type: string
          description: This is the name of credential. This is just for your reference.
    CredentialSessionResponse:
      required:
      - sessionToken
      type: object
      properties:
        sessionToken:
          type: string
    CredentialEndUser:
      required:
      - endUserId
      - organizationId
      type: object
      properties:
        endUserId:
          type: string
        organizationId:
          type: string
    CredentialSessionError:
      required:
      - description
      - type
      type: object
      properties:
        type:
          type: string
        description:
          type: string
    CredentialWebhookDTO:
      required:
      - authMode
      - connectionId
      - endUser
      - environment
      - from
      - operation
      - provider
      - providerConfigKey
      - success
      - type
      type: object
      properties:
        type:
          type: string
          enum:
          - auth
          - sync
          - forward
        operation:
          type: string
          enum:
          - creation
          - override
          - refresh
        from:
          type: string
        connectionId:
          type: string
        authMode:
          type: string
          enum:
          - OAUTH2
          - API_KEY
          - BASIC
        providerConfigKey:
          type: string
        provider:
          type: string
        environment:
          type: string
        success:
          type: boolean
        endUser:
          $ref: '#/components/schemas/CredentialEndUser'
        error:
          $ref: '#/components/schemas/CredentialSessionError'
    CredentialActionRequest:
      required:
      - action_name
      - input
      type: object
      properties:
        action_name:
          type: string
        input:
          type: object
    CredentialSessionDTO:
      required:
      - provider
      type: object
      properties:
        provider:
          type: string
          description: The type of credential to generate a session for. Only Nango user-facing providers are supported.
          enum:
          - google.calendar.oauth2-client
          - google.calendar.oauth2-authorization
          - google.sheets.oauth2-authorization
          - slack.oauth2-authorization
    ToolTemplateSetup:
      required:
      - title
      type: object
      properties:
        title:
          type: string
        description:
          type: string
        videoUrl:
          type: string
        docsUrl:
          type: string
    MakeToolProviderDetails:
      required:
      - type
      type: object
      properties:
        templateUrl:
          type: string
          description: This is the Template URL or the Snapshot URL corresponding to the Template.
        setupInstructions:
          type: array
          items:
            $ref: '#/components/schemas/ToolTemplateSetup'
        type:
          type: string
          description: The type of tool. "make" for Make tool.
          enum:
          - make
        scenarioId:
          type: number
        scenarioName:
          type: string
        triggerHookId:
          type: number
        triggerHookName:
          type: string
    GhlToolProviderDetails:
      required:
      - type
      type: object
      properties:
        templateUrl:
          type: string
          description: This is the Template URL or the Snapshot URL corresponding to the Template.
        setupInstructions:
          type: array
          items:
            $ref: '#/components/schemas/ToolTemplateSetup'
        type:
          type: string
          description: The type of tool. "ghl" for GHL tool.
          enum:
          - ghl
        workflowId:
          type: string
        workflowName:
          type: string
        webhookHookId:
          type: string
        webhookHookName:
          type: string
        locationId:
          type: string
    FunctionToolProviderDetails:
      required:
      - type
      type: object
      properties:
        templateUrl:
          type: string
          description: This is the Template URL or the Snapshot URL corresponding to the Template.
        setupInstructions:
          type: array
          items:
            $ref: '#/components/schemas/ToolTemplateSetup'
        type:
          type: string
          description: The type of tool. "function" for Function tool.
          enum:
          - function
    GoogleCalendarCreateEventToolProviderDetails:
      required:
      - type
      type: object
      properties:
        templateUrl:
          type: string
          description: This is the Template URL or the Snapshot URL corresponding to the Template.
        setupInstructions:
          type: array
          items:
            $ref: '#/components/schemas/ToolTemplateSetup'
        type:
          type: string
          description: The type of tool. "google.calendar.event.create" for Google Calendar tool.
          enum:
          - google.calendar.event.create
    GoogleSheetsRowAppendToolProviderDetails:
      required:
      - type
      type: object
      properties:
        templateUrl:
          type: string
          description: This is the Template URL or the Snapshot URL corresponding to the Template.
        setupInstructions:
          type: array
          items:
            $ref: '#/components/schemas/ToolTemplateSetup'
        type:
          type: string
          description: The type of tool. "google.sheets.row.append" for Google Sheets tool.
          enum:
          - google.sheets.row.append
    ToolTemplateMetadata:
      type: object
      properties:
        collectionType:
          type: string
        collectionId:
          type: string
        collectionName:
          type: string
    CreateToolTemplateDTO:
      required:
      - type
      type: object
      properties:
        details:
          oneOf:
          - $ref: '#/components/schemas/CreateDtmfToolDTO'
          - $ref: '#/components/schemas/CreateEndCallToolDTO'
          - $ref: '#/components/schemas/CreateVoicemailToolDTO'
          - $ref: '#/components/schemas/CreateFunctionToolDTO'
          - $ref: '#/components/schemas/CreateGhlToolDTO'
          - $ref: '#/components/schemas/CreateMakeToolDTO'
          - $ref: '#/components/schemas/CreateTransferCallToolDTO'
          - $ref: '#/components/schemas/CreateGoogleCalendarCreateEventToolDTO'
          - $ref: '#/components/schemas/CreateGoogleSheetsRowAppendToolDTO'
        providerDetails:
          oneOf:
          - $ref: '#/components/schemas/MakeToolProviderDetails'
          - $ref: '#/components/schemas/GhlToolProviderDetails'
          - $ref: '#/components/schemas/FunctionToolProviderDetails'
          - $ref: '#/components/schemas/GoogleCalendarCreateEventToolProviderDetails'
          - $ref: '#/components/schemas/GoogleSheetsRowAppendToolProviderDetails'
        metadata:
          $ref: '#/components/schemas/ToolTemplateMetadata'
        visibility:
          type: string
          default: private
          enum:
          - public
          - private
        type:
          type: string
          default: tool
          enum:
          - tool
        name:
          maxLength: 40
          type: string
          description: The name of the template. This is just for your own reference.
        provider:
          type: string
          enum:
          - make
          - gohighlevel
          - function
    Template:
      required:
      - createdAt
      - id
      - orgId
      - type
      - updatedAt
      type: object
      properties:
        details:
          oneOf:
          - $ref: '#/components/schemas/CreateDtmfToolDTO'
          - $ref: '#/components/schemas/CreateEndCallToolDTO'
          - $ref: '#/components/schemas/CreateVoicemailToolDTO'
          - $ref: '#/components/schemas/CreateFunctionToolDTO'
          - $ref: '#/components/schemas/CreateGhlToolDTO'
          - $ref: '#/components/schemas/CreateMakeToolDTO'
          - $ref: '#/components/schemas/CreateTransferCallToolDTO'
          - $ref: '#/components/schemas/CreateGoogleCalendarCreateEventToolDTO'
          - $ref: '#/components/schemas/CreateGoogleSheetsRowAppendToolDTO'
        providerDetails:
          oneOf:
          - $ref: '#/components/schemas/MakeToolProviderDetails'
          - $ref: '#/components/schemas/GhlToolProviderDetails'
          - $ref: '#/components/schemas/FunctionToolProviderDetails'
          - $ref: '#/components/schemas/GoogleCalendarCreateEventToolProviderDetails'
          - $ref: '#/components/schemas/GoogleSheetsRowAppendToolProviderDetails'
        metadata:
          $ref: '#/components/schemas/ToolTemplateMetadata'
        visibility:
          type: string
          default: private
          enum:
          - public
          - private
        type:
          type: string
          default: tool
          enum:
          - tool
        name:
          maxLength: 40
          type: string
          description: The name of the template. This is just for your own reference.
        provider:
          type: string
          enum:
          - make
          - gohighlevel
          - function
        id:
          type: string
          description: The unique identifier for the template.
        orgId:
          type: string
          description: The unique identifier for the organization that this template belongs to.
        createdAt:
          type: string
          description: The ISO 8601 date-time string of when the template was created.
          format: date-time
        updatedAt:
          type: string
          description: The ISO 8601 date-time string of when the template was last updated.
          format: date-time
    UpdateToolTemplateDTO:
      required:
      - type
      type: object
      properties:
        details:
          oneOf:
          - $ref: '#/components/schemas/CreateDtmfToolDTO'
          - $ref: '#/components/schemas/CreateEndCallToolDTO'
          - $ref: '#/components/schemas/CreateVoicemailToolDTO'
          - $ref: '#/components/schemas/CreateFunctionToolDTO'
          - $ref: '#/components/schemas/CreateGhlToolDTO'
          - $ref: '#/components/schemas/CreateMakeToolDTO'
          - $ref: '#/components/schemas/CreateTransferCallToolDTO'
          - $ref: '#/components/schemas/CreateGoogleCalendarCreateEventToolDTO'
          - $ref: '#/components/schemas/CreateGoogleSheetsRowAppendToolDTO'
        providerDetails:
          oneOf:
          - $ref: '#/components/schemas/MakeToolProviderDetails'
          - $ref: '#/components/schemas/GhlToolProviderDetails'
          - $ref: '#/components/schemas/FunctionToolProviderDetails'
          - $ref: '#/components/schemas/GoogleCalendarCreateEventToolProviderDetails'
          - $ref: '#/components/schemas/GoogleSheetsRowAppendToolProviderDetails'
        metadata:
          $ref: '#/components/schemas/ToolTemplateMetadata'
        visibility:
          type: string
          default: private
          enum:
          - public
          - private
        type:
          type: string
          default: tool
          enum:
          - tool
        name:
          maxLength: 40
          type: string
          description: The name of the template. This is just for your own reference.
        provider:
          type: string
          enum:
          - make
          - gohighlevel
          - function
    VoiceLibrary:
      required:
      - createdAt
      - id
      - isDeleted
      - isPublic
      - orgId
      - updatedAt
      type: object
      properties:
        provider:
          type: object
          description: This is the voice provider that will be used.
          enum:
          - vapi
          - 11labs
          - azure
          - cartesia
          - custom-voice
          - deepgram
          - hume
          - lmnt
          - neuphonic
          - openai
          - playht
          - rime-ai
          - smallest-ai
          - tavus
          - sesame
        providerId:
          type: string
          description: The ID of the voice provided by the provider.
        slug:
          type: string
          description: The unique slug of the voice.
        name:
          type: string
          description: The name of the voice.
        language:
          type: string
          description: The language of the voice.
        languageCode:
          type: string
          description: The language code of the voice.
        model:
          type: string
          description: The model of the voice.
        supportedModels:
          type: string
          description: The supported models of the voice.
        gender:
          type: string
          description: The gender of the voice.
          enum:
          - male
          - female
        accent:
          type: string
          description: The accent of the voice.
        previewUrl:
          type: string
          description: The preview URL of the voice.
        description:
          type: string
          description: The description of the voice.
        credentialId:
          type: string
          description: The credential ID of the voice.
        id:
          type: string
          description: The unique identifier for the voice library.
        orgId:
          type: string
          description: The unique identifier for the organization that this voice library belongs to.
        isPublic:
          type: boolean
          description: The Public voice is shared accross all the organizations.
        isDeleted:
          type: boolean
          description: The deletion status of the voice.
        createdAt:
          type: string
          description: The ISO 8601 date-time string of when the voice library was created.
          format: date-time
        updatedAt:
          type: string
          description: The ISO 8601 date-time string of when the voice library was last updated.
          format: date-time
    SyncVoiceLibraryDTO:
      type: object
      properties:
        providers:
          type: array
          description: List of providers you want to sync.
          items:
            type: string
            enum:
            - vapi
            - 11labs
            - azure
            - cartesia
            - custom-voice
            - deepgram
            - hume
            - lmnt
            - neuphonic
            - openai
            - playht
            - rime-ai
            - smallest-ai
            - tavus
            - sesame
          enum:
          - vapi
          - 11labs
          - azure
          - cartesia
          - custom-voice
          - deepgram
          - hume
          - lmnt
          - neuphonic
          - openai
          - playht
          - rime-ai
          - smallest-ai
          - tavus
          - sesame
    VoiceLibraryVoiceResponse:
      required:
      - name
      - voiceId
      type: object
      properties:
        voiceId:
          type: string
        name:
          type: string
        publicOwnerId:
          type: string
        description:
          type: string
        gender:
          type: string
        age:
          type: object
        accent:
          type: string
    AddVoiceToProviderDTO:
      required:
      - name
      - ownerId
      - voiceId
      type: object
      properties:
        ownerId:
          type: string
          description: This is the owner_id of your shared voice which you want to add to your provider Account from Provider Voice Library
        voiceId:
          type: string
          description: This is the voice_id of the shared voice which you want to add to your provider Account from Provider Voice Library
        name:
          type: string
          description: This is the new name of the voice which you want to have once you have added voice to your provider Account from Provider Voice Library
    CloneVoiceDTO:
      required:
      - files
      - name
      type: object
      properties:
        name:
          type: string
          description: This is the name of the cloned voice in the provider account.
        description:
          type: string
          description: This is the description of your cloned voice.
        labels:
          type: string
          description: Serialized labels dictionary for the voice.
        files:
          type: array
          description: These are the files you want to use to clone your voice. Only Audio files are supported.
          items:
            type: string
            format: binary
    ClientMessageWorkflowNodeStarted:
      required:
      - node
      - type
      type: object
      properties:
        type:
          type: string
          description: This is the type of the message. "workflow.node.started" is sent when the active node changes.
          enum:
          - workflow.node.started
        node:
          type: object
          description: This is the active node.
    ClientMessageConversationUpdate:
      required:
      - messagesOpenAIFormatted
      - type
      type: object
      properties:
        type:
          type: string
          description: This is the type of the message. "conversation-update" is sent when an update is committed to the conversation history.
          enum:
          - conversation-update
        messages:
          type: array
          description: This is the most up-to-date conversation history at the time the message is sent.
          items:
            oneOf:
            - $ref: '#/components/schemas/UserMessage'
            - $ref: '#/components/schemas/SystemMessage'
            - $ref: '#/components/schemas/BotMessage'
            - $ref: '#/components/schemas/ToolCallMessage'
            - $ref: '#/components/schemas/ToolCallResultMessage'
        messagesOpenAIFormatted:
          type: array
          description: "This is the most up-to-date conversation history at the time the message is sent, formatted for OpenAI."
          items:
            $ref: '#/components/schemas/OpenAIMessage'
    ClientMessageHang:
      required:
      - type
      type: object
      properties:
        type:
          type: string
          description: |-
            This is the type of the message. "hang" is sent when the assistant is hanging due to a delay. The delay can be caused by many factors, such as:
            - the model is too slow to respond
            - the voice is too slow to respond
            - the tool call is still waiting for a response from your server
            - etc.
          enum:
          - hang
    ClientMessageMetadata:
      required:
      - metadata
      - type
      type: object
      properties:
        type:
          type: string
          description: This is the type of the message. "metadata" is sent to forward metadata to the client.
          enum:
          - metadata
        metadata:
          type: string
          description: This is the metadata content
    ClientMessageModelOutput:
      required:
      - output
      - type
      type: object
      properties:
        type:
          type: string
          description: This is the type of the message. "model-output" is sent as the model outputs tokens.
          enum:
          - model-output
        output:
          type: object
          description: This is the output of the model. It can be a token or tool call.
    ClientMessageSpeechUpdate:
      required:
      - role
      - status
      - type
      type: object
      properties:
        type:
          type: string
          description: This is the type of the message. "speech-update" is sent whenever assistant or user start or stop speaking.
          enum:
          - speech-update
        status:
          type: string
          description: This is the status of the speech update.
          enum:
          - started
          - stopped
        role:
          type: string
          description: This is the role which the speech update is for.
          enum:
          - assistant
          - user
        turn:
          type: number
          description: This is the turn number of the speech update (0-indexed).
    ClientMessageTranscript:
      required:
      - role
      - transcript
      - transcriptType
      - type
      type: object
      properties:
        type:
          type: string
          description: This is the type of the message. "transcript" is sent as transcriber outputs partial or final transcript.
          enum:
          - transcript
          - "transcript[transcriptType=\"final\"]"
        role:
          type: string
          description: This is the role for which the transcript is for.
          enum:
          - assistant
          - user
        transcriptType:
          type: string
          description: This is the type of the transcript.
          enum:
          - partial
          - final
        transcript:
          type: string
          description: This is the transcript content.
    ToolCallFunction:
      required:
      - arguments
      - name
      type: object
      properties:
        name:
          type: string
          description: This is the name of the function the model called.
        arguments:
          type: object
          description: These are the arguments that the function was called with.
    ToolCall:
      required:
      - function
      - id
      - type
      type: object
      properties:
        type:
          type: string
          description: This is the type of tool the model called.
          enum:
          - function
        function:
          description: This is the function the model called.
          allOf:
          - $ref: '#/components/schemas/ToolCallFunction'
        id:
          type: string
          description: This is the unique identifier for the tool call.
    ClientMessageToolCalls:
      required:
      - toolCallList
      - toolWithToolCallList
      type: object
      properties:
        type:
          type: string
          description: This is the type of the message. "tool-calls" is sent to call a tool.
          enum:
          - tool-calls
        toolWithToolCallList:
          type: array
          description: This is the list of tools calls that the model is requesting along with the original tool configuration.
          items:
            oneOf:
            - $ref: '#/components/schemas/FunctionToolWithToolCall'
            - $ref: '#/components/schemas/GhlToolWithToolCall'
            - $ref: '#/components/schemas/MakeToolWithToolCall'
            - $ref: '#/components/schemas/BashToolWithToolCall'
            - $ref: '#/components/schemas/ComputerToolWithToolCall'
            - $ref: '#/components/schemas/TextEditorToolWithToolCall'
            - $ref: '#/components/schemas/GoogleCalendarCreateEventToolWithToolCall'
        toolCallList:
          type: array
          description: This is the list of tool calls that the model is requesting.
          items:
            $ref: '#/components/schemas/ToolCall'
    ClientMessageToolCallsResult:
      required:
      - toolCallResult
      - type
      type: object
      properties:
        type:
          type: string
          description: This is the type of the message. "tool-calls-result" is sent to forward the result of a tool call to the client.
          enum:
          - tool-calls-result
        toolCallResult:
          type: object
          description: This is the result of the tool call.
    ClientMessageTransferUpdate:
      required:
      - type
      type: object
      properties:
        type:
          type: string
          description: This is the type of the message. "transfer-update" is sent whenever a transfer happens.
          enum:
          - transfer-update
        destination:
          description: This is the destination of the transfer.
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationAssistant'
          - $ref: '#/components/schemas/TransferDestinationStep'
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
        toAssistant:
          description: This is the assistant that the call is being transferred to. This is only sent if `destination.type` is "assistant".
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        fromAssistant:
          description: This is the assistant that the call is being transferred from. This is only sent if `destination.type` is "assistant".
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        toStepRecord:
          type: object
          description: This is the step that the conversation moved to.
        fromStepRecord:
          type: object
          description: This is the step that the conversation moved from. =
    ClientMessageUserInterrupted:
      required:
      - type
      type: object
      properties:
        type:
          type: string
          description: This is the type of the message. "user-interrupted" is sent when the user interrupts the assistant.
          enum:
          - user-interrupted
    ClientMessageLanguageChangeDetected:
      required:
      - language
      - type
      type: object
      properties:
        type:
          type: string
          description: This is the type of the message. "language-change-detected" is sent when the transcriber is automatically switched based on the detected language.
          enum:
          - language-change-detected
        language:
          type: string
          description: This is the language the transcriber is switched to.
    ClientMessageVoiceInput:
      required:
      - input
      - type
      type: object
      properties:
        type:
          type: string
          description: This is the type of the message. "voice-input" is sent when a generation is requested from voice provider.
          enum:
          - voice-input
        input:
          type: string
          description: This is the voice input content
    ClientMessage:
      required:
      - message
      type: object
      properties:
        message:
          description: These are all the messages that can be sent to the client-side SDKs during the call. Configure the messages you'd like to receive in `assistant.clientMessages`.
          oneOf:
          - $ref: '#/components/schemas/ClientMessageWorkflowNodeStarted'
          - $ref: '#/components/schemas/ClientMessageConversationUpdate'
          - $ref: '#/components/schemas/ClientMessageHang'
          - $ref: '#/components/schemas/ClientMessageMetadata'
          - $ref: '#/components/schemas/ClientMessageModelOutput'
          - $ref: '#/components/schemas/ClientMessageSpeechUpdate'
          - $ref: '#/components/schemas/ClientMessageTranscript'
          - $ref: '#/components/schemas/ClientMessageToolCalls'
          - $ref: '#/components/schemas/ClientMessageToolCallsResult'
          - $ref: '#/components/schemas/ClientMessageTransferUpdate'
          - $ref: '#/components/schemas/ClientMessageUserInterrupted'
          - $ref: '#/components/schemas/ClientMessageLanguageChangeDetected'
          - $ref: '#/components/schemas/ClientMessageVoiceInput'
    ServerMessageAssistantRequest:
      required:
      - type
      type: object
      properties:
        phoneNumber:
          description: |-
            This is the phone number associated with the call.

            This matches one of the following:
            - `call.phoneNumber`,
            - `call.phoneNumberId`.
          oneOf:
          - $ref: '#/components/schemas/CreateByoPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateTwilioPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVonagePhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVapiPhoneNumberDTO'
        type:
          type: string
          description: This is the type of the message. "assistant-request" is sent to fetch assistant configuration for an incoming call.
          enum:
          - assistant-request
        timestamp:
          type: number
          description: This is the timestamp of when the message was sent in milliseconds since Unix Epoch.
        artifact:
          description: |-
            This is a live version of the `call.artifact`.

            This matches what is stored on `call.artifact` after the call.
          allOf:
          - $ref: '#/components/schemas/Artifact'
        assistant:
          description: |-
            This is the assistant that is currently active. This is provided for convenience.

            This matches one of the following:
            - `call.assistant`,
            - `call.assistantId`,
            - `call.squad[n].assistant`,
            - `call.squad[n].assistantId`,
            - `call.squadId->[n].assistant`,
            - `call.squadId->[n].assistantId`.
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        customer:
          description: |-
            This is the customer associated with the call.

            This matches one of the following:
            - `call.customer`,
            - `call.customerId`.
          allOf:
          - $ref: '#/components/schemas/CreateCustomerDTO'
        call:
          description: |-
            This is the call object.

            This matches what was returned in POST /call.

            Note: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.
          allOf:
          - $ref: '#/components/schemas/Call'
    ServerMessageConversationUpdate:
      required:
      - messagesOpenAIFormatted
      - type
      type: object
      properties:
        phoneNumber:
          description: |-
            This is the phone number associated with the call.

            This matches one of the following:
            - `call.phoneNumber`,
            - `call.phoneNumberId`.
          oneOf:
          - $ref: '#/components/schemas/CreateByoPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateTwilioPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVonagePhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVapiPhoneNumberDTO'
        type:
          type: string
          description: This is the type of the message. "conversation-update" is sent when an update is committed to the conversation history.
          enum:
          - conversation-update
        messages:
          type: array
          description: This is the most up-to-date conversation history at the time the message is sent.
          items:
            oneOf:
            - $ref: '#/components/schemas/UserMessage'
            - $ref: '#/components/schemas/SystemMessage'
            - $ref: '#/components/schemas/BotMessage'
            - $ref: '#/components/schemas/ToolCallMessage'
            - $ref: '#/components/schemas/ToolCallResultMessage'
        messagesOpenAIFormatted:
          type: array
          description: "This is the most up-to-date conversation history at the time the message is sent, formatted for OpenAI."
          items:
            $ref: '#/components/schemas/OpenAIMessage'
        timestamp:
          type: number
          description: This is the timestamp of when the message was sent in milliseconds since Unix Epoch.
        artifact:
          description: |-
            This is a live version of the `call.artifact`.

            This matches what is stored on `call.artifact` after the call.
          allOf:
          - $ref: '#/components/schemas/Artifact'
        assistant:
          description: |-
            This is the assistant that is currently active. This is provided for convenience.

            This matches one of the following:
            - `call.assistant`,
            - `call.assistantId`,
            - `call.squad[n].assistant`,
            - `call.squad[n].assistantId`,
            - `call.squadId->[n].assistant`,
            - `call.squadId->[n].assistantId`.
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        customer:
          description: |-
            This is the customer associated with the call.

            This matches one of the following:
            - `call.customer`,
            - `call.customerId`.
          allOf:
          - $ref: '#/components/schemas/CreateCustomerDTO'
        call:
          description: |-
            This is the call object.

            This matches what was returned in POST /call.

            Note: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.
          allOf:
          - $ref: '#/components/schemas/Call'
    ServerMessageEndOfCallReport:
      required:
      - analysis
      - artifact
      - endedReason
      - type
      type: object
      properties:
        phoneNumber:
          description: |-
            This is the phone number associated with the call.

            This matches one of the following:
            - `call.phoneNumber`,
            - `call.phoneNumberId`.
          oneOf:
          - $ref: '#/components/schemas/CreateByoPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateTwilioPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVonagePhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVapiPhoneNumberDTO'
        type:
          type: string
          description: This is the type of the message. "end-of-call-report" is sent when the call ends and post-processing is complete.
          enum:
          - end-of-call-report
        endedReason:
          type: string
          description: This is the reason the call ended. This can also be found at `call.endedReason` on GET /call/:id.
          enum:
          - call-start-error-neither-assistant-nor-server-set
          - assistant-request-failed
          - assistant-request-returned-error
          - assistant-request-returned-unspeakable-error
          - assistant-request-returned-invalid-assistant
          - assistant-request-returned-no-assistant
          - assistant-request-returned-forwarding-phone-number
          - call.start.error-get-org
          - call.start.error-get-subscription
          - call.start.error-get-assistant
          - call.start.error-get-phone-number
          - call.start.error-get-customer
          - call.start.error-get-resources-validation
          - call.start.error-vapi-number-international
          - call.start.error-vapi-number-outbound-daily-limit
          - call.start.error-get-transport
          - assistant-not-valid
          - database-error
          - assistant-not-found
          - pipeline-error-openai-voice-failed
          - pipeline-error-cartesia-voice-failed
          - pipeline-error-deepgram-voice-failed
          - pipeline-error-eleven-labs-voice-failed
          - pipeline-error-playht-voice-failed
          - pipeline-error-lmnt-voice-failed
          - pipeline-error-azure-voice-failed
          - pipeline-error-rime-ai-voice-failed
          - pipeline-error-smallest-ai-voice-failed
          - pipeline-error-neuphonic-voice-failed
          - pipeline-error-hume-voice-failed
          - pipeline-error-sesame-voice-failed
          - pipeline-error-tavus-video-failed
          - call.in-progress.error-vapifault-openai-voice-failed
          - call.in-progress.error-vapifault-cartesia-voice-failed
          - call.in-progress.error-vapifault-deepgram-voice-failed
          - call.in-progress.error-vapifault-eleven-labs-voice-failed
          - call.in-progress.error-vapifault-playht-voice-failed
          - call.in-progress.error-vapifault-lmnt-voice-failed
          - call.in-progress.error-vapifault-azure-voice-failed
          - call.in-progress.error-vapifault-rime-ai-voice-failed
          - call.in-progress.error-vapifault-smallest-ai-voice-failed
          - call.in-progress.error-vapifault-neuphonic-voice-failed
          - call.in-progress.error-vapifault-hume-voice-failed
          - call.in-progress.error-vapifault-sesame-voice-failed
          - call.in-progress.error-vapifault-tavus-video-failed
          - pipeline-error-vapi-llm-failed
          - pipeline-error-vapi-400-bad-request-validation-failed
          - pipeline-error-vapi-401-unauthorized
          - pipeline-error-vapi-403-model-access-denied
          - pipeline-error-vapi-429-exceeded-quota
          - pipeline-error-vapi-500-server-error
          - pipeline-error-vapi-503-server-overloaded-error
          - call.in-progress.error-vapifault-vapi-llm-failed
          - call.in-progress.error-vapifault-vapi-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-vapi-401-unauthorized
          - call.in-progress.error-vapifault-vapi-403-model-access-denied
          - call.in-progress.error-vapifault-vapi-429-exceeded-quota
          - call.in-progress.error-providerfault-vapi-500-server-error
          - call.in-progress.error-providerfault-vapi-503-server-overloaded-error
          - pipeline-error-deepgram-transcriber-failed
          - call.in-progress.error-vapifault-deepgram-transcriber-failed
          - pipeline-error-gladia-transcriber-failed
          - call.in-progress.error-vapifault-gladia-transcriber-failed
          - pipeline-error-speechmatics-transcriber-failed
          - call.in-progress.error-vapifault-speechmatics-transcriber-failed
          - pipeline-error-assembly-ai-transcriber-failed
          - pipeline-error-assembly-ai-returning-400-insufficent-funds
          - pipeline-error-assembly-ai-returning-400-paid-only-feature
          - pipeline-error-assembly-ai-returning-401-invalid-credentials
          - pipeline-error-assembly-ai-returning-500-invalid-schema
          - pipeline-error-assembly-ai-returning-500-word-boost-parsing-failed
          - call.in-progress.error-vapifault-assembly-ai-transcriber-failed
          - call.in-progress.error-vapifault-assembly-ai-returning-400-insufficent-funds
          - call.in-progress.error-vapifault-assembly-ai-returning-400-paid-only-feature
          - call.in-progress.error-vapifault-assembly-ai-returning-401-invalid-credentials
          - call.in-progress.error-vapifault-assembly-ai-returning-500-invalid-schema
          - call.in-progress.error-vapifault-assembly-ai-returning-500-word-boost-parsing-failed
          - pipeline-error-talkscriber-transcriber-failed
          - call.in-progress.error-vapifault-talkscriber-transcriber-failed
          - pipeline-error-azure-speech-transcriber-failed
          - call.in-progress.error-vapifault-azure-speech-transcriber-failed
          - call.in-progress.error-pipeline-no-available-llm-model
          - worker-shutdown
          - unknown-error
          - vonage-disconnected
          - vonage-failed-to-connect-call
          - vonage-completed
          - phone-call-provider-bypass-enabled-but-no-call-received
          - call.in-progress.error-vapifault-transport-never-connected
          - call.in-progress.error-vapifault-transport-connected-but-call-not-active
          - call.in-progress.error-vapifault-call-started-but-connection-to-transport-missing
          - call.in-progress.error-vapifault-openai-llm-failed
          - call.in-progress.error-vapifault-azure-openai-llm-failed
          - call.in-progress.error-vapifault-groq-llm-failed
          - call.in-progress.error-vapifault-google-llm-failed
          - call.in-progress.error-vapifault-xai-llm-failed
          - call.in-progress.error-vapifault-mistral-llm-failed
          - call.in-progress.error-vapifault-inflection-ai-llm-failed
          - call.in-progress.error-vapifault-cerebras-llm-failed
          - call.in-progress.error-vapifault-deep-seek-llm-failed
          - pipeline-error-openai-400-bad-request-validation-failed
          - pipeline-error-openai-401-unauthorized
          - pipeline-error-openai-401-incorrect-api-key
          - pipeline-error-openai-401-account-not-in-organization
          - pipeline-error-openai-403-model-access-denied
          - pipeline-error-openai-429-exceeded-quota
          - pipeline-error-openai-429-rate-limit-reached
          - pipeline-error-openai-500-server-error
          - pipeline-error-openai-503-server-overloaded-error
          - pipeline-error-openai-llm-failed
          - call.in-progress.error-vapifault-openai-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-openai-401-unauthorized
          - call.in-progress.error-vapifault-openai-401-incorrect-api-key
          - call.in-progress.error-vapifault-openai-401-account-not-in-organization
          - call.in-progress.error-vapifault-openai-403-model-access-denied
          - call.in-progress.error-vapifault-openai-429-exceeded-quota
          - call.in-progress.error-vapifault-openai-429-rate-limit-reached
          - call.in-progress.error-providerfault-openai-500-server-error
          - call.in-progress.error-providerfault-openai-503-server-overloaded-error
          - pipeline-error-azure-openai-400-bad-request-validation-failed
          - pipeline-error-azure-openai-401-unauthorized
          - pipeline-error-azure-openai-403-model-access-denied
          - pipeline-error-azure-openai-429-exceeded-quota
          - pipeline-error-azure-openai-500-server-error
          - pipeline-error-azure-openai-503-server-overloaded-error
          - pipeline-error-azure-openai-llm-failed
          - call.in-progress.error-vapifault-azure-openai-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-azure-openai-401-unauthorized
          - call.in-progress.error-vapifault-azure-openai-403-model-access-denied
          - call.in-progress.error-vapifault-azure-openai-429-exceeded-quota
          - call.in-progress.error-providerfault-azure-openai-500-server-error
          - call.in-progress.error-providerfault-azure-openai-503-server-overloaded-error
          - pipeline-error-google-400-bad-request-validation-failed
          - pipeline-error-google-401-unauthorized
          - pipeline-error-google-403-model-access-denied
          - pipeline-error-google-429-exceeded-quota
          - pipeline-error-google-500-server-error
          - pipeline-error-google-503-server-overloaded-error
          - pipeline-error-google-llm-failed
          - call.in-progress.error-vapifault-google-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-google-401-unauthorized
          - call.in-progress.error-vapifault-google-403-model-access-denied
          - call.in-progress.error-vapifault-google-429-exceeded-quota
          - call.in-progress.error-providerfault-google-500-server-error
          - call.in-progress.error-providerfault-google-503-server-overloaded-error
          - pipeline-error-xai-400-bad-request-validation-failed
          - pipeline-error-xai-401-unauthorized
          - pipeline-error-xai-403-model-access-denied
          - pipeline-error-xai-429-exceeded-quota
          - pipeline-error-xai-500-server-error
          - pipeline-error-xai-503-server-overloaded-error
          - pipeline-error-xai-llm-failed
          - call.in-progress.error-vapifault-xai-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-xai-401-unauthorized
          - call.in-progress.error-vapifault-xai-403-model-access-denied
          - call.in-progress.error-vapifault-xai-429-exceeded-quota
          - call.in-progress.error-providerfault-xai-500-server-error
          - call.in-progress.error-providerfault-xai-503-server-overloaded-error
          - pipeline-error-mistral-400-bad-request-validation-failed
          - pipeline-error-mistral-401-unauthorized
          - pipeline-error-mistral-403-model-access-denied
          - pipeline-error-mistral-429-exceeded-quota
          - pipeline-error-mistral-500-server-error
          - pipeline-error-mistral-503-server-overloaded-error
          - pipeline-error-mistral-llm-failed
          - call.in-progress.error-vapifault-mistral-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-mistral-401-unauthorized
          - call.in-progress.error-vapifault-mistral-403-model-access-denied
          - call.in-progress.error-vapifault-mistral-429-exceeded-quota
          - call.in-progress.error-providerfault-mistral-500-server-error
          - call.in-progress.error-providerfault-mistral-503-server-overloaded-error
          - pipeline-error-inflection-ai-400-bad-request-validation-failed
          - pipeline-error-inflection-ai-401-unauthorized
          - pipeline-error-inflection-ai-403-model-access-denied
          - pipeline-error-inflection-ai-429-exceeded-quota
          - pipeline-error-inflection-ai-500-server-error
          - pipeline-error-inflection-ai-503-server-overloaded-error
          - pipeline-error-inflection-ai-llm-failed
          - call.in-progress.error-vapifault-inflection-ai-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-inflection-ai-401-unauthorized
          - call.in-progress.error-vapifault-inflection-ai-403-model-access-denied
          - call.in-progress.error-vapifault-inflection-ai-429-exceeded-quota
          - call.in-progress.error-providerfault-inflection-ai-500-server-error
          - call.in-progress.error-providerfault-inflection-ai-503-server-overloaded-error
          - pipeline-error-deep-seek-400-bad-request-validation-failed
          - pipeline-error-deep-seek-401-unauthorized
          - pipeline-error-deep-seek-403-model-access-denied
          - pipeline-error-deep-seek-429-exceeded-quota
          - pipeline-error-deep-seek-500-server-error
          - pipeline-error-deep-seek-503-server-overloaded-error
          - pipeline-error-deep-seek-llm-failed
          - call.in-progress.error-vapifault-deep-seek-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-deep-seek-401-unauthorized
          - call.in-progress.error-vapifault-deep-seek-403-model-access-denied
          - call.in-progress.error-vapifault-deep-seek-429-exceeded-quota
          - call.in-progress.error-providerfault-deep-seek-500-server-error
          - call.in-progress.error-providerfault-deep-seek-503-server-overloaded-error
          - pipeline-error-groq-400-bad-request-validation-failed
          - pipeline-error-groq-401-unauthorized
          - pipeline-error-groq-403-model-access-denied
          - pipeline-error-groq-429-exceeded-quota
          - pipeline-error-groq-500-server-error
          - pipeline-error-groq-503-server-overloaded-error
          - pipeline-error-groq-llm-failed
          - call.in-progress.error-vapifault-groq-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-groq-401-unauthorized
          - call.in-progress.error-vapifault-groq-403-model-access-denied
          - call.in-progress.error-vapifault-groq-429-exceeded-quota
          - call.in-progress.error-providerfault-groq-500-server-error
          - call.in-progress.error-providerfault-groq-503-server-overloaded-error
          - pipeline-error-cerebras-400-bad-request-validation-failed
          - pipeline-error-cerebras-401-unauthorized
          - pipeline-error-cerebras-403-model-access-denied
          - pipeline-error-cerebras-429-exceeded-quota
          - pipeline-error-cerebras-500-server-error
          - pipeline-error-cerebras-503-server-overloaded-error
          - pipeline-error-cerebras-llm-failed
          - call.in-progress.error-vapifault-cerebras-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-cerebras-401-unauthorized
          - call.in-progress.error-vapifault-cerebras-403-model-access-denied
          - call.in-progress.error-vapifault-cerebras-429-exceeded-quota
          - call.in-progress.error-providerfault-cerebras-500-server-error
          - call.in-progress.error-providerfault-cerebras-503-server-overloaded-error
          - pipeline-error-anthropic-400-bad-request-validation-failed
          - pipeline-error-anthropic-401-unauthorized
          - pipeline-error-anthropic-403-model-access-denied
          - pipeline-error-anthropic-429-exceeded-quota
          - pipeline-error-anthropic-500-server-error
          - pipeline-error-anthropic-503-server-overloaded-error
          - pipeline-error-anthropic-llm-failed
          - call.in-progress.error-vapifault-anthropic-llm-failed
          - call.in-progress.error-vapifault-anthropic-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-anthropic-401-unauthorized
          - call.in-progress.error-vapifault-anthropic-403-model-access-denied
          - call.in-progress.error-vapifault-anthropic-429-exceeded-quota
          - call.in-progress.error-providerfault-anthropic-500-server-error
          - call.in-progress.error-providerfault-anthropic-503-server-overloaded-error
          - pipeline-error-anthropic-bedrock-400-bad-request-validation-failed
          - pipeline-error-anthropic-bedrock-401-unauthorized
          - pipeline-error-anthropic-bedrock-403-model-access-denied
          - pipeline-error-anthropic-bedrock-429-exceeded-quota
          - pipeline-error-anthropic-bedrock-500-server-error
          - pipeline-error-anthropic-bedrock-503-server-overloaded-error
          - pipeline-error-anthropic-bedrock-llm-failed
          - call.in-progress.error-vapifault-anthropic-bedrock-llm-failed
          - call.in-progress.error-vapifault-anthropic-bedrock-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-anthropic-bedrock-401-unauthorized
          - call.in-progress.error-vapifault-anthropic-bedrock-403-model-access-denied
          - call.in-progress.error-vapifault-anthropic-bedrock-429-exceeded-quota
          - call.in-progress.error-providerfault-anthropic-bedrock-500-server-error
          - call.in-progress.error-providerfault-anthropic-bedrock-503-server-overloaded-error
          - pipeline-error-anthropic-vertex-400-bad-request-validation-failed
          - pipeline-error-anthropic-vertex-401-unauthorized
          - pipeline-error-anthropic-vertex-403-model-access-denied
          - pipeline-error-anthropic-vertex-429-exceeded-quota
          - pipeline-error-anthropic-vertex-500-server-error
          - pipeline-error-anthropic-vertex-503-server-overloaded-error
          - pipeline-error-anthropic-vertex-llm-failed
          - call.in-progress.error-vapifault-anthropic-vertex-llm-failed
          - call.in-progress.error-vapifault-anthropic-vertex-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-anthropic-vertex-401-unauthorized
          - call.in-progress.error-vapifault-anthropic-vertex-403-model-access-denied
          - call.in-progress.error-vapifault-anthropic-vertex-429-exceeded-quota
          - call.in-progress.error-providerfault-anthropic-vertex-500-server-error
          - call.in-progress.error-providerfault-anthropic-vertex-503-server-overloaded-error
          - pipeline-error-together-ai-400-bad-request-validation-failed
          - pipeline-error-together-ai-401-unauthorized
          - pipeline-error-together-ai-403-model-access-denied
          - pipeline-error-together-ai-429-exceeded-quota
          - pipeline-error-together-ai-500-server-error
          - pipeline-error-together-ai-503-server-overloaded-error
          - pipeline-error-together-ai-llm-failed
          - call.in-progress.error-vapifault-together-ai-llm-failed
          - call.in-progress.error-vapifault-together-ai-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-together-ai-401-unauthorized
          - call.in-progress.error-vapifault-together-ai-403-model-access-denied
          - call.in-progress.error-vapifault-together-ai-429-exceeded-quota
          - call.in-progress.error-providerfault-together-ai-500-server-error
          - call.in-progress.error-providerfault-together-ai-503-server-overloaded-error
          - pipeline-error-anyscale-400-bad-request-validation-failed
          - pipeline-error-anyscale-401-unauthorized
          - pipeline-error-anyscale-403-model-access-denied
          - pipeline-error-anyscale-429-exceeded-quota
          - pipeline-error-anyscale-500-server-error
          - pipeline-error-anyscale-503-server-overloaded-error
          - pipeline-error-anyscale-llm-failed
          - call.in-progress.error-vapifault-anyscale-llm-failed
          - call.in-progress.error-vapifault-anyscale-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-anyscale-401-unauthorized
          - call.in-progress.error-vapifault-anyscale-403-model-access-denied
          - call.in-progress.error-vapifault-anyscale-429-exceeded-quota
          - call.in-progress.error-providerfault-anyscale-500-server-error
          - call.in-progress.error-providerfault-anyscale-503-server-overloaded-error
          - pipeline-error-openrouter-400-bad-request-validation-failed
          - pipeline-error-openrouter-401-unauthorized
          - pipeline-error-openrouter-403-model-access-denied
          - pipeline-error-openrouter-429-exceeded-quota
          - pipeline-error-openrouter-500-server-error
          - pipeline-error-openrouter-503-server-overloaded-error
          - pipeline-error-openrouter-llm-failed
          - call.in-progress.error-vapifault-openrouter-llm-failed
          - call.in-progress.error-vapifault-openrouter-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-openrouter-401-unauthorized
          - call.in-progress.error-vapifault-openrouter-403-model-access-denied
          - call.in-progress.error-vapifault-openrouter-429-exceeded-quota
          - call.in-progress.error-providerfault-openrouter-500-server-error
          - call.in-progress.error-providerfault-openrouter-503-server-overloaded-error
          - pipeline-error-perplexity-ai-400-bad-request-validation-failed
          - pipeline-error-perplexity-ai-401-unauthorized
          - pipeline-error-perplexity-ai-403-model-access-denied
          - pipeline-error-perplexity-ai-429-exceeded-quota
          - pipeline-error-perplexity-ai-500-server-error
          - pipeline-error-perplexity-ai-503-server-overloaded-error
          - pipeline-error-perplexity-ai-llm-failed
          - call.in-progress.error-vapifault-perplexity-ai-llm-failed
          - call.in-progress.error-vapifault-perplexity-ai-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-perplexity-ai-401-unauthorized
          - call.in-progress.error-vapifault-perplexity-ai-403-model-access-denied
          - call.in-progress.error-vapifault-perplexity-ai-429-exceeded-quota
          - call.in-progress.error-providerfault-perplexity-ai-500-server-error
          - call.in-progress.error-providerfault-perplexity-ai-503-server-overloaded-error
          - pipeline-error-deepinfra-400-bad-request-validation-failed
          - pipeline-error-deepinfra-401-unauthorized
          - pipeline-error-deepinfra-403-model-access-denied
          - pipeline-error-deepinfra-429-exceeded-quota
          - pipeline-error-deepinfra-500-server-error
          - pipeline-error-deepinfra-503-server-overloaded-error
          - pipeline-error-deepinfra-llm-failed
          - call.in-progress.error-vapifault-deepinfra-llm-failed
          - call.in-progress.error-vapifault-deepinfra-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-deepinfra-401-unauthorized
          - call.in-progress.error-vapifault-deepinfra-403-model-access-denied
          - call.in-progress.error-vapifault-deepinfra-429-exceeded-quota
          - call.in-progress.error-providerfault-deepinfra-500-server-error
          - call.in-progress.error-providerfault-deepinfra-503-server-overloaded-error
          - pipeline-error-runpod-400-bad-request-validation-failed
          - pipeline-error-runpod-401-unauthorized
          - pipeline-error-runpod-403-model-access-denied
          - pipeline-error-runpod-429-exceeded-quota
          - pipeline-error-runpod-500-server-error
          - pipeline-error-runpod-503-server-overloaded-error
          - pipeline-error-runpod-llm-failed
          - call.in-progress.error-vapifault-runpod-llm-failed
          - call.in-progress.error-vapifault-runpod-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-runpod-401-unauthorized
          - call.in-progress.error-vapifault-runpod-403-model-access-denied
          - call.in-progress.error-vapifault-runpod-429-exceeded-quota
          - call.in-progress.error-providerfault-runpod-500-server-error
          - call.in-progress.error-providerfault-runpod-503-server-overloaded-error
          - pipeline-error-custom-llm-400-bad-request-validation-failed
          - pipeline-error-custom-llm-401-unauthorized
          - pipeline-error-custom-llm-403-model-access-denied
          - pipeline-error-custom-llm-429-exceeded-quota
          - pipeline-error-custom-llm-500-server-error
          - pipeline-error-custom-llm-503-server-overloaded-error
          - pipeline-error-custom-llm-llm-failed
          - call.in-progress.error-vapifault-custom-llm-llm-failed
          - call.in-progress.error-vapifault-custom-llm-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-custom-llm-401-unauthorized
          - call.in-progress.error-vapifault-custom-llm-403-model-access-denied
          - call.in-progress.error-vapifault-custom-llm-429-exceeded-quota
          - call.in-progress.error-providerfault-custom-llm-500-server-error
          - call.in-progress.error-providerfault-custom-llm-503-server-overloaded-error
          - pipeline-error-custom-voice-failed
          - pipeline-error-cartesia-socket-hang-up
          - pipeline-error-cartesia-requested-payment
          - pipeline-error-cartesia-500-server-error
          - pipeline-error-cartesia-503-server-error
          - pipeline-error-cartesia-522-server-error
          - call.in-progress.error-vapifault-cartesia-socket-hang-up
          - call.in-progress.error-vapifault-cartesia-requested-payment
          - call.in-progress.error-providerfault-cartesia-500-server-error
          - call.in-progress.error-providerfault-cartesia-503-server-error
          - call.in-progress.error-providerfault-cartesia-522-server-error
          - pipeline-error-eleven-labs-voice-not-found
          - pipeline-error-eleven-labs-quota-exceeded
          - pipeline-error-eleven-labs-unauthorized-access
          - pipeline-error-eleven-labs-unauthorized-to-access-model
          - pipeline-error-eleven-labs-professional-voices-only-for-creator-plus
          - pipeline-error-eleven-labs-blocked-free-plan-and-requested-upgrade
          - pipeline-error-eleven-labs-blocked-concurrent-requests-and-requested-upgrade
          - pipeline-error-eleven-labs-blocked-using-instant-voice-clone-and-requested-upgrade
          - pipeline-error-eleven-labs-system-busy-and-requested-upgrade
          - pipeline-error-eleven-labs-voice-not-fine-tuned
          - pipeline-error-eleven-labs-invalid-api-key
          - pipeline-error-eleven-labs-invalid-voice-samples
          - pipeline-error-eleven-labs-voice-disabled-by-owner
          - pipeline-error-eleven-labs-blocked-account-in-probation
          - pipeline-error-eleven-labs-blocked-content-against-their-policy
          - pipeline-error-eleven-labs-missing-samples-for-voice-clone
          - pipeline-error-eleven-labs-voice-not-fine-tuned-and-cannot-be-used
          - pipeline-error-eleven-labs-voice-not-allowed-for-free-users
          - pipeline-error-eleven-labs-max-character-limit-exceeded
          - pipeline-error-eleven-labs-blocked-voice-potentially-against-terms-of-service-and-awaiting-verification
          - pipeline-error-eleven-labs-500-server-error
          - call.in-progress.error-vapifault-eleven-labs-voice-not-found
          - call.in-progress.error-vapifault-eleven-labs-quota-exceeded
          - call.in-progress.error-vapifault-eleven-labs-unauthorized-access
          - call.in-progress.error-vapifault-eleven-labs-unauthorized-to-access-model
          - call.in-progress.error-vapifault-eleven-labs-professional-voices-only-for-creator-plus
          - call.in-progress.error-vapifault-eleven-labs-blocked-free-plan-and-requested-upgrade
          - call.in-progress.error-vapifault-eleven-labs-blocked-concurrent-requests-and-requested-upgrade
          - call.in-progress.error-vapifault-eleven-labs-blocked-using-instant-voice-clone-and-requested-upgrade
          - call.in-progress.error-vapifault-eleven-labs-system-busy-and-requested-upgrade
          - call.in-progress.error-vapifault-eleven-labs-voice-not-fine-tuned
          - call.in-progress.error-vapifault-eleven-labs-invalid-api-key
          - call.in-progress.error-vapifault-eleven-labs-invalid-voice-samples
          - call.in-progress.error-vapifault-eleven-labs-voice-disabled-by-owner
          - call.in-progress.error-vapifault-eleven-labs-blocked-account-in-probation
          - call.in-progress.error-vapifault-eleven-labs-blocked-content-against-their-policy
          - call.in-progress.error-vapifault-eleven-labs-missing-samples-for-voice-clone
          - call.in-progress.error-vapifault-eleven-labs-voice-not-fine-tuned-and-cannot-be-used
          - call.in-progress.error-vapifault-eleven-labs-voice-not-allowed-for-free-users
          - call.in-progress.error-vapifault-eleven-labs-max-character-limit-exceeded
          - call.in-progress.error-vapifault-eleven-labs-blocked-voice-potentially-against-terms-of-service-and-awaiting-verification
          - call.in-progress.error-providerfault-eleven-labs-500-server-error
          - pipeline-error-playht-request-timed-out
          - pipeline-error-playht-invalid-voice
          - pipeline-error-playht-unexpected-error
          - pipeline-error-playht-out-of-credits
          - pipeline-error-playht-invalid-emotion
          - pipeline-error-playht-voice-must-be-a-valid-voice-manifest-uri
          - pipeline-error-playht-401-unauthorized
          - pipeline-error-playht-403-forbidden-out-of-characters
          - pipeline-error-playht-403-forbidden-api-access-not-available
          - pipeline-error-playht-429-exceeded-quota
          - pipeline-error-playht-502-gateway-error
          - pipeline-error-playht-504-gateway-error
          - call.in-progress.error-vapifault-playht-request-timed-out
          - call.in-progress.error-vapifault-playht-invalid-voice
          - call.in-progress.error-vapifault-playht-unexpected-error
          - call.in-progress.error-vapifault-playht-out-of-credits
          - call.in-progress.error-vapifault-playht-invalid-emotion
          - call.in-progress.error-vapifault-playht-voice-must-be-a-valid-voice-manifest-uri
          - call.in-progress.error-vapifault-playht-401-unauthorized
          - call.in-progress.error-vapifault-playht-403-forbidden-out-of-characters
          - call.in-progress.error-vapifault-playht-403-forbidden-api-access-not-available
          - call.in-progress.error-vapifault-playht-429-exceeded-quota
          - call.in-progress.error-providerfault-playht-502-gateway-error
          - call.in-progress.error-providerfault-playht-504-gateway-error
          - pipeline-error-custom-transcriber-failed
          - call.in-progress.error-vapifault-custom-transcriber-failed
          - pipeline-error-eleven-labs-transcriber-failed
          - call.in-progress.error-vapifault-eleven-labs-transcriber-failed
          - pipeline-error-deepgram-returning-400-no-such-model-language-tier-combination
          - pipeline-error-deepgram-returning-401-invalid-credentials
          - pipeline-error-deepgram-returning-403-model-access-denied
          - pipeline-error-deepgram-returning-404-not-found
          - pipeline-error-deepgram-returning-500-invalid-json
          - pipeline-error-deepgram-returning-502-network-error
          - pipeline-error-deepgram-returning-502-bad-gateway-ehostunreach
          - call.in-progress.error-vapifault-deepgram-returning-400-no-such-model-language-tier-combination
          - call.in-progress.error-vapifault-deepgram-returning-401-invalid-credentials
          - call.in-progress.error-vapifault-deepgram-returning-404-not-found
          - call.in-progress.error-vapifault-deepgram-returning-403-model-access-denied
          - call.in-progress.error-providerfault-deepgram-returning-500-invalid-json
          - call.in-progress.error-providerfault-deepgram-returning-502-network-error
          - call.in-progress.error-providerfault-deepgram-returning-502-bad-gateway-ehostunreach
          - pipeline-error-google-transcriber-failed
          - call.in-progress.error-vapifault-google-transcriber-failed
          - pipeline-error-openai-transcriber-failed
          - call.in-progress.error-vapifault-openai-transcriber-failed
          - assistant-ended-call
          - assistant-said-end-call-phrase
          - assistant-ended-call-with-hangup-task
          - assistant-ended-call-after-message-spoken
          - assistant-forwarded-call
          - assistant-join-timed-out
          - call.in-progress.error-assistant-did-not-receive-customer-audio
          - customer-busy
          - customer-ended-call
          - customer-did-not-answer
          - customer-did-not-give-microphone-permission
          - exceeded-max-duration
          - manually-canceled
          - phone-call-provider-closed-websocket
          - silence-timed-out
          - call.in-progress.error-sip-telephony-provider-failed-to-connect-call
          - call.ringing.hook-executed-say
          - call.ringing.hook-executed-transfer
          - twilio-failed-to-connect-call
          - twilio-reported-customer-misdialed
          - vonage-rejected
          - voicemail
        cost:
          type: number
          description: This is the cost of the call in USD. This can also be found at `call.cost` on GET /call/:id.
        costs:
          type: array
          description: These are the costs of individual components of the call in USD. This can also be found at `call.costs` on GET /call/:id.
          items:
            oneOf:
            - $ref: '#/components/schemas/TransportCost'
            - $ref: '#/components/schemas/TranscriberCost'
            - $ref: '#/components/schemas/ModelCost'
            - $ref: '#/components/schemas/VoiceCost'
            - $ref: '#/components/schemas/VapiCost'
            - $ref: '#/components/schemas/VoicemailDetectionCost'
            - $ref: '#/components/schemas/AnalysisCost'
        timestamp:
          type: number
          description: This is the timestamp of when the message was sent in milliseconds since Unix Epoch.
        artifact:
          description: These are the artifacts from the call. This can also be found at `call.artifact` on GET /call/:id.
          allOf:
          - $ref: '#/components/schemas/Artifact'
        assistant:
          description: |-
            This is the assistant that is currently active. This is provided for convenience.

            This matches one of the following:
            - `call.assistant`,
            - `call.assistantId`,
            - `call.squad[n].assistant`,
            - `call.squad[n].assistantId`,
            - `call.squadId->[n].assistant`,
            - `call.squadId->[n].assistantId`.
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        customer:
          description: |-
            This is the customer associated with the call.

            This matches one of the following:
            - `call.customer`,
            - `call.customerId`.
          allOf:
          - $ref: '#/components/schemas/CreateCustomerDTO'
        call:
          description: |-
            This is the call object.

            This matches what was returned in POST /call.

            Note: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.
          allOf:
          - $ref: '#/components/schemas/Call'
        analysis:
          description: This is the analysis of the call. This can also be found at `call.analysis` on GET /call/:id.
          allOf:
          - $ref: '#/components/schemas/Analysis'
        startedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the call started. This can also be found at `call.startedAt` on GET /call/:id.
          format: date-time
        endedAt:
          type: string
          description: This is the ISO 8601 date-time string of when the call ended. This can also be found at `call.endedAt` on GET /call/:id.
          format: date-time
    ServerMessageHang:
      required:
      - type
      type: object
      properties:
        phoneNumber:
          description: |-
            This is the phone number associated with the call.

            This matches one of the following:
            - `call.phoneNumber`,
            - `call.phoneNumberId`.
          oneOf:
          - $ref: '#/components/schemas/CreateByoPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateTwilioPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVonagePhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVapiPhoneNumberDTO'
        type:
          type: string
          description: |-
            This is the type of the message. "hang" is sent when the assistant is hanging due to a delay. The delay can be caused by many factors, such as:
            - the model is too slow to respond
            - the voice is too slow to respond
            - the tool call is still waiting for a response from your server
            - etc.
          enum:
          - hang
        timestamp:
          type: number
          description: This is the timestamp of when the message was sent in milliseconds since Unix Epoch.
        artifact:
          description: |-
            This is a live version of the `call.artifact`.

            This matches what is stored on `call.artifact` after the call.
          allOf:
          - $ref: '#/components/schemas/Artifact'
        assistant:
          description: |-
            This is the assistant that is currently active. This is provided for convenience.

            This matches one of the following:
            - `call.assistant`,
            - `call.assistantId`,
            - `call.squad[n].assistant`,
            - `call.squad[n].assistantId`,
            - `call.squadId->[n].assistant`,
            - `call.squadId->[n].assistantId`.
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        customer:
          description: |-
            This is the customer associated with the call.

            This matches one of the following:
            - `call.customer`,
            - `call.customerId`.
          allOf:
          - $ref: '#/components/schemas/CreateCustomerDTO'
        call:
          description: |-
            This is the call object.

            This matches what was returned in POST /call.

            Note: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.
          allOf:
          - $ref: '#/components/schemas/Call'
    ServerMessageKnowledgeBaseRequest:
      required:
      - messagesOpenAIFormatted
      - type
      type: object
      properties:
        phoneNumber:
          description: |-
            This is the phone number associated with the call.

            This matches one of the following:
            - `call.phoneNumber`,
            - `call.phoneNumberId`.
          oneOf:
          - $ref: '#/components/schemas/CreateByoPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateTwilioPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVonagePhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVapiPhoneNumberDTO'
        type:
          type: string
          description: "This is the type of the message. \"knowledge-base-request\" is sent to request knowledge base documents. To enable, use `assistant.knowledgeBase.provider=custom-knowledge-base`."
          enum:
          - knowledge-base-request
        messages:
          type: array
          description: These are the messages that are going to be sent to the `model` right after the `knowledge-base-request` webhook completes.
          items:
            oneOf:
            - $ref: '#/components/schemas/UserMessage'
            - $ref: '#/components/schemas/SystemMessage'
            - $ref: '#/components/schemas/BotMessage'
            - $ref: '#/components/schemas/ToolCallMessage'
            - $ref: '#/components/schemas/ToolCallResultMessage'
        messagesOpenAIFormatted:
          type: array
          description: This is just `messages` formatted for OpenAI.
          items:
            $ref: '#/components/schemas/OpenAIMessage'
        timestamp:
          type: number
          description: This is the timestamp of when the message was sent in milliseconds since Unix Epoch.
        artifact:
          description: |-
            This is a live version of the `call.artifact`.

            This matches what is stored on `call.artifact` after the call.
          allOf:
          - $ref: '#/components/schemas/Artifact'
        assistant:
          description: |-
            This is the assistant that is currently active. This is provided for convenience.

            This matches one of the following:
            - `call.assistant`,
            - `call.assistantId`,
            - `call.squad[n].assistant`,
            - `call.squad[n].assistantId`,
            - `call.squadId->[n].assistant`,
            - `call.squadId->[n].assistantId`.
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        customer:
          description: |-
            This is the customer associated with the call.

            This matches one of the following:
            - `call.customer`,
            - `call.customerId`.
          allOf:
          - $ref: '#/components/schemas/CreateCustomerDTO'
        call:
          description: |-
            This is the call object.

            This matches what was returned in POST /call.

            Note: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.
          allOf:
          - $ref: '#/components/schemas/Call'
    ServerMessageModelOutput:
      required:
      - output
      - type
      type: object
      properties:
        phoneNumber:
          description: |-
            This is the phone number associated with the call.

            This matches one of the following:
            - `call.phoneNumber`,
            - `call.phoneNumberId`.
          oneOf:
          - $ref: '#/components/schemas/CreateByoPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateTwilioPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVonagePhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVapiPhoneNumberDTO'
        type:
          type: string
          description: This is the type of the message. "model-output" is sent as the model outputs tokens.
          enum:
          - model-output
        timestamp:
          type: number
          description: This is the timestamp of when the message was sent in milliseconds since Unix Epoch.
        artifact:
          description: |-
            This is a live version of the `call.artifact`.

            This matches what is stored on `call.artifact` after the call.
          allOf:
          - $ref: '#/components/schemas/Artifact'
        assistant:
          description: |-
            This is the assistant that is currently active. This is provided for convenience.

            This matches one of the following:
            - `call.assistant`,
            - `call.assistantId`,
            - `call.squad[n].assistant`,
            - `call.squad[n].assistantId`,
            - `call.squadId->[n].assistant`,
            - `call.squadId->[n].assistantId`.
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        customer:
          description: |-
            This is the customer associated with the call.

            This matches one of the following:
            - `call.customer`,
            - `call.customerId`.
          allOf:
          - $ref: '#/components/schemas/CreateCustomerDTO'
        call:
          description: |-
            This is the call object.

            This matches what was returned in POST /call.

            Note: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.
          allOf:
          - $ref: '#/components/schemas/Call'
        output:
          type: object
          description: This is the output of the model. It can be a token or tool call.
    ServerMessagePhoneCallControl:
      required:
      - request
      - type
      type: object
      properties:
        phoneNumber:
          description: |-
            This is the phone number associated with the call.

            This matches one of the following:
            - `call.phoneNumber`,
            - `call.phoneNumberId`.
          oneOf:
          - $ref: '#/components/schemas/CreateByoPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateTwilioPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVonagePhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVapiPhoneNumberDTO'
        type:
          type: string
          description: |-
            This is the type of the message. "phone-call-control" is an advanced type of message.

            When it is requested in `assistant.serverMessages`, the hangup and forwarding responsibilities are delegated to your server. Vapi will no longer do the actual transfer and hangup.
          enum:
          - phone-call-control
        request:
          type: string
          description: This is the request to control the phone call.
          enum:
          - forward
          - hang-up
        destination:
          description: This is the destination to forward the call to if the request is "forward".
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
        timestamp:
          type: number
          description: This is the timestamp of when the message was sent in milliseconds since Unix Epoch.
        artifact:
          description: |-
            This is a live version of the `call.artifact`.

            This matches what is stored on `call.artifact` after the call.
          allOf:
          - $ref: '#/components/schemas/Artifact'
        assistant:
          description: |-
            This is the assistant that is currently active. This is provided for convenience.

            This matches one of the following:
            - `call.assistant`,
            - `call.assistantId`,
            - `call.squad[n].assistant`,
            - `call.squad[n].assistantId`,
            - `call.squadId->[n].assistant`,
            - `call.squadId->[n].assistantId`.
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        customer:
          description: |-
            This is the customer associated with the call.

            This matches one of the following:
            - `call.customer`,
            - `call.customerId`.
          allOf:
          - $ref: '#/components/schemas/CreateCustomerDTO'
        call:
          description: |-
            This is the call object.

            This matches what was returned in POST /call.

            Note: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.
          allOf:
          - $ref: '#/components/schemas/Call'
    ServerMessageSpeechUpdate:
      required:
      - role
      - status
      - type
      type: object
      properties:
        phoneNumber:
          description: |-
            This is the phone number associated with the call.

            This matches one of the following:
            - `call.phoneNumber`,
            - `call.phoneNumberId`.
          oneOf:
          - $ref: '#/components/schemas/CreateByoPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateTwilioPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVonagePhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVapiPhoneNumberDTO'
        type:
          type: string
          description: This is the type of the message. "speech-update" is sent whenever assistant or user start or stop speaking.
          enum:
          - speech-update
        status:
          type: string
          description: This is the status of the speech update.
          enum:
          - started
          - stopped
        role:
          type: string
          description: This is the role which the speech update is for.
          enum:
          - assistant
          - user
        turn:
          type: number
          description: This is the turn number of the speech update (0-indexed).
        timestamp:
          type: number
          description: This is the timestamp of when the message was sent in milliseconds since Unix Epoch.
        artifact:
          description: |-
            This is a live version of the `call.artifact`.

            This matches what is stored on `call.artifact` after the call.
          allOf:
          - $ref: '#/components/schemas/Artifact'
        assistant:
          description: |-
            This is the assistant that is currently active. This is provided for convenience.

            This matches one of the following:
            - `call.assistant`,
            - `call.assistantId`,
            - `call.squad[n].assistant`,
            - `call.squad[n].assistantId`,
            - `call.squadId->[n].assistant`,
            - `call.squadId->[n].assistantId`.
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        customer:
          description: |-
            This is the customer associated with the call.

            This matches one of the following:
            - `call.customer`,
            - `call.customerId`.
          allOf:
          - $ref: '#/components/schemas/CreateCustomerDTO'
        call:
          description: |-
            This is the call object.

            This matches what was returned in POST /call.

            Note: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.
          allOf:
          - $ref: '#/components/schemas/Call'
    ServerMessageStatusUpdate:
      required:
      - status
      - type
      type: object
      properties:
        phoneNumber:
          description: |-
            This is the phone number associated with the call.

            This matches one of the following:
            - `call.phoneNumber`,
            - `call.phoneNumberId`.
          oneOf:
          - $ref: '#/components/schemas/CreateByoPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateTwilioPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVonagePhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVapiPhoneNumberDTO'
        type:
          type: string
          description: This is the type of the message. "status-update" is sent whenever the `call.status` changes.
          enum:
          - status-update
        status:
          type: string
          description: This is the status of the call.
          enum:
          - scheduled
          - queued
          - ringing
          - in-progress
          - forwarding
          - ended
        endedReason:
          type: string
          description: This is the reason the call ended. This is only sent if the status is "ended".
          enum:
          - call-start-error-neither-assistant-nor-server-set
          - assistant-request-failed
          - assistant-request-returned-error
          - assistant-request-returned-unspeakable-error
          - assistant-request-returned-invalid-assistant
          - assistant-request-returned-no-assistant
          - assistant-request-returned-forwarding-phone-number
          - call.start.error-get-org
          - call.start.error-get-subscription
          - call.start.error-get-assistant
          - call.start.error-get-phone-number
          - call.start.error-get-customer
          - call.start.error-get-resources-validation
          - call.start.error-vapi-number-international
          - call.start.error-vapi-number-outbound-daily-limit
          - call.start.error-get-transport
          - assistant-not-valid
          - database-error
          - assistant-not-found
          - pipeline-error-openai-voice-failed
          - pipeline-error-cartesia-voice-failed
          - pipeline-error-deepgram-voice-failed
          - pipeline-error-eleven-labs-voice-failed
          - pipeline-error-playht-voice-failed
          - pipeline-error-lmnt-voice-failed
          - pipeline-error-azure-voice-failed
          - pipeline-error-rime-ai-voice-failed
          - pipeline-error-smallest-ai-voice-failed
          - pipeline-error-neuphonic-voice-failed
          - pipeline-error-hume-voice-failed
          - pipeline-error-sesame-voice-failed
          - pipeline-error-tavus-video-failed
          - call.in-progress.error-vapifault-openai-voice-failed
          - call.in-progress.error-vapifault-cartesia-voice-failed
          - call.in-progress.error-vapifault-deepgram-voice-failed
          - call.in-progress.error-vapifault-eleven-labs-voice-failed
          - call.in-progress.error-vapifault-playht-voice-failed
          - call.in-progress.error-vapifault-lmnt-voice-failed
          - call.in-progress.error-vapifault-azure-voice-failed
          - call.in-progress.error-vapifault-rime-ai-voice-failed
          - call.in-progress.error-vapifault-smallest-ai-voice-failed
          - call.in-progress.error-vapifault-neuphonic-voice-failed
          - call.in-progress.error-vapifault-hume-voice-failed
          - call.in-progress.error-vapifault-sesame-voice-failed
          - call.in-progress.error-vapifault-tavus-video-failed
          - pipeline-error-vapi-llm-failed
          - pipeline-error-vapi-400-bad-request-validation-failed
          - pipeline-error-vapi-401-unauthorized
          - pipeline-error-vapi-403-model-access-denied
          - pipeline-error-vapi-429-exceeded-quota
          - pipeline-error-vapi-500-server-error
          - pipeline-error-vapi-503-server-overloaded-error
          - call.in-progress.error-vapifault-vapi-llm-failed
          - call.in-progress.error-vapifault-vapi-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-vapi-401-unauthorized
          - call.in-progress.error-vapifault-vapi-403-model-access-denied
          - call.in-progress.error-vapifault-vapi-429-exceeded-quota
          - call.in-progress.error-providerfault-vapi-500-server-error
          - call.in-progress.error-providerfault-vapi-503-server-overloaded-error
          - pipeline-error-deepgram-transcriber-failed
          - call.in-progress.error-vapifault-deepgram-transcriber-failed
          - pipeline-error-gladia-transcriber-failed
          - call.in-progress.error-vapifault-gladia-transcriber-failed
          - pipeline-error-speechmatics-transcriber-failed
          - call.in-progress.error-vapifault-speechmatics-transcriber-failed
          - pipeline-error-assembly-ai-transcriber-failed
          - pipeline-error-assembly-ai-returning-400-insufficent-funds
          - pipeline-error-assembly-ai-returning-400-paid-only-feature
          - pipeline-error-assembly-ai-returning-401-invalid-credentials
          - pipeline-error-assembly-ai-returning-500-invalid-schema
          - pipeline-error-assembly-ai-returning-500-word-boost-parsing-failed
          - call.in-progress.error-vapifault-assembly-ai-transcriber-failed
          - call.in-progress.error-vapifault-assembly-ai-returning-400-insufficent-funds
          - call.in-progress.error-vapifault-assembly-ai-returning-400-paid-only-feature
          - call.in-progress.error-vapifault-assembly-ai-returning-401-invalid-credentials
          - call.in-progress.error-vapifault-assembly-ai-returning-500-invalid-schema
          - call.in-progress.error-vapifault-assembly-ai-returning-500-word-boost-parsing-failed
          - pipeline-error-talkscriber-transcriber-failed
          - call.in-progress.error-vapifault-talkscriber-transcriber-failed
          - pipeline-error-azure-speech-transcriber-failed
          - call.in-progress.error-vapifault-azure-speech-transcriber-failed
          - call.in-progress.error-pipeline-no-available-llm-model
          - worker-shutdown
          - unknown-error
          - vonage-disconnected
          - vonage-failed-to-connect-call
          - vonage-completed
          - phone-call-provider-bypass-enabled-but-no-call-received
          - call.in-progress.error-vapifault-transport-never-connected
          - call.in-progress.error-vapifault-transport-connected-but-call-not-active
          - call.in-progress.error-vapifault-call-started-but-connection-to-transport-missing
          - call.in-progress.error-vapifault-openai-llm-failed
          - call.in-progress.error-vapifault-azure-openai-llm-failed
          - call.in-progress.error-vapifault-groq-llm-failed
          - call.in-progress.error-vapifault-google-llm-failed
          - call.in-progress.error-vapifault-xai-llm-failed
          - call.in-progress.error-vapifault-mistral-llm-failed
          - call.in-progress.error-vapifault-inflection-ai-llm-failed
          - call.in-progress.error-vapifault-cerebras-llm-failed
          - call.in-progress.error-vapifault-deep-seek-llm-failed
          - pipeline-error-openai-400-bad-request-validation-failed
          - pipeline-error-openai-401-unauthorized
          - pipeline-error-openai-401-incorrect-api-key
          - pipeline-error-openai-401-account-not-in-organization
          - pipeline-error-openai-403-model-access-denied
          - pipeline-error-openai-429-exceeded-quota
          - pipeline-error-openai-429-rate-limit-reached
          - pipeline-error-openai-500-server-error
          - pipeline-error-openai-503-server-overloaded-error
          - pipeline-error-openai-llm-failed
          - call.in-progress.error-vapifault-openai-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-openai-401-unauthorized
          - call.in-progress.error-vapifault-openai-401-incorrect-api-key
          - call.in-progress.error-vapifault-openai-401-account-not-in-organization
          - call.in-progress.error-vapifault-openai-403-model-access-denied
          - call.in-progress.error-vapifault-openai-429-exceeded-quota
          - call.in-progress.error-vapifault-openai-429-rate-limit-reached
          - call.in-progress.error-providerfault-openai-500-server-error
          - call.in-progress.error-providerfault-openai-503-server-overloaded-error
          - pipeline-error-azure-openai-400-bad-request-validation-failed
          - pipeline-error-azure-openai-401-unauthorized
          - pipeline-error-azure-openai-403-model-access-denied
          - pipeline-error-azure-openai-429-exceeded-quota
          - pipeline-error-azure-openai-500-server-error
          - pipeline-error-azure-openai-503-server-overloaded-error
          - pipeline-error-azure-openai-llm-failed
          - call.in-progress.error-vapifault-azure-openai-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-azure-openai-401-unauthorized
          - call.in-progress.error-vapifault-azure-openai-403-model-access-denied
          - call.in-progress.error-vapifault-azure-openai-429-exceeded-quota
          - call.in-progress.error-providerfault-azure-openai-500-server-error
          - call.in-progress.error-providerfault-azure-openai-503-server-overloaded-error
          - pipeline-error-google-400-bad-request-validation-failed
          - pipeline-error-google-401-unauthorized
          - pipeline-error-google-403-model-access-denied
          - pipeline-error-google-429-exceeded-quota
          - pipeline-error-google-500-server-error
          - pipeline-error-google-503-server-overloaded-error
          - pipeline-error-google-llm-failed
          - call.in-progress.error-vapifault-google-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-google-401-unauthorized
          - call.in-progress.error-vapifault-google-403-model-access-denied
          - call.in-progress.error-vapifault-google-429-exceeded-quota
          - call.in-progress.error-providerfault-google-500-server-error
          - call.in-progress.error-providerfault-google-503-server-overloaded-error
          - pipeline-error-xai-400-bad-request-validation-failed
          - pipeline-error-xai-401-unauthorized
          - pipeline-error-xai-403-model-access-denied
          - pipeline-error-xai-429-exceeded-quota
          - pipeline-error-xai-500-server-error
          - pipeline-error-xai-503-server-overloaded-error
          - pipeline-error-xai-llm-failed
          - call.in-progress.error-vapifault-xai-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-xai-401-unauthorized
          - call.in-progress.error-vapifault-xai-403-model-access-denied
          - call.in-progress.error-vapifault-xai-429-exceeded-quota
          - call.in-progress.error-providerfault-xai-500-server-error
          - call.in-progress.error-providerfault-xai-503-server-overloaded-error
          - pipeline-error-mistral-400-bad-request-validation-failed
          - pipeline-error-mistral-401-unauthorized
          - pipeline-error-mistral-403-model-access-denied
          - pipeline-error-mistral-429-exceeded-quota
          - pipeline-error-mistral-500-server-error
          - pipeline-error-mistral-503-server-overloaded-error
          - pipeline-error-mistral-llm-failed
          - call.in-progress.error-vapifault-mistral-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-mistral-401-unauthorized
          - call.in-progress.error-vapifault-mistral-403-model-access-denied
          - call.in-progress.error-vapifault-mistral-429-exceeded-quota
          - call.in-progress.error-providerfault-mistral-500-server-error
          - call.in-progress.error-providerfault-mistral-503-server-overloaded-error
          - pipeline-error-inflection-ai-400-bad-request-validation-failed
          - pipeline-error-inflection-ai-401-unauthorized
          - pipeline-error-inflection-ai-403-model-access-denied
          - pipeline-error-inflection-ai-429-exceeded-quota
          - pipeline-error-inflection-ai-500-server-error
          - pipeline-error-inflection-ai-503-server-overloaded-error
          - pipeline-error-inflection-ai-llm-failed
          - call.in-progress.error-vapifault-inflection-ai-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-inflection-ai-401-unauthorized
          - call.in-progress.error-vapifault-inflection-ai-403-model-access-denied
          - call.in-progress.error-vapifault-inflection-ai-429-exceeded-quota
          - call.in-progress.error-providerfault-inflection-ai-500-server-error
          - call.in-progress.error-providerfault-inflection-ai-503-server-overloaded-error
          - pipeline-error-deep-seek-400-bad-request-validation-failed
          - pipeline-error-deep-seek-401-unauthorized
          - pipeline-error-deep-seek-403-model-access-denied
          - pipeline-error-deep-seek-429-exceeded-quota
          - pipeline-error-deep-seek-500-server-error
          - pipeline-error-deep-seek-503-server-overloaded-error
          - pipeline-error-deep-seek-llm-failed
          - call.in-progress.error-vapifault-deep-seek-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-deep-seek-401-unauthorized
          - call.in-progress.error-vapifault-deep-seek-403-model-access-denied
          - call.in-progress.error-vapifault-deep-seek-429-exceeded-quota
          - call.in-progress.error-providerfault-deep-seek-500-server-error
          - call.in-progress.error-providerfault-deep-seek-503-server-overloaded-error
          - pipeline-error-groq-400-bad-request-validation-failed
          - pipeline-error-groq-401-unauthorized
          - pipeline-error-groq-403-model-access-denied
          - pipeline-error-groq-429-exceeded-quota
          - pipeline-error-groq-500-server-error
          - pipeline-error-groq-503-server-overloaded-error
          - pipeline-error-groq-llm-failed
          - call.in-progress.error-vapifault-groq-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-groq-401-unauthorized
          - call.in-progress.error-vapifault-groq-403-model-access-denied
          - call.in-progress.error-vapifault-groq-429-exceeded-quota
          - call.in-progress.error-providerfault-groq-500-server-error
          - call.in-progress.error-providerfault-groq-503-server-overloaded-error
          - pipeline-error-cerebras-400-bad-request-validation-failed
          - pipeline-error-cerebras-401-unauthorized
          - pipeline-error-cerebras-403-model-access-denied
          - pipeline-error-cerebras-429-exceeded-quota
          - pipeline-error-cerebras-500-server-error
          - pipeline-error-cerebras-503-server-overloaded-error
          - pipeline-error-cerebras-llm-failed
          - call.in-progress.error-vapifault-cerebras-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-cerebras-401-unauthorized
          - call.in-progress.error-vapifault-cerebras-403-model-access-denied
          - call.in-progress.error-vapifault-cerebras-429-exceeded-quota
          - call.in-progress.error-providerfault-cerebras-500-server-error
          - call.in-progress.error-providerfault-cerebras-503-server-overloaded-error
          - pipeline-error-anthropic-400-bad-request-validation-failed
          - pipeline-error-anthropic-401-unauthorized
          - pipeline-error-anthropic-403-model-access-denied
          - pipeline-error-anthropic-429-exceeded-quota
          - pipeline-error-anthropic-500-server-error
          - pipeline-error-anthropic-503-server-overloaded-error
          - pipeline-error-anthropic-llm-failed
          - call.in-progress.error-vapifault-anthropic-llm-failed
          - call.in-progress.error-vapifault-anthropic-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-anthropic-401-unauthorized
          - call.in-progress.error-vapifault-anthropic-403-model-access-denied
          - call.in-progress.error-vapifault-anthropic-429-exceeded-quota
          - call.in-progress.error-providerfault-anthropic-500-server-error
          - call.in-progress.error-providerfault-anthropic-503-server-overloaded-error
          - pipeline-error-anthropic-bedrock-400-bad-request-validation-failed
          - pipeline-error-anthropic-bedrock-401-unauthorized
          - pipeline-error-anthropic-bedrock-403-model-access-denied
          - pipeline-error-anthropic-bedrock-429-exceeded-quota
          - pipeline-error-anthropic-bedrock-500-server-error
          - pipeline-error-anthropic-bedrock-503-server-overloaded-error
          - pipeline-error-anthropic-bedrock-llm-failed
          - call.in-progress.error-vapifault-anthropic-bedrock-llm-failed
          - call.in-progress.error-vapifault-anthropic-bedrock-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-anthropic-bedrock-401-unauthorized
          - call.in-progress.error-vapifault-anthropic-bedrock-403-model-access-denied
          - call.in-progress.error-vapifault-anthropic-bedrock-429-exceeded-quota
          - call.in-progress.error-providerfault-anthropic-bedrock-500-server-error
          - call.in-progress.error-providerfault-anthropic-bedrock-503-server-overloaded-error
          - pipeline-error-anthropic-vertex-400-bad-request-validation-failed
          - pipeline-error-anthropic-vertex-401-unauthorized
          - pipeline-error-anthropic-vertex-403-model-access-denied
          - pipeline-error-anthropic-vertex-429-exceeded-quota
          - pipeline-error-anthropic-vertex-500-server-error
          - pipeline-error-anthropic-vertex-503-server-overloaded-error
          - pipeline-error-anthropic-vertex-llm-failed
          - call.in-progress.error-vapifault-anthropic-vertex-llm-failed
          - call.in-progress.error-vapifault-anthropic-vertex-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-anthropic-vertex-401-unauthorized
          - call.in-progress.error-vapifault-anthropic-vertex-403-model-access-denied
          - call.in-progress.error-vapifault-anthropic-vertex-429-exceeded-quota
          - call.in-progress.error-providerfault-anthropic-vertex-500-server-error
          - call.in-progress.error-providerfault-anthropic-vertex-503-server-overloaded-error
          - pipeline-error-together-ai-400-bad-request-validation-failed
          - pipeline-error-together-ai-401-unauthorized
          - pipeline-error-together-ai-403-model-access-denied
          - pipeline-error-together-ai-429-exceeded-quota
          - pipeline-error-together-ai-500-server-error
          - pipeline-error-together-ai-503-server-overloaded-error
          - pipeline-error-together-ai-llm-failed
          - call.in-progress.error-vapifault-together-ai-llm-failed
          - call.in-progress.error-vapifault-together-ai-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-together-ai-401-unauthorized
          - call.in-progress.error-vapifault-together-ai-403-model-access-denied
          - call.in-progress.error-vapifault-together-ai-429-exceeded-quota
          - call.in-progress.error-providerfault-together-ai-500-server-error
          - call.in-progress.error-providerfault-together-ai-503-server-overloaded-error
          - pipeline-error-anyscale-400-bad-request-validation-failed
          - pipeline-error-anyscale-401-unauthorized
          - pipeline-error-anyscale-403-model-access-denied
          - pipeline-error-anyscale-429-exceeded-quota
          - pipeline-error-anyscale-500-server-error
          - pipeline-error-anyscale-503-server-overloaded-error
          - pipeline-error-anyscale-llm-failed
          - call.in-progress.error-vapifault-anyscale-llm-failed
          - call.in-progress.error-vapifault-anyscale-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-anyscale-401-unauthorized
          - call.in-progress.error-vapifault-anyscale-403-model-access-denied
          - call.in-progress.error-vapifault-anyscale-429-exceeded-quota
          - call.in-progress.error-providerfault-anyscale-500-server-error
          - call.in-progress.error-providerfault-anyscale-503-server-overloaded-error
          - pipeline-error-openrouter-400-bad-request-validation-failed
          - pipeline-error-openrouter-401-unauthorized
          - pipeline-error-openrouter-403-model-access-denied
          - pipeline-error-openrouter-429-exceeded-quota
          - pipeline-error-openrouter-500-server-error
          - pipeline-error-openrouter-503-server-overloaded-error
          - pipeline-error-openrouter-llm-failed
          - call.in-progress.error-vapifault-openrouter-llm-failed
          - call.in-progress.error-vapifault-openrouter-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-openrouter-401-unauthorized
          - call.in-progress.error-vapifault-openrouter-403-model-access-denied
          - call.in-progress.error-vapifault-openrouter-429-exceeded-quota
          - call.in-progress.error-providerfault-openrouter-500-server-error
          - call.in-progress.error-providerfault-openrouter-503-server-overloaded-error
          - pipeline-error-perplexity-ai-400-bad-request-validation-failed
          - pipeline-error-perplexity-ai-401-unauthorized
          - pipeline-error-perplexity-ai-403-model-access-denied
          - pipeline-error-perplexity-ai-429-exceeded-quota
          - pipeline-error-perplexity-ai-500-server-error
          - pipeline-error-perplexity-ai-503-server-overloaded-error
          - pipeline-error-perplexity-ai-llm-failed
          - call.in-progress.error-vapifault-perplexity-ai-llm-failed
          - call.in-progress.error-vapifault-perplexity-ai-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-perplexity-ai-401-unauthorized
          - call.in-progress.error-vapifault-perplexity-ai-403-model-access-denied
          - call.in-progress.error-vapifault-perplexity-ai-429-exceeded-quota
          - call.in-progress.error-providerfault-perplexity-ai-500-server-error
          - call.in-progress.error-providerfault-perplexity-ai-503-server-overloaded-error
          - pipeline-error-deepinfra-400-bad-request-validation-failed
          - pipeline-error-deepinfra-401-unauthorized
          - pipeline-error-deepinfra-403-model-access-denied
          - pipeline-error-deepinfra-429-exceeded-quota
          - pipeline-error-deepinfra-500-server-error
          - pipeline-error-deepinfra-503-server-overloaded-error
          - pipeline-error-deepinfra-llm-failed
          - call.in-progress.error-vapifault-deepinfra-llm-failed
          - call.in-progress.error-vapifault-deepinfra-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-deepinfra-401-unauthorized
          - call.in-progress.error-vapifault-deepinfra-403-model-access-denied
          - call.in-progress.error-vapifault-deepinfra-429-exceeded-quota
          - call.in-progress.error-providerfault-deepinfra-500-server-error
          - call.in-progress.error-providerfault-deepinfra-503-server-overloaded-error
          - pipeline-error-runpod-400-bad-request-validation-failed
          - pipeline-error-runpod-401-unauthorized
          - pipeline-error-runpod-403-model-access-denied
          - pipeline-error-runpod-429-exceeded-quota
          - pipeline-error-runpod-500-server-error
          - pipeline-error-runpod-503-server-overloaded-error
          - pipeline-error-runpod-llm-failed
          - call.in-progress.error-vapifault-runpod-llm-failed
          - call.in-progress.error-vapifault-runpod-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-runpod-401-unauthorized
          - call.in-progress.error-vapifault-runpod-403-model-access-denied
          - call.in-progress.error-vapifault-runpod-429-exceeded-quota
          - call.in-progress.error-providerfault-runpod-500-server-error
          - call.in-progress.error-providerfault-runpod-503-server-overloaded-error
          - pipeline-error-custom-llm-400-bad-request-validation-failed
          - pipeline-error-custom-llm-401-unauthorized
          - pipeline-error-custom-llm-403-model-access-denied
          - pipeline-error-custom-llm-429-exceeded-quota
          - pipeline-error-custom-llm-500-server-error
          - pipeline-error-custom-llm-503-server-overloaded-error
          - pipeline-error-custom-llm-llm-failed
          - call.in-progress.error-vapifault-custom-llm-llm-failed
          - call.in-progress.error-vapifault-custom-llm-400-bad-request-validation-failed
          - call.in-progress.error-vapifault-custom-llm-401-unauthorized
          - call.in-progress.error-vapifault-custom-llm-403-model-access-denied
          - call.in-progress.error-vapifault-custom-llm-429-exceeded-quota
          - call.in-progress.error-providerfault-custom-llm-500-server-error
          - call.in-progress.error-providerfault-custom-llm-503-server-overloaded-error
          - pipeline-error-custom-voice-failed
          - pipeline-error-cartesia-socket-hang-up
          - pipeline-error-cartesia-requested-payment
          - pipeline-error-cartesia-500-server-error
          - pipeline-error-cartesia-503-server-error
          - pipeline-error-cartesia-522-server-error
          - call.in-progress.error-vapifault-cartesia-socket-hang-up
          - call.in-progress.error-vapifault-cartesia-requested-payment
          - call.in-progress.error-providerfault-cartesia-500-server-error
          - call.in-progress.error-providerfault-cartesia-503-server-error
          - call.in-progress.error-providerfault-cartesia-522-server-error
          - pipeline-error-eleven-labs-voice-not-found
          - pipeline-error-eleven-labs-quota-exceeded
          - pipeline-error-eleven-labs-unauthorized-access
          - pipeline-error-eleven-labs-unauthorized-to-access-model
          - pipeline-error-eleven-labs-professional-voices-only-for-creator-plus
          - pipeline-error-eleven-labs-blocked-free-plan-and-requested-upgrade
          - pipeline-error-eleven-labs-blocked-concurrent-requests-and-requested-upgrade
          - pipeline-error-eleven-labs-blocked-using-instant-voice-clone-and-requested-upgrade
          - pipeline-error-eleven-labs-system-busy-and-requested-upgrade
          - pipeline-error-eleven-labs-voice-not-fine-tuned
          - pipeline-error-eleven-labs-invalid-api-key
          - pipeline-error-eleven-labs-invalid-voice-samples
          - pipeline-error-eleven-labs-voice-disabled-by-owner
          - pipeline-error-eleven-labs-blocked-account-in-probation
          - pipeline-error-eleven-labs-blocked-content-against-their-policy
          - pipeline-error-eleven-labs-missing-samples-for-voice-clone
          - pipeline-error-eleven-labs-voice-not-fine-tuned-and-cannot-be-used
          - pipeline-error-eleven-labs-voice-not-allowed-for-free-users
          - pipeline-error-eleven-labs-max-character-limit-exceeded
          - pipeline-error-eleven-labs-blocked-voice-potentially-against-terms-of-service-and-awaiting-verification
          - pipeline-error-eleven-labs-500-server-error
          - call.in-progress.error-vapifault-eleven-labs-voice-not-found
          - call.in-progress.error-vapifault-eleven-labs-quota-exceeded
          - call.in-progress.error-vapifault-eleven-labs-unauthorized-access
          - call.in-progress.error-vapifault-eleven-labs-unauthorized-to-access-model
          - call.in-progress.error-vapifault-eleven-labs-professional-voices-only-for-creator-plus
          - call.in-progress.error-vapifault-eleven-labs-blocked-free-plan-and-requested-upgrade
          - call.in-progress.error-vapifault-eleven-labs-blocked-concurrent-requests-and-requested-upgrade
          - call.in-progress.error-vapifault-eleven-labs-blocked-using-instant-voice-clone-and-requested-upgrade
          - call.in-progress.error-vapifault-eleven-labs-system-busy-and-requested-upgrade
          - call.in-progress.error-vapifault-eleven-labs-voice-not-fine-tuned
          - call.in-progress.error-vapifault-eleven-labs-invalid-api-key
          - call.in-progress.error-vapifault-eleven-labs-invalid-voice-samples
          - call.in-progress.error-vapifault-eleven-labs-voice-disabled-by-owner
          - call.in-progress.error-vapifault-eleven-labs-blocked-account-in-probation
          - call.in-progress.error-vapifault-eleven-labs-blocked-content-against-their-policy
          - call.in-progress.error-vapifault-eleven-labs-missing-samples-for-voice-clone
          - call.in-progress.error-vapifault-eleven-labs-voice-not-fine-tuned-and-cannot-be-used
          - call.in-progress.error-vapifault-eleven-labs-voice-not-allowed-for-free-users
          - call.in-progress.error-vapifault-eleven-labs-max-character-limit-exceeded
          - call.in-progress.error-vapifault-eleven-labs-blocked-voice-potentially-against-terms-of-service-and-awaiting-verification
          - call.in-progress.error-providerfault-eleven-labs-500-server-error
          - pipeline-error-playht-request-timed-out
          - pipeline-error-playht-invalid-voice
          - pipeline-error-playht-unexpected-error
          - pipeline-error-playht-out-of-credits
          - pipeline-error-playht-invalid-emotion
          - pipeline-error-playht-voice-must-be-a-valid-voice-manifest-uri
          - pipeline-error-playht-401-unauthorized
          - pipeline-error-playht-403-forbidden-out-of-characters
          - pipeline-error-playht-403-forbidden-api-access-not-available
          - pipeline-error-playht-429-exceeded-quota
          - pipeline-error-playht-502-gateway-error
          - pipeline-error-playht-504-gateway-error
          - call.in-progress.error-vapifault-playht-request-timed-out
          - call.in-progress.error-vapifault-playht-invalid-voice
          - call.in-progress.error-vapifault-playht-unexpected-error
          - call.in-progress.error-vapifault-playht-out-of-credits
          - call.in-progress.error-vapifault-playht-invalid-emotion
          - call.in-progress.error-vapifault-playht-voice-must-be-a-valid-voice-manifest-uri
          - call.in-progress.error-vapifault-playht-401-unauthorized
          - call.in-progress.error-vapifault-playht-403-forbidden-out-of-characters
          - call.in-progress.error-vapifault-playht-403-forbidden-api-access-not-available
          - call.in-progress.error-vapifault-playht-429-exceeded-quota
          - call.in-progress.error-providerfault-playht-502-gateway-error
          - call.in-progress.error-providerfault-playht-504-gateway-error
          - pipeline-error-custom-transcriber-failed
          - call.in-progress.error-vapifault-custom-transcriber-failed
          - pipeline-error-eleven-labs-transcriber-failed
          - call.in-progress.error-vapifault-eleven-labs-transcriber-failed
          - pipeline-error-deepgram-returning-400-no-such-model-language-tier-combination
          - pipeline-error-deepgram-returning-401-invalid-credentials
          - pipeline-error-deepgram-returning-403-model-access-denied
          - pipeline-error-deepgram-returning-404-not-found
          - pipeline-error-deepgram-returning-500-invalid-json
          - pipeline-error-deepgram-returning-502-network-error
          - pipeline-error-deepgram-returning-502-bad-gateway-ehostunreach
          - call.in-progress.error-vapifault-deepgram-returning-400-no-such-model-language-tier-combination
          - call.in-progress.error-vapifault-deepgram-returning-401-invalid-credentials
          - call.in-progress.error-vapifault-deepgram-returning-404-not-found
          - call.in-progress.error-vapifault-deepgram-returning-403-model-access-denied
          - call.in-progress.error-providerfault-deepgram-returning-500-invalid-json
          - call.in-progress.error-providerfault-deepgram-returning-502-network-error
          - call.in-progress.error-providerfault-deepgram-returning-502-bad-gateway-ehostunreach
          - pipeline-error-google-transcriber-failed
          - call.in-progress.error-vapifault-google-transcriber-failed
          - pipeline-error-openai-transcriber-failed
          - call.in-progress.error-vapifault-openai-transcriber-failed
          - assistant-ended-call
          - assistant-said-end-call-phrase
          - assistant-ended-call-with-hangup-task
          - assistant-ended-call-after-message-spoken
          - assistant-forwarded-call
          - assistant-join-timed-out
          - call.in-progress.error-assistant-did-not-receive-customer-audio
          - customer-busy
          - customer-ended-call
          - customer-did-not-answer
          - customer-did-not-give-microphone-permission
          - exceeded-max-duration
          - manually-canceled
          - phone-call-provider-closed-websocket
          - silence-timed-out
          - call.in-progress.error-sip-telephony-provider-failed-to-connect-call
          - call.ringing.hook-executed-say
          - call.ringing.hook-executed-transfer
          - twilio-failed-to-connect-call
          - twilio-reported-customer-misdialed
          - vonage-rejected
          - voicemail
        messages:
          type: array
          description: These are the conversation messages of the call. This is only sent if the status is "forwarding".
          items:
            oneOf:
            - $ref: '#/components/schemas/UserMessage'
            - $ref: '#/components/schemas/SystemMessage'
            - $ref: '#/components/schemas/BotMessage'
            - $ref: '#/components/schemas/ToolCallMessage'
            - $ref: '#/components/schemas/ToolCallResultMessage'
        messagesOpenAIFormatted:
          type: array
          description: These are the conversation messages of the call. This is only sent if the status is "forwarding".
          items:
            $ref: '#/components/schemas/OpenAIMessage'
        destination:
          description: This is the destination the call is being transferred to. This is only sent if the status is "forwarding".
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
        timestamp:
          type: number
          description: This is the timestamp of when the message was sent in milliseconds since Unix Epoch.
        artifact:
          description: |-
            This is a live version of the `call.artifact`.

            This matches what is stored on `call.artifact` after the call.
          allOf:
          - $ref: '#/components/schemas/Artifact'
        assistant:
          description: |-
            This is the assistant that is currently active. This is provided for convenience.

            This matches one of the following:
            - `call.assistant`,
            - `call.assistantId`,
            - `call.squad[n].assistant`,
            - `call.squad[n].assistantId`,
            - `call.squadId->[n].assistant`,
            - `call.squadId->[n].assistantId`.
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        customer:
          description: |-
            This is the customer associated with the call.

            This matches one of the following:
            - `call.customer`,
            - `call.customerId`.
          allOf:
          - $ref: '#/components/schemas/CreateCustomerDTO'
        call:
          description: |-
            This is the call object.

            This matches what was returned in POST /call.

            Note: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.
          allOf:
          - $ref: '#/components/schemas/Call'
        transcript:
          type: string
          description: This is the transcript of the call. This is only sent if the status is "forwarding".
        summary:
          type: string
          description: This is the summary of the call. This is only sent if the status is "forwarding".
        inboundPhoneCallDebuggingArtifacts:
          type: object
          description: |-
            This is the inbound phone call debugging artifacts. This is only sent if the status is "ended" and there was an error accepting the inbound phone call.

            This will include any errors related to the "assistant-request" if one was made.
    ServerMessageToolCalls:
      required:
      - toolCallList
      - toolWithToolCallList
      type: object
      properties:
        phoneNumber:
          description: |-
            This is the phone number associated with the call.

            This matches one of the following:
            - `call.phoneNumber`,
            - `call.phoneNumberId`.
          oneOf:
          - $ref: '#/components/schemas/CreateByoPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateTwilioPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVonagePhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVapiPhoneNumberDTO'
        type:
          type: string
          description: This is the type of the message. "tool-calls" is sent to call a tool.
          enum:
          - tool-calls
        toolWithToolCallList:
          type: array
          description: This is the list of tools calls that the model is requesting along with the original tool configuration.
          items:
            oneOf:
            - $ref: '#/components/schemas/FunctionToolWithToolCall'
            - $ref: '#/components/schemas/GhlToolWithToolCall'
            - $ref: '#/components/schemas/MakeToolWithToolCall'
            - $ref: '#/components/schemas/BashToolWithToolCall'
            - $ref: '#/components/schemas/ComputerToolWithToolCall'
            - $ref: '#/components/schemas/TextEditorToolWithToolCall'
            - $ref: '#/components/schemas/GoogleCalendarCreateEventToolWithToolCall'
        timestamp:
          type: number
          description: This is the timestamp of when the message was sent in milliseconds since Unix Epoch.
        artifact:
          description: |-
            This is a live version of the `call.artifact`.

            This matches what is stored on `call.artifact` after the call.
          allOf:
          - $ref: '#/components/schemas/Artifact'
        assistant:
          description: |-
            This is the assistant that is currently active. This is provided for convenience.

            This matches one of the following:
            - `call.assistant`,
            - `call.assistantId`,
            - `call.squad[n].assistant`,
            - `call.squad[n].assistantId`,
            - `call.squadId->[n].assistant`,
            - `call.squadId->[n].assistantId`.
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        customer:
          description: |-
            This is the customer associated with the call.

            This matches one of the following:
            - `call.customer`,
            - `call.customerId`.
          allOf:
          - $ref: '#/components/schemas/CreateCustomerDTO'
        call:
          description: |-
            This is the call object.

            This matches what was returned in POST /call.

            Note: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.
          allOf:
          - $ref: '#/components/schemas/Call'
        toolCallList:
          type: array
          description: This is the list of tool calls that the model is requesting.
          items:
            $ref: '#/components/schemas/ToolCall'
    ServerMessageTransferDestinationRequest:
      required:
      - type
      type: object
      properties:
        phoneNumber:
          description: |-
            This is the phone number associated with the call.

            This matches one of the following:
            - `call.phoneNumber`,
            - `call.phoneNumberId`.
          oneOf:
          - $ref: '#/components/schemas/CreateByoPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateTwilioPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVonagePhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVapiPhoneNumberDTO'
        type:
          type: string
          description: This is the type of the message. "transfer-destination-request" is sent when the model is requesting transfer but destination is unknown.
          enum:
          - transfer-destination-request
        timestamp:
          type: number
          description: This is the timestamp of when the message was sent in milliseconds since Unix Epoch.
        artifact:
          description: |-
            This is a live version of the `call.artifact`.

            This matches what is stored on `call.artifact` after the call.
          allOf:
          - $ref: '#/components/schemas/Artifact'
        assistant:
          description: |-
            This is the assistant that is currently active. This is provided for convenience.

            This matches one of the following:
            - `call.assistant`,
            - `call.assistantId`,
            - `call.squad[n].assistant`,
            - `call.squad[n].assistantId`,
            - `call.squadId->[n].assistant`,
            - `call.squadId->[n].assistantId`.
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        customer:
          description: |-
            This is the customer associated with the call.

            This matches one of the following:
            - `call.customer`,
            - `call.customerId`.
          allOf:
          - $ref: '#/components/schemas/CreateCustomerDTO'
        call:
          description: |-
            This is the call object.

            This matches what was returned in POST /call.

            Note: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.
          allOf:
          - $ref: '#/components/schemas/Call'
    ServerMessageTransferUpdate:
      required:
      - type
      type: object
      properties:
        phoneNumber:
          description: |-
            This is the phone number associated with the call.

            This matches one of the following:
            - `call.phoneNumber`,
            - `call.phoneNumberId`.
          oneOf:
          - $ref: '#/components/schemas/CreateByoPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateTwilioPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVonagePhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVapiPhoneNumberDTO'
        type:
          type: string
          description: This is the type of the message. "transfer-update" is sent whenever a transfer happens.
          enum:
          - transfer-update
        destination:
          description: This is the destination of the transfer.
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationAssistant'
          - $ref: '#/components/schemas/TransferDestinationStep'
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
        timestamp:
          type: number
          description: This is the timestamp of when the message was sent in milliseconds since Unix Epoch.
        artifact:
          description: |-
            This is a live version of the `call.artifact`.

            This matches what is stored on `call.artifact` after the call.
          allOf:
          - $ref: '#/components/schemas/Artifact'
        assistant:
          description: |-
            This is the assistant that is currently active. This is provided for convenience.

            This matches one of the following:
            - `call.assistant`,
            - `call.assistantId`,
            - `call.squad[n].assistant`,
            - `call.squad[n].assistantId`,
            - `call.squadId->[n].assistant`,
            - `call.squadId->[n].assistantId`.
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        customer:
          description: |-
            This is the customer associated with the call.

            This matches one of the following:
            - `call.customer`,
            - `call.customerId`.
          allOf:
          - $ref: '#/components/schemas/CreateCustomerDTO'
        call:
          description: |-
            This is the call object.

            This matches what was returned in POST /call.

            Note: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.
          allOf:
          - $ref: '#/components/schemas/Call'
        toAssistant:
          description: This is the assistant that the call is being transferred to. This is only sent if `destination.type` is "assistant".
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        fromAssistant:
          description: This is the assistant that the call is being transferred from. This is only sent if `destination.type` is "assistant".
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        toStepRecord:
          type: object
          description: This is the step that the conversation moved to.
        fromStepRecord:
          type: object
          description: This is the step that the conversation moved from. =
    ServerMessageTranscript:
      required:
      - role
      - transcript
      - transcriptType
      - type
      type: object
      properties:
        phoneNumber:
          description: |-
            This is the phone number associated with the call.

            This matches one of the following:
            - `call.phoneNumber`,
            - `call.phoneNumberId`.
          oneOf:
          - $ref: '#/components/schemas/CreateByoPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateTwilioPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVonagePhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVapiPhoneNumberDTO'
        type:
          type: string
          description: This is the type of the message. "transcript" is sent as transcriber outputs partial or final transcript.
          enum:
          - transcript
          - "transcript[transcriptType=\"final\"]"
        timestamp:
          type: number
          description: This is the timestamp of when the message was sent in milliseconds since Unix Epoch.
        artifact:
          description: |-
            This is a live version of the `call.artifact`.

            This matches what is stored on `call.artifact` after the call.
          allOf:
          - $ref: '#/components/schemas/Artifact'
        assistant:
          description: |-
            This is the assistant that is currently active. This is provided for convenience.

            This matches one of the following:
            - `call.assistant`,
            - `call.assistantId`,
            - `call.squad[n].assistant`,
            - `call.squad[n].assistantId`,
            - `call.squadId->[n].assistant`,
            - `call.squadId->[n].assistantId`.
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        customer:
          description: |-
            This is the customer associated with the call.

            This matches one of the following:
            - `call.customer`,
            - `call.customerId`.
          allOf:
          - $ref: '#/components/schemas/CreateCustomerDTO'
        call:
          description: |-
            This is the call object.

            This matches what was returned in POST /call.

            Note: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.
          allOf:
          - $ref: '#/components/schemas/Call'
        role:
          type: string
          description: This is the role for which the transcript is for.
          enum:
          - assistant
          - user
        transcriptType:
          type: string
          description: This is the type of the transcript.
          enum:
          - partial
          - final
        transcript:
          type: string
          description: This is the transcript content.
    ServerMessageUserInterrupted:
      required:
      - type
      type: object
      properties:
        phoneNumber:
          description: |-
            This is the phone number associated with the call.

            This matches one of the following:
            - `call.phoneNumber`,
            - `call.phoneNumberId`.
          oneOf:
          - $ref: '#/components/schemas/CreateByoPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateTwilioPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVonagePhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVapiPhoneNumberDTO'
        type:
          type: string
          description: This is the type of the message. "user-interrupted" is sent when the user interrupts the assistant.
          enum:
          - user-interrupted
        timestamp:
          type: number
          description: This is the timestamp of when the message was sent in milliseconds since Unix Epoch.
        artifact:
          description: |-
            This is a live version of the `call.artifact`.

            This matches what is stored on `call.artifact` after the call.
          allOf:
          - $ref: '#/components/schemas/Artifact'
        assistant:
          description: |-
            This is the assistant that is currently active. This is provided for convenience.

            This matches one of the following:
            - `call.assistant`,
            - `call.assistantId`,
            - `call.squad[n].assistant`,
            - `call.squad[n].assistantId`,
            - `call.squadId->[n].assistant`,
            - `call.squadId->[n].assistantId`.
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        customer:
          description: |-
            This is the customer associated with the call.

            This matches one of the following:
            - `call.customer`,
            - `call.customerId`.
          allOf:
          - $ref: '#/components/schemas/CreateCustomerDTO'
        call:
          description: |-
            This is the call object.

            This matches what was returned in POST /call.

            Note: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.
          allOf:
          - $ref: '#/components/schemas/Call'
    ServerMessageLanguageChangeDetected:
      required:
      - language
      - type
      type: object
      properties:
        phoneNumber:
          description: |-
            This is the phone number associated with the call.

            This matches one of the following:
            - `call.phoneNumber`,
            - `call.phoneNumberId`.
          oneOf:
          - $ref: '#/components/schemas/CreateByoPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateTwilioPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVonagePhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVapiPhoneNumberDTO'
        type:
          type: string
          description: This is the type of the message. "language-change-detected" is sent when the transcriber is automatically switched based on the detected language.
          enum:
          - language-change-detected
        timestamp:
          type: number
          description: This is the timestamp of when the message was sent in milliseconds since Unix Epoch.
        artifact:
          description: |-
            This is a live version of the `call.artifact`.

            This matches what is stored on `call.artifact` after the call.
          allOf:
          - $ref: '#/components/schemas/Artifact'
        assistant:
          description: |-
            This is the assistant that is currently active. This is provided for convenience.

            This matches one of the following:
            - `call.assistant`,
            - `call.assistantId`,
            - `call.squad[n].assistant`,
            - `call.squad[n].assistantId`,
            - `call.squadId->[n].assistant`,
            - `call.squadId->[n].assistantId`.
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        customer:
          description: |-
            This is the customer associated with the call.

            This matches one of the following:
            - `call.customer`,
            - `call.customerId`.
          allOf:
          - $ref: '#/components/schemas/CreateCustomerDTO'
        call:
          description: |-
            This is the call object.

            This matches what was returned in POST /call.

            Note: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.
          allOf:
          - $ref: '#/components/schemas/Call'
        language:
          type: string
          description: This is the language the transcriber is switched to.
    ServerMessageVoiceInput:
      required:
      - input
      - type
      type: object
      properties:
        phoneNumber:
          description: |-
            This is the phone number associated with the call.

            This matches one of the following:
            - `call.phoneNumber`,
            - `call.phoneNumberId`.
          oneOf:
          - $ref: '#/components/schemas/CreateByoPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateTwilioPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVonagePhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVapiPhoneNumberDTO'
        type:
          type: string
          description: This is the type of the message. "voice-input" is sent when a generation is requested from voice provider.
          enum:
          - voice-input
        timestamp:
          type: number
          description: This is the timestamp of when the message was sent in milliseconds since Unix Epoch.
        artifact:
          description: |-
            This is a live version of the `call.artifact`.

            This matches what is stored on `call.artifact` after the call.
          allOf:
          - $ref: '#/components/schemas/Artifact'
        assistant:
          description: |-
            This is the assistant that is currently active. This is provided for convenience.

            This matches one of the following:
            - `call.assistant`,
            - `call.assistantId`,
            - `call.squad[n].assistant`,
            - `call.squad[n].assistantId`,
            - `call.squadId->[n].assistant`,
            - `call.squadId->[n].assistantId`.
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        customer:
          description: |-
            This is the customer associated with the call.

            This matches one of the following:
            - `call.customer`,
            - `call.customerId`.
          allOf:
          - $ref: '#/components/schemas/CreateCustomerDTO'
        call:
          description: |-
            This is the call object.

            This matches what was returned in POST /call.

            Note: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.
          allOf:
          - $ref: '#/components/schemas/Call'
        input:
          type: string
          description: This is the voice input content
    ServerMessageVoiceRequest:
      required:
      - sampleRate
      - text
      - type
      type: object
      properties:
        phoneNumber:
          description: |-
            This is the phone number associated with the call.

            This matches one of the following:
            - `call.phoneNumber`,
            - `call.phoneNumberId`.
          oneOf:
          - $ref: '#/components/schemas/CreateByoPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateTwilioPhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVonagePhoneNumberDTO'
          - $ref: '#/components/schemas/CreateVapiPhoneNumberDTO'
        type:
          type: string
          description: |-
            This is the type of the message. "voice-request" is sent when using `assistant.voice={ "type": "custom-voice" }`.

            Here is what the request will look like:

            POST https://{assistant.voice.server.url}
            Content-Type: application/json

            {
              "messsage": {
                "type": "voice-request",
                "text": "Hello, world!",
                "sampleRate": 24000,
                ...other metadata about the call...
              }
            }

            The expected response is 1-channel 16-bit raw PCM audio at the sample rate specified in the request. Here is how the response will be piped to the transport:
            ```
            response.on('data', (chunk: Buffer) => {
              outputStream.write(chunk);
            });
            ```
          enum:
          - voice-request
        timestamp:
          type: number
          description: This is the timestamp of when the message was sent in milliseconds since Unix Epoch.
        artifact:
          description: |-
            This is a live version of the `call.artifact`.

            This matches what is stored on `call.artifact` after the call.
          allOf:
          - $ref: '#/components/schemas/Artifact'
        assistant:
          description: |-
            This is the assistant that is currently active. This is provided for convenience.

            This matches one of the following:
            - `call.assistant`,
            - `call.assistantId`,
            - `call.squad[n].assistant`,
            - `call.squad[n].assistantId`,
            - `call.squadId->[n].assistant`,
            - `call.squadId->[n].assistantId`.
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        customer:
          description: |-
            This is the customer associated with the call.

            This matches one of the following:
            - `call.customer`,
            - `call.customerId`.
          allOf:
          - $ref: '#/components/schemas/CreateCustomerDTO'
        call:
          description: |-
            This is the call object.

            This matches what was returned in POST /call.

            Note: This might get stale during the call. To get the latest call object, especially after the call is ended, use GET /call/:id.
          allOf:
          - $ref: '#/components/schemas/Call'
        text:
          type: string
          description: This is the text to be synthesized.
        sampleRate:
          type: number
          description: This is the sample rate to be synthesized.
    ServerMessage:
      required:
      - message
      type: object
      properties:
        message:
          description: |-
            These are all the messages that can be sent to your server before, after and during the call. Configure the messages you'd like to receive in `assistant.serverMessages`.

            The server where the message is sent is determined by the following precedence order:

            1. `tool.server.url` (if configured, and only for "tool-calls" message)
            2. `assistant.serverUrl` (if configure)
            3. `phoneNumber.serverUrl` (if configured)
            4. `org.serverUrl` (if configured)
          oneOf:
          - $ref: '#/components/schemas/ServerMessageAssistantRequest'
          - $ref: '#/components/schemas/ServerMessageConversationUpdate'
          - $ref: '#/components/schemas/ServerMessageEndOfCallReport'
          - $ref: '#/components/schemas/ServerMessageHang'
          - $ref: '#/components/schemas/ServerMessageKnowledgeBaseRequest'
          - $ref: '#/components/schemas/ServerMessageModelOutput'
          - $ref: '#/components/schemas/ServerMessagePhoneCallControl'
          - $ref: '#/components/schemas/ServerMessageSpeechUpdate'
          - $ref: '#/components/schemas/ServerMessageStatusUpdate'
          - $ref: '#/components/schemas/ServerMessageToolCalls'
          - $ref: '#/components/schemas/ServerMessageTransferDestinationRequest'
          - $ref: '#/components/schemas/ServerMessageTransferUpdate'
          - $ref: '#/components/schemas/ServerMessageTranscript'
          - $ref: '#/components/schemas/ServerMessageUserInterrupted'
          - $ref: '#/components/schemas/ServerMessageLanguageChangeDetected'
          - $ref: '#/components/schemas/ServerMessageVoiceInput'
          - $ref: '#/components/schemas/ServerMessageVoiceRequest'
    ServerMessageResponseAssistantRequest:
      type: object
      properties:
        destination:
          description: |-
            This is the destination to transfer the inbound call to. This will immediately transfer without using any assistants.

            If this is sent, `assistantId`, `assistant`, `squadId`, and `squad` are ignored.
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
        assistantId:
          type: string
          description: "This is the assistant that will be used for the call. To use a transient assistant, use `assistant` instead."
          nullable: true
        assistant:
          description: |-
            This is the assistant that will be used for the call. To use an existing assistant, use `assistantId` instead.

            If you're unsure why you're getting an invalid assistant, try logging your response and send the JSON blob to POST /assistant which will return the validation errors.
          allOf:
          - $ref: '#/components/schemas/CreateAssistantDTO'
        assistantOverrides:
          description: These are the overrides for the `assistant` or `assistantId`'s settings and template variables.
          allOf:
          - $ref: '#/components/schemas/AssistantOverrides'
        squadId:
          type: string
          description: "This is the squad that will be used for the call. To use a transient squad, use `squad` instead."
        squad:
          description: "This is a squad that will be used for the call. To use an existing squad, use `squadId` instead."
          allOf:
          - $ref: '#/components/schemas/CreateSquadDTO'
        error:
          type: string
          description: |-
            This is the error if the call shouldn't be accepted. This is spoken to the customer.

            If this is sent, `assistantId`, `assistant`, `squadId`, `squad`, and `destination` are ignored.
    KnowledgeBaseResponseDocument:
      required:
      - content
      - similarity
      type: object
      properties:
        content:
          type: string
          description: This is the content of the document.
        similarity:
          type: number
          description: This is the similarity score of the document.
        uuid:
          type: string
          description: This is the uuid of the document.
    ServerMessageResponseKnowledgeBaseRequest:
      type: object
      properties:
        documents:
          type: array
          description: This is the list of documents that will be sent to the model alongside the `messages` to generate a response.
          items:
            $ref: '#/components/schemas/KnowledgeBaseResponseDocument'
        message:
          description: This can be used to skip the model output generation and speak a custom message.
          allOf:
          - $ref: '#/components/schemas/CustomMessage'
    ToolCallResult:
      required:
      - name
      - toolCallId
      type: object
      properties:
        message:
          type: array
          description: |-
            This is the message that will be spoken to the user.

            If this is not returned, assistant will speak:
            1. a `request-complete` or `request-failed` message from `tool.messages`, if it exists
            2. a response generated by the model, if not
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
        name:
          type: string
          description: This is the name of the function the model called.
        toolCallId:
          type: string
          description: This is the unique identifier for the tool call.
        result:
          type: string
          description: |-
            This is the result if the tool call was successful. This is added to the conversation history.

            Further, if this is returned, assistant will speak:
            1. the `message`, if it exists and is of type `request-complete`
            2. a `request-complete` message from `tool.messages`, if it exists
            3. a response generated by the model, if neither exist
        error:
          type: string
          description: |-
            This is the error if the tool call was not successful. This is added to the conversation history.

            Further, if this is returned, assistant will speak:
            1. the `message`, if it exists and is of type `request-failed`
            2. a `request-failed` message from `tool.messages`, if it exists
            3. a response generated by the model, if neither exist
    ServerMessageResponseToolCalls:
      type: object
      properties:
        results:
          type: array
          description: These are the results of the "tool-calls" message.
          items:
            $ref: '#/components/schemas/ToolCallResult'
        error:
          type: string
          description: This is the error message if the tool call was not successful.
    ServerMessageResponseTransferDestinationRequest:
      type: object
      properties:
        destination:
          description: This is the destination you'd like the call to be transferred to.
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationAssistant'
          - $ref: '#/components/schemas/TransferDestinationStep'
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
        error:
          type: string
          description: This is the error message if the transfer should not be made.
    ServerMessageResponseVoiceRequest:
      required:
      - data
      type: object
      properties:
        data:
          type: string
          description: |-
            DO NOT respond to a `voice-request` webhook with this schema of { data }. This schema just exists to document what the response should look like. Follow these instructions:

            Here is what the request will look like:

            POST https://{assistant.voice.server.url}
            Content-Type: application/json

            {
              "messsage": {
                "type": "voice-request",
                "text": "Hello, world!",
                "sampleRate": 24000,
                ...other metadata about the call...
              }
            }

            The expected response is 1-channel 16-bit raw PCM audio at the sample rate specified in the request. Here is how the response will be piped to the transport:
            ```
            response.on('data', (chunk: Buffer) => {
              outputStream.write(chunk);
            });
            ```
    ServerMessageResponse:
      required:
      - messageResponse
      type: object
      properties:
        messageResponse:
          description: |-
            This is the response that is expected from the server to the message.

            Note: Most messages don't expect a response. Only "assistant-request", "tool-calls" and "transfer-destination-request" do.
          oneOf:
          - $ref: '#/components/schemas/ServerMessageResponseAssistantRequest'
          - $ref: '#/components/schemas/ServerMessageResponseKnowledgeBaseRequest'
          - $ref: '#/components/schemas/ServerMessageResponseToolCalls'
          - $ref: '#/components/schemas/ServerMessageResponseTransferDestinationRequest'
          - $ref: '#/components/schemas/ServerMessageResponseVoiceRequest'
    ClientInboundMessageAddMessage:
      required:
      - message
      - type
      type: object
      properties:
        type:
          type: string
          description: This is the type of the message. Send "add-message" message to add a message to the conversation history.
          enum:
          - add-message
        message:
          description: This is the message to add to the conversation.
          allOf:
          - $ref: '#/components/schemas/OpenAIMessage'
        triggerResponseEnabled:
          type: boolean
          description: |-
            This is the flag to trigger a response, or to insert the message into the conversation history silently. Defaults to `true`.

            Usage:
            - Use `true` to trigger a response.
            - Use `false` to insert the message into the conversation history silently.

            @default true
          default: true
    ClientInboundMessageControl:
      required:
      - control
      - type
      type: object
      properties:
        type:
          type: string
          description: |-
            This is the type of the message. Send "control" message to control the assistant. `control` options are:
            - "mute-assistant" - mute the assistant
            - "unmute-assistant" - unmute the assistant
            - "say-first-message" - say the first message (this is used when video recording is enabled and the conversation is only started once the client side kicks off the recording)
          enum:
          - control
        control:
          type: string
          description: This is the control action
          enum:
          - mute-assistant
          - unmute-assistant
          - say-first-message
    ClientInboundMessageSay:
      type: object
      properties:
        type:
          type: string
          description: This is the type of the message. Send "say" message to make the assistant say something.
          enum:
          - say
        content:
          type: string
          description: This is the content to say.
        endCallAfterSpoken:
          type: boolean
          description: This is the flag to end call after content is spoken.
        interruptionsEnabled:
          type: boolean
          description: This is the flag for whether the message is interruptible.
    ClientInboundMessageEndCall:
      required:
      - type
      type: object
      properties:
        type:
          type: string
          description: This is the type of the message. Send "end-call" message to end the call.
          enum:
          - end-call
    ClientInboundMessageTransfer:
      required:
      - type
      type: object
      properties:
        type:
          type: string
          description: This is the type of the message. Send "transfer" message to transfer the call to a destination.
          enum:
          - transfer
        destination:
          description: This is the destination to transfer the call to.
          oneOf:
          - $ref: '#/components/schemas/TransferDestinationNumber'
          - $ref: '#/components/schemas/TransferDestinationSip'
        content:
          type: string
          description: This is the content to say.
    ClientInboundMessage:
      required:
      - message
      type: object
      properties:
        message:
          description: These are the messages that can be sent from client-side SDKs to control the call.
          oneOf:
          - $ref: '#/components/schemas/ClientInboundMessageAddMessage'
          - $ref: '#/components/schemas/ClientInboundMessageControl'
          - $ref: '#/components/schemas/ClientInboundMessageSay'
          - $ref: '#/components/schemas/ClientInboundMessageEndCall'
          - $ref: '#/components/schemas/ClientInboundMessageTransfer'
    UserMessage:
      required:
      - endTime
      - message
      - role
      - secondsFromStart
      - time
      type: object
      properties:
        role:
          type: string
          description: The role of the user in the conversation.
        message:
          type: string
          description: The message content from the user.
        time:
          type: number
          description: The timestamp when the message was sent.
        endTime:
          type: number
          description: The timestamp when the message ended.
        secondsFromStart:
          type: number
          description: The number of seconds from the start of the conversation.
        duration:
          type: number
          description: The duration of the message in seconds.
    SystemMessage:
      required:
      - message
      - role
      - secondsFromStart
      - time
      type: object
      properties:
        role:
          type: string
          description: The role of the system in the conversation.
        message:
          type: string
          description: The message content from the system.
        time:
          type: number
          description: The timestamp when the message was sent.
        secondsFromStart:
          type: number
          description: The number of seconds from the start of the conversation.
    BotMessage:
      required:
      - endTime
      - message
      - role
      - secondsFromStart
      - time
      type: object
      properties:
        role:
          type: string
          description: The role of the bot in the conversation.
        message:
          type: string
          description: The message content from the bot.
        time:
          type: number
          description: The timestamp when the message was sent.
        endTime:
          type: number
          description: The timestamp when the message ended.
        secondsFromStart:
          type: number
          description: The number of seconds from the start of the conversation.
        source:
          type: string
          description: The source of the message.
        duration:
          type: number
          description: The duration of the message in seconds.
    ToolCallMessage:
      required:
      - message
      - role
      - secondsFromStart
      - time
      - toolCalls
      type: object
      properties:
        role:
          type: string
          description: The role of the tool call in the conversation.
        toolCalls:
          type: array
          description: The list of tool calls made during the conversation.
          items:
            type: object
        message:
          type: string
          description: The message content for the tool call.
        time:
          type: number
          description: The timestamp when the message was sent.
        secondsFromStart:
          type: number
          description: The number of seconds from the start of the conversation.
    ToolCallResultMessage:
      required:
      - name
      - result
      - role
      - secondsFromStart
      - time
      - toolCallId
      type: object
      properties:
        role:
          type: string
          description: The role of the tool call result in the conversation.
        toolCallId:
          type: string
          description: The ID of the tool call.
        name:
          type: string
          description: The name of the tool that returned the result.
        result:
          type: string
          description: The result of the tool call in JSON format.
        time:
          type: number
          description: The timestamp when the message was sent.
        secondsFromStart:
          type: number
          description: The number of seconds from the start of the conversation.
    TransportCost:
      required:
      - cost
      - minutes
      - type
      type: object
      properties:
        type:
          type: string
          description: "This is the type of cost, always 'transport' for this class."
          enum:
          - transport
        provider:
          type: string
          enum:
          - twilio
          - vonage
          - vapi
        minutes:
          type: number
          description: This is the minutes of `transport` usage. This should match `call.endedAt` - `call.startedAt`.
        cost:
          type: number
          description: This is the cost of the component in USD.
    TranscriberCost:
      required:
      - cost
      - minutes
      - transcriber
      - type
      type: object
      properties:
        type:
          type: string
          description: "This is the type of cost, always 'transcriber' for this class."
          enum:
          - transcriber
        transcriber:
          type: object
          description: |-
            This is the transcriber that was used during the call.

            This matches one of the below:
            - `call.assistant.transcriber`,
            - `call.assistantId->transcriber`,
            - `call.squad[n].assistant.transcriber`,
            - `call.squad[n].assistantId->transcriber`,
            - `call.squadId->[n].assistant.transcriber`,
            - `call.squadId->[n].assistantId->transcriber`.
        minutes:
          type: number
          description: "This is the minutes of `transcriber` usage. This should match `call.endedAt` - `call.startedAt` for single assistant calls, while squad calls will have multiple transcriber costs one for each assistant that was used."
        cost:
          type: number
          description: This is the cost of the component in USD.
    ModelCost:
      required:
      - completionTokens
      - cost
      - model
      - promptTokens
      - type
      type: object
      properties:
        type:
          type: string
          description: "This is the type of cost, always 'model' for this class."
          enum:
          - model
        model:
          type: object
          description: |-
            This is the model that was used during the call.

            This matches one of the following:
            - `call.assistant.model`,
            - `call.assistantId->model`,
            - `call.squad[n].assistant.model`,
            - `call.squad[n].assistantId->model`,
            - `call.squadId->[n].assistant.model`,
            - `call.squadId->[n].assistantId->model`.
        promptTokens:
          type: number
          description: "This is the number of prompt tokens used in the call. These should be total prompt tokens used in the call for single assistant calls, while squad calls will have multiple model costs one for each assistant that was used."
        completionTokens:
          type: number
          description: "This is the number of completion tokens generated in the call. These should be total completion tokens used in the call for single assistant calls, while squad calls will have multiple model costs one for each assistant that was used."
        cost:
          type: number
          description: This is the cost of the component in USD.
    VoiceCost:
      required:
      - characters
      - cost
      - type
      - voice
      type: object
      properties:
        type:
          type: string
          description: "This is the type of cost, always 'voice' for this class."
          enum:
          - voice
        voice:
          type: object
          description: |-
            This is the voice that was used during the call.

            This matches one of the following:
            - `call.assistant.voice`,
            - `call.assistantId->voice`,
            - `call.squad[n].assistant.voice`,
            - `call.squad[n].assistantId->voice`,
            - `call.squadId->[n].assistant.voice`,
            - `call.squadId->[n].assistantId->voice`.
        characters:
          type: number
          description: "This is the number of characters that were generated during the call. These should be total characters used in the call for single assistant calls, while squad calls will have multiple voice costs one for each assistant that was used."
        cost:
          type: number
          description: This is the cost of the component in USD.
    VapiCost:
      required:
      - cost
      - minutes
      - subType
      - type
      type: object
      properties:
        type:
          type: string
          description: "This is the type of cost, always 'vapi' for this class."
          enum:
          - vapi
        subType:
          type: string
          description: This is the sub type of the cost.
          enum:
          - normal
          - overage
        minutes:
          type: number
          description: This is the minutes of Vapi usage. This should match `call.endedAt` - `call.startedAt`.
        cost:
          type: number
          description: This is the cost of the component in USD.
    AnalysisCost:
      required:
      - analysisType
      - completionTokens
      - cost
      - model
      - promptTokens
      - type
      type: object
      properties:
        type:
          type: string
          description: "This is the type of cost, always 'analysis' for this class."
          enum:
          - analysis
        analysisType:
          type: string
          description: This is the type of analysis performed.
          enum:
          - summary
          - structuredData
          - successEvaluation
        model:
          type: object
          description: This is the model that was used to perform the analysis.
        promptTokens:
          type: number
          description: This is the number of prompt tokens used in the analysis.
        completionTokens:
          type: number
          description: This is the number of completion tokens generated in the analysis.
        cost:
          type: number
          description: This is the cost of the component in USD.
    VoicemailDetectionCost:
      required:
      - completionAudioTokens
      - completionTextTokens
      - cost
      - model
      - promptAudioTokens
      - promptTextTokens
      - provider
      - type
      type: object
      properties:
        type:
          type: string
          description: "This is the type of cost, always 'voicemail-detection' for this class."
          enum:
          - voicemail-detection
        model:
          type: object
          description: This is the model that was used to perform the analysis.
        provider:
          type: string
          description: This is the provider that was used to detect the voicemail.
          enum:
          - twilio
          - google
          - openai
        promptTextTokens:
          type: number
          description: This is the number of prompt text tokens used in the voicemail detection.
        promptAudioTokens:
          type: number
          description: This is the number of prompt audio tokens used in the voicemail detection.
        completionTextTokens:
          type: number
          description: This is the number of completion text tokens used in the voicemail detection.
        completionAudioTokens:
          type: number
          description: This is the number of completion audio tokens used in the voicemail detection.
        cost:
          type: number
          description: This is the cost of the component in USD.
    FunctionToolWithToolCall:
      required:
      - toolCall
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "function" for Function tool.
          enum:
          - function
        toolCall:
          $ref: '#/components/schemas/ToolCall'
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    GhlToolWithToolCall:
      required:
      - metadata
      - toolCall
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "ghl" for GHL tool.
          enum:
          - ghl
        toolCall:
          $ref: '#/components/schemas/ToolCall'
        metadata:
          $ref: '#/components/schemas/GhlToolMetadata'
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    MakeToolWithToolCall:
      required:
      - metadata
      - toolCall
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "make" for Make tool.
          enum:
          - make
        toolCall:
          $ref: '#/components/schemas/ToolCall'
        metadata:
          $ref: '#/components/schemas/MakeToolMetadata'
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    BashToolWithToolCall:
      required:
      - name
      - subType
      - toolCall
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "bash" for Bash tool.
          enum:
          - bash
        subType:
          type: string
          description: The sub type of tool.
          enum:
          - bash_20241022
        toolCall:
          $ref: '#/components/schemas/ToolCall'
        name:
          type: string
          description: "The name of the tool, fixed to 'bash'"
          default: bash
          enum:
          - bash
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    ComputerToolWithToolCall:
      required:
      - displayHeightPx
      - displayWidthPx
      - name
      - subType
      - toolCall
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "computer" for Computer tool.
          enum:
          - computer
        subType:
          type: string
          description: The sub type of tool.
          enum:
          - computer_20241022
        toolCall:
          $ref: '#/components/schemas/ToolCall'
        name:
          type: string
          description: "The name of the tool, fixed to 'computer'"
          default: computer
          enum:
          - computer
        displayWidthPx:
          type: number
          description: The display width in pixels
        displayHeightPx:
          type: number
          description: The display height in pixels
        displayNumber:
          type: number
          description: Optional display number
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    TextEditorToolWithToolCall:
      required:
      - name
      - subType
      - toolCall
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "textEditor" for Text Editor tool.
          enum:
          - textEditor
        subType:
          type: string
          description: The sub type of tool.
          enum:
          - text_editor_20241022
        toolCall:
          $ref: '#/components/schemas/ToolCall'
        name:
          type: string
          description: "The name of the tool, fixed to 'str_replace_editor'"
          default: str_replace_editor
          enum:
          - str_replace_editor
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    GoogleCalendarCreateEventToolWithToolCall:
      required:
      - toolCall
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "google.calendar.event.create" for Google Calendar tool.
          enum:
          - google.calendar.event.create
        toolCall:
          $ref: '#/components/schemas/ToolCall'
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    GoogleSheetsRowAppendToolWithToolCall:
      required:
      - toolCall
      - type
      type: object
      properties:
        async:
          type: boolean
          description: |-
            This determines if the tool is async.

            If async, the assistant will move forward without waiting for your server to respond. This is useful if you just want to trigger something on your server.

            If sync, the assistant will wait for your server to respond. This is useful if want assistant to respond with the result from your server.

            Defaults to synchronous (`false`).
          example: false
        messages:
          type: array
          description: |-
            These are the messages that will be spoken to the user as the tool is running.

            For some tools, this is auto-filled based on special fields like `tool.destinations`. For others like the function tool, these can be custom configured.
          items:
            oneOf:
            - $ref: '#/components/schemas/ToolMessageStart'
            - $ref: '#/components/schemas/ToolMessageComplete'
            - $ref: '#/components/schemas/ToolMessageFailed'
            - $ref: '#/components/schemas/ToolMessageDelayed'
        type:
          type: string
          description: The type of tool. "google.sheets.row.append" for Google Sheets tool.
          enum:
          - google.sheets.row.append
        toolCall:
          $ref: '#/components/schemas/ToolCall'
        function:
          description: |-
            This is the function definition of the tool.

            For `endCall`, `transferCall`, and `dtmf` tools, this is auto-filled based on tool-specific fields like `tool.destinations`. But, even in those cases, you can provide a custom function definition for advanced use cases.

            An example of an advanced use case is if you want to customize the message that's spoken for `endCall` tool. You can specify a function where it returns an argument "reason". Then, in `messages` array, you can have many "request-complete" messages. One of these messages will be triggered if the `messages[].conditions` matches the "reason" argument.
          allOf:
          - $ref: '#/components/schemas/OpenAIFunction'
        server:
          description: |-
            This is the server that will be hit when this tool is requested by the model.

            All requests will be sent with the call object among other things. You can find more details in the Server URL documentation.

            This overrides the serverUrl set on the org and the phoneNumber. Order of precedence: highest tool.server.url, then assistant.serverUrl, then phoneNumber.serverUrl, then org.serverUrl.
          allOf:
          - $ref: '#/components/schemas/Server'
    inline_response_201:
      oneOf:
      - $ref: '#/components/schemas/Call'
      - $ref: '#/components/schemas/CallBatchResponse'
    phonenumber_body:
      discriminator:
        propertyName: provider
        mapping:
          byo-phone-number: '#/components/schemas/CreateByoPhoneNumberDTO'
          twilio: '#/components/schemas/CreateTwilioPhoneNumberDTO'
          vonage: '#/components/schemas/CreateVonagePhoneNumberDTO'
          vapi: '#/components/schemas/CreateVapiPhoneNumberDTO'
          telnyx: '#/components/schemas/CreateTelnyxPhoneNumberDTO'
      oneOf:
      - $ref: '#/components/schemas/CreateByoPhoneNumberDTO'
      - $ref: '#/components/schemas/CreateTwilioPhoneNumberDTO'
      - $ref: '#/components/schemas/CreateVonagePhoneNumberDTO'
      - $ref: '#/components/schemas/CreateVapiPhoneNumberDTO'
      - $ref: '#/components/schemas/CreateTelnyxPhoneNumberDTO'
    PhoneNumber:
      title: PhoneNumber
      discriminator:
        propertyName: provider
        mapping:
          byo-phone-number: '#/components/schemas/ByoPhoneNumber'
          twilio: '#/components/schemas/TwilioPhoneNumber'
          vonage: '#/components/schemas/VonagePhoneNumber'
          vapi: '#/components/schemas/VapiPhoneNumber'
          telnyx: '#/components/schemas/TelnyxPhoneNumber'
      oneOf:
      - $ref: '#/components/schemas/ByoPhoneNumber'
      - $ref: '#/components/schemas/TwilioPhoneNumber'
      - $ref: '#/components/schemas/VonagePhoneNumber'
      - $ref: '#/components/schemas/VapiPhoneNumber'
      - $ref: '#/components/schemas/TelnyxPhoneNumber'
    phonenumber_id_body:
      discriminator:
        propertyName: provider
        mapping:
          byo-phone-number: '#/components/schemas/UpdateByoPhoneNumberDTO'
          twilio: '#/components/schemas/UpdateTwilioPhoneNumberDTO'
          vonage: '#/components/schemas/UpdateVonagePhoneNumberDTO'
          vapi: '#/components/schemas/UpdateVapiPhoneNumberDTO'
          telnyx: '#/components/schemas/UpdateTelnyxPhoneNumberDTO'
      oneOf:
      - $ref: '#/components/schemas/UpdateByoPhoneNumberDTO'
      - $ref: '#/components/schemas/UpdateTwilioPhoneNumberDTO'
      - $ref: '#/components/schemas/UpdateVonagePhoneNumberDTO'
      - $ref: '#/components/schemas/UpdateVapiPhoneNumberDTO'
      - $ref: '#/components/schemas/UpdateTelnyxPhoneNumberDTO'
    tool_body:
      discriminator:
        propertyName: type
        mapping:
          dtmf: '#/components/schemas/CreateDtmfToolDTO'
          endCall: '#/components/schemas/CreateEndCallToolDTO'
          function: '#/components/schemas/CreateFunctionToolDTO'
          ghl: '#/components/schemas/CreateGhlToolDTO'
          make: '#/components/schemas/CreateMakeToolDTO'
          transferCall: '#/components/schemas/CreateTransferCallToolDTO'
          output: '#/components/schemas/CreateOutputToolDTO'
          bash: '#/components/schemas/CreateBashToolDTO'
          computer: '#/components/schemas/CreateComputerToolDTO'
          textEditor: '#/components/schemas/CreateTextEditorToolDTO'
          query: '#/components/schemas/CreateQueryToolDTO'
          google.calendar.event.create: '#/components/schemas/CreateGoogleCalendarCreateEventToolDTO'
          google.sheets.row.append: '#/components/schemas/CreateGoogleSheetsRowAppendToolDTO'
          google.calendar.availability.check: '#/components/schemas/CreateGoogleCalendarCheckAvailabilityToolDTO'
          slack.message.send: '#/components/schemas/CreateSlackSendMessageToolDTO'
          sms: '#/components/schemas/CreateSmsSendToolDTO'
          mcp: '#/components/schemas/CreateMcpToolDTO'
      oneOf:
      - $ref: '#/components/schemas/CreateDtmfToolDTO'
      - $ref: '#/components/schemas/CreateEndCallToolDTO'
      - $ref: '#/components/schemas/CreateFunctionToolDTO'
      - $ref: '#/components/schemas/CreateGhlToolDTO'
      - $ref: '#/components/schemas/CreateMakeToolDTO'
      - $ref: '#/components/schemas/CreateTransferCallToolDTO'
      - $ref: '#/components/schemas/CreateOutputToolDTO'
      - $ref: '#/components/schemas/CreateBashToolDTO'
      - $ref: '#/components/schemas/CreateComputerToolDTO'
      - $ref: '#/components/schemas/CreateTextEditorToolDTO'
      - $ref: '#/components/schemas/CreateQueryToolDTO'
      - $ref: '#/components/schemas/CreateGoogleCalendarCreateEventToolDTO'
      - $ref: '#/components/schemas/CreateGoogleSheetsRowAppendToolDTO'
      - $ref: '#/components/schemas/CreateGoogleCalendarCheckAvailabilityToolDTO'
      - $ref: '#/components/schemas/CreateSlackSendMessageToolDTO'
      - $ref: '#/components/schemas/CreateSmsSendToolDTO'
      - $ref: '#/components/schemas/CreateMcpToolDTO'
    inline_response_201_1:
      discriminator:
        propertyName: type
        mapping:
          dtmf: '#/components/schemas/DtmfTool'
          endCall: '#/components/schemas/EndCallTool'
          function: '#/components/schemas/FunctionTool'
          ghl: '#/components/schemas/GhlTool'
          make: '#/components/schemas/MakeTool'
          transferCall: '#/components/schemas/TransferCallTool'
          output: '#/components/schemas/OutputTool'
          bash: '#/components/schemas/BashTool'
          computer: '#/components/schemas/ComputerTool'
          textEditor: '#/components/schemas/TextEditorTool'
          query: '#/components/schemas/QueryTool'
          google.calendar.event.create: '#/components/schemas/GoogleCalendarCreateEventTool'
          google.sheets.row.append: '#/components/schemas/GoogleSheetsRowAppendTool'
          google.calendar.availability.check: '#/components/schemas/GoogleCalendarCheckAvailabilityTool'
          slack.message.send: '#/components/schemas/SlackSendMessageTool'
          sms: '#/components/schemas/SmsSendTool'
          mcp: '#/components/schemas/McpTool'
      oneOf:
      - $ref: '#/components/schemas/DtmfTool'
      - $ref: '#/components/schemas/EndCallTool'
      - $ref: '#/components/schemas/FunctionTool'
      - $ref: '#/components/schemas/GhlTool'
      - $ref: '#/components/schemas/MakeTool'
      - $ref: '#/components/schemas/TransferCallTool'
      - $ref: '#/components/schemas/OutputTool'
      - $ref: '#/components/schemas/BashTool'
      - $ref: '#/components/schemas/ComputerTool'
      - $ref: '#/components/schemas/TextEditorTool'
      - $ref: '#/components/schemas/QueryTool'
      - $ref: '#/components/schemas/GoogleCalendarCreateEventTool'
      - $ref: '#/components/schemas/GoogleSheetsRowAppendTool'
      - $ref: '#/components/schemas/GoogleCalendarCheckAvailabilityTool'
      - $ref: '#/components/schemas/SlackSendMessageTool'
      - $ref: '#/components/schemas/SmsSendTool'
      - $ref: '#/components/schemas/McpTool'
    tool_id_body:
      discriminator:
        propertyName: type
        mapping:
          dtmf: '#/components/schemas/UpdateDtmfToolDTO'
          endCall: '#/components/schemas/UpdateEndCallToolDTO'
          function: '#/components/schemas/UpdateFunctionToolDTO'
          ghl: '#/components/schemas/UpdateGhlToolDTO'
          make: '#/components/schemas/UpdateMakeToolDTO'
          transferCall: '#/components/schemas/UpdateTransferCallToolDTO'
          output: '#/components/schemas/UpdateOutputToolDTO'
          bash: '#/components/schemas/UpdateBashToolDTO'
          computer: '#/components/schemas/UpdateComputerToolDTO'
          textEditor: '#/components/schemas/UpdateTextEditorToolDTO'
          query: '#/components/schemas/UpdateQueryToolDTO'
          google.calendar.event.create: '#/components/schemas/UpdateGoogleCalendarCreateEventToolDTO'
          google.sheets.row.append: '#/components/schemas/UpdateGoogleSheetsRowAppendToolDTO'
          google.calendar.availability.check: '#/components/schemas/UpdateGoogleCalendarCheckAvailabilityToolDTO'
          slack.message.send: '#/components/schemas/UpdateSlackSendMessageToolDTO'
          sms: '#/components/schemas/UpdateSmsSendToolDTO'
          mcp: '#/components/schemas/UpdateMcpToolDTO'
      oneOf:
      - $ref: '#/components/schemas/UpdateDtmfToolDTO'
      - $ref: '#/components/schemas/UpdateEndCallToolDTO'
      - $ref: '#/components/schemas/UpdateFunctionToolDTO'
      - $ref: '#/components/schemas/UpdateGhlToolDTO'
      - $ref: '#/components/schemas/UpdateMakeToolDTO'
      - $ref: '#/components/schemas/UpdateTransferCallToolDTO'
      - $ref: '#/components/schemas/UpdateOutputToolDTO'
      - $ref: '#/components/schemas/UpdateBashToolDTO'
      - $ref: '#/components/schemas/UpdateComputerToolDTO'
      - $ref: '#/components/schemas/UpdateTextEditorToolDTO'
      - $ref: '#/components/schemas/UpdateQueryToolDTO'
      - $ref: '#/components/schemas/UpdateGoogleCalendarCreateEventToolDTO'
      - $ref: '#/components/schemas/UpdateGoogleSheetsRowAppendToolDTO'
      - $ref: '#/components/schemas/UpdateGoogleCalendarCheckAvailabilityToolDTO'
      - $ref: '#/components/schemas/UpdateSlackSendMessageToolDTO'
      - $ref: '#/components/schemas/UpdateSmsSendToolDTO'
      - $ref: '#/components/schemas/UpdateMcpToolDTO'
    knowledgebase_body:
      discriminator:
        propertyName: provider
        mapping:
          trieve: '#/components/schemas/CreateTrieveKnowledgeBaseDTO'
          custom-knowledge-base: '#/components/schemas/CreateCustomKnowledgeBaseDTO'
      oneOf:
      - $ref: '#/components/schemas/CreateTrieveKnowledgeBaseDTO'
      - $ref: '#/components/schemas/CreateCustomKnowledgeBaseDTO'
    inline_response_201_2:
      discriminator:
        propertyName: provider
        mapping:
          trieve: '#/components/schemas/TrieveKnowledgeBase'
          custom-knowledge-base: '#/components/schemas/CustomKnowledgeBase'
      oneOf:
      - $ref: '#/components/schemas/TrieveKnowledgeBase'
      - $ref: '#/components/schemas/CustomKnowledgeBase'
    knowledgebase_id_body:
      discriminator:
        propertyName: provider
        mapping:
          trieve: '#/components/schemas/UpdateTrieveKnowledgeBaseDTO'
          custom-knowledge-base: '#/components/schemas/UpdateCustomKnowledgeBaseDTO'
      oneOf:
      - $ref: '#/components/schemas/UpdateTrieveKnowledgeBaseDTO'
      - $ref: '#/components/schemas/UpdateCustomKnowledgeBaseDTO'
    testSuiteId_test_body:
      discriminator:
        propertyName: type
        mapping:
          voice: '#/components/schemas/CreateTestSuiteTestVoiceDto'
          chat: '#/components/schemas/CreateTestSuiteTestChatDto'
      oneOf:
      - $ref: '#/components/schemas/CreateTestSuiteTestVoiceDto'
      - $ref: '#/components/schemas/CreateTestSuiteTestChatDto'
    inline_response_201_3:
      discriminator:
        propertyName: type
        mapping:
          voice: '#/components/schemas/TestSuiteTestVoice'
          chat: '#/components/schemas/TestSuiteTestChat'
      oneOf:
      - $ref: '#/components/schemas/TestSuiteTestVoice'
      - $ref: '#/components/schemas/TestSuiteTestChat'
    test_id_body:
      discriminator:
        propertyName: type
        mapping:
          voice: '#/components/schemas/UpdateTestSuiteTestVoiceDto'
          chat: '#/components/schemas/UpdateTestSuiteTestChatDto'
      oneOf:
      - $ref: '#/components/schemas/UpdateTestSuiteTestVoiceDto'
      - $ref: '#/components/schemas/UpdateTestSuiteTestChatDto'
  securitySchemes:
    bearer:
      type: http
      description: "Retrieve your API Key from [Dashboard](dashboard.vapi.ai)."
      scheme: bearer
      bearerFormat: Bearer
